<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
    <title>Pierre Zemb&#x27;s Blog - distributed-systems</title>
    <subtitle>Pierre Zemb personal blog</subtitle>
    <link rel="self" type="application/atom+xml" href="https://pierrezemb.fr/tags/distributed-systems/atom.xml"/>
    <link rel="alternate" type="text/html" href="https://pierrezemb.fr"/>
    <generator uri="https://www.getzola.org/">Zola</generator>
    <updated>2025-12-09T00:00:00+00:00</updated>
    <id>https://pierrezemb.fr/tags/distributed-systems/atom.xml</id>
    <entry xml:lang="en">
        <title>Designing Rust FDB Workloads That Actually Find Bugs</title>
        <published>2025-12-09T00:00:00+00:00</published>
        <updated>2025-12-09T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Pierre Zemb
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://pierrezemb.fr/posts/writing-rust-fdb-workloads-that-find-bugs/"/>
        <id>https://pierrezemb.fr/posts/writing-rust-fdb-workloads-that-find-bugs/</id>
        
        <category term="foundationdb" schema="https://pierrezemb.fr/tags/" label="foundationdb"/>
        <category term="rust" schema="https://pierrezemb.fr/tags/" label="rust"/>
        <category term="testing" schema="https://pierrezemb.fr/tags/" label="testing"/>
        <category term="simulation" schema="https://pierrezemb.fr/tags/" label="simulation"/>
        <category term="deterministic" schema="https://pierrezemb.fr/tags/" label="deterministic"/>
        <category term="distributed-systems" schema="https://pierrezemb.fr/tags/" label="distributed-systems"/>
        <content type="html" xml:base="https://pierrezemb.fr/posts/writing-rust-fdb-workloads-that-find-bugs/">&lt;p&gt;After &lt;a href=&quot;&#x2F;posts&#x2F;diving-into-foundationdb-simulation&#x2F;&quot;&gt;one trillion CPU-hours of simulation testing&lt;&#x2F;a&gt;, FoundationDB has been stress-tested under conditions far worse than any production environment. Network partitions, disk failures, Byzantine faults. FDB handles them all. &lt;strong&gt;But what about your code?&lt;&#x2F;strong&gt; Your layer sits on top of FDB. Your indexes, your transaction logic, your retry handling. How do you know it survives chaos?&lt;&#x2F;p&gt;
&lt;p&gt;At Clever Cloud, we were building &lt;a href=&quot;https:&#x2F;&#x2F;www.clever-cloud.com&#x2F;materia&#x2F;&quot;&gt;Materia&lt;&#x2F;a&gt;, our serverless database product. We were afraid to ship our layer code without the same level of testing FDB itself enjoys. So we hacked our way into FDB&#x27;s simulation framework using &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;foundationdb-rs&#x2F;foundationdb-rs&#x2F;tree&#x2F;4ed057a&#x2F;foundationdb-simulation&quot;&gt;foundationdb-simulation&lt;&#x2F;a&gt;. On our first seed, simulation surfaced one of the most dreaded edge cases for FDB layer developers: &lt;a href=&quot;https:&#x2F;&#x2F;apple.github.io&#x2F;foundationdb&#x2F;developer-guide.html#transactions-with-unknown-results&quot;&gt;&lt;code&gt;commit_unknown_result&lt;&#x2F;code&gt;&lt;&#x2F;a&gt;. The client can&#x27;t always know if a transaction committed before the connection dropped. Our atomic counter increments were sometimes running twice. In production, you might see this once every few months under heavy load and during failures. In simulation? &lt;strong&gt;Almost immediately.&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;This post won&#x27;t walk you through the code mechanics. The &lt;a href=&quot;https:&#x2F;&#x2F;crates.io&#x2F;crates&#x2F;foundationdb-simulation&quot;&gt;foundationdb-simulation crate&lt;&#x2F;a&gt; and its &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;foundationdb-rs&#x2F;foundationdb-rs&#x2F;tree&#x2F;4ed057a&#x2F;foundationdb-simulation&quot;&gt;README&lt;&#x2F;a&gt; cover that. Instead, this teaches you how to &lt;strong&gt;design&lt;&#x2F;strong&gt; workloads that catch real bugs. Whether you&#x27;re a junior engineer or an LLM helping write tests, these principles will guide you.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;why-autonomous-testing-works&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#why-autonomous-testing-works&quot; aria-label=&quot;Anchor link for: why-autonomous-testing-works&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;Why Autonomous Testing Works&lt;&#x2F;h2&gt;
&lt;p&gt;Traditional testing has you write specific tests for scenarios you imagined. But as Will Wilson put it at &lt;a href=&quot;https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=eZ1mmqlq-mY&quot;&gt;Bug Bash 2025&lt;&#x2F;a&gt;: &lt;strong&gt;&quot;The most dangerous bugs occur in states you never imagined possible.&quot;&lt;&#x2F;strong&gt; The key insight of autonomous testing (what FDB&#x27;s simulation embodies) is that instead of writing tests, you write a &lt;strong&gt;test generator&lt;&#x2F;strong&gt;. If you ran it for infinite time, it would eventually produce all possible tests you could have written. You don&#x27;t have infinite time, so instead you get a probability distribution over all possible tests. And probability distributions are leaky: they cover cases you never would have thought to test.&lt;&#x2F;p&gt;
&lt;p&gt;This is why simulation finds bugs so fast. You&#x27;re not testing what you thought to test. You&#x27;re testing what the probability distribution happens to generate, which includes edge cases you&#x27;d never have written explicitly. Add fault injection (a probability distribution over all possible ways the world can conspire to screw you) and now you&#x27;re finding bugs that would take months or years to surface in production.&lt;&#x2F;p&gt;
&lt;p&gt;This is what got me interested in simulation in the first place: how do you test the things you see during on-call shifts? Those weird transient bugs at 3 AM, the race conditions that happen once a month, the edge cases you only discover when production is on fire. Simulation shifts that complexity from SRE time to SWE time. What was a 3 AM page becomes a daytime debugging session. What&#x27;s a high-pressure incident becomes a reproducible test case you can bisect, rewind, and experiment with freely.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-sequential-luck-problem&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#the-sequential-luck-problem&quot; aria-label=&quot;Anchor link for: the-sequential-luck-problem&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;The Sequential Luck Problem&lt;&#x2F;h2&gt;
&lt;p&gt;Here&#x27;s why rare bugs are so hard to find: imagine a bug that requires three unlikely events in sequence. Each event has a 1&#x2F;1000 probability. Finding that bug requires 1&#x2F;1,000,000,000 attempts, roughly a billion tries with random testing. &lt;strong&gt;But here&#x27;s the good news for Rust workloads&lt;&#x2F;strong&gt;: you don&#x27;t solve this problem yourself. FDB&#x27;s simulation handles fault injection. BUGGIFY injects failures at arbitrary code points. Network partitions appear and disappear. Disks fail. Machines crash and restart. The simulator explores failure combinations that would take years to encounter in production.&lt;&#x2F;p&gt;
&lt;p&gt;Your job is different. You need to design operations that exercise interesting code paths. Not just reads and writes, but the edge cases your users will inevitably trigger. And you need to write invariants that CATCH bugs when simulation surfaces them. After a million injected faults, how do you prove your data is still correct? This division of labor is the key insight: FDB injects chaos, you verify correctness.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;designing-your-operation-alphabet&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#designing-your-operation-alphabet&quot; aria-label=&quot;Anchor link for: designing-your-operation-alphabet&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;Designing Your Operation Alphabet&lt;&#x2F;h2&gt;
&lt;p&gt;The &lt;strong&gt;operation alphabet&lt;&#x2F;strong&gt; is the complete set of operations your workload can perform. This is where most workloads fail: they test happy paths with uniform distribution and miss the edge cases that break production. Think about three categories:&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Normal operations&lt;&#x2F;strong&gt; with realistic weights. In production, maybe 80% of your traffic is reads, 15% is simple writes, 5% is complex updates. Your workload should reflect this, because bugs often hide in the interactions between operation types. A workload that runs 50% reads and 50% writes tests different code paths than one that runs 95% reads and 5% writes. Both might be valid, but they&#x27;ll find different bugs.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Adversarial inputs&lt;&#x2F;strong&gt; that customers will inevitably send. Empty strings. Maximum-length values. Null bytes in the middle of strings. Unicode edge cases. Boundary integers (0, -1, MAX_INT). Customers never respect your API specs, so model the chaos they create.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Nemesis operations&lt;&#x2F;strong&gt; that break things on purpose. Delete random data mid-test. Clear ranges that &quot;shouldn&#x27;t&quot; be cleared. Crash batch jobs mid-execution to test recovery. Run compaction every operation instead of daily. Create conflict storms where multiple clients hammer the same key. Approach the 10MB transaction limit. These operations stress your error handling and recovery paths. The rare operations are where bugs hide. That batch job running once a day in production? In simulation, you&#x27;ll hit its partial-failure edge case in minutes, but only if your operation alphabet includes it.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;designing-invariants&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#designing-invariants&quot; aria-label=&quot;Anchor link for: designing-invariants&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;Designing Invariants&lt;&#x2F;h2&gt;
&lt;p&gt;After simulation runs thousands of operations with injected faults, network partitions, and machine crashes, how do you know your data is still correct? Unlike FDB&#x27;s internal testing, Rust workloads can&#x27;t inject assertions at arbitrary code points. You verify correctness in the &lt;code&gt;check()&lt;&#x2F;code&gt; phase, after the chaos ends. The key question: &lt;strong&gt;&quot;After all this, how do I PROVE my data is still correct?&quot;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;One critical tip: validate during &lt;code&gt;start()&lt;&#x2F;code&gt;, not just in &lt;code&gt;check()&lt;&#x2F;code&gt;.&lt;&#x2F;strong&gt; Don&#x27;t wait until the end to discover corruption. After each operation (or batch of operations), read back the data and verify it matches expectations. If you&#x27;re maintaining a counter, read it and check the bounds. If you&#x27;re building an index, query it immediately after insertion. Early validation catches bugs closer to their source, making debugging far easier. The &lt;code&gt;check()&lt;&#x2F;code&gt; phase is your final safety net, but continuous validation during execution is where you&#x27;ll catch most issues.&lt;&#x2F;p&gt;
&lt;p&gt;Four patterns dominate invariant design:&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Reference Models&lt;&#x2F;strong&gt; maintain an in-memory copy of expected state. Every operation updates both the database and the reference model. In &lt;code&gt;check()&lt;&#x2F;code&gt;, you compare them. If they diverge, something went wrong. Use &lt;code&gt;BTreeMap&lt;&#x2F;code&gt; (not &lt;code&gt;HashMap&lt;&#x2F;code&gt;) for deterministic iteration. This pattern works best for single-client workloads where you can track state locally.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Conservation Laws&lt;&#x2F;strong&gt; track quantities that must stay constant. Inventory transfers between warehouses shouldn&#x27;t change total inventory. Money transfers between accounts shouldn&#x27;t create or destroy money. Sum everything up and verify the conservation law holds. This pattern is elegant because it doesn&#x27;t require tracking individual operations, just the aggregate property.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Structural Integrity&lt;&#x2F;strong&gt; verifies data structures remain valid. If you maintain a secondary index, verify every index entry points to an existing record and every record appears in the index exactly once. If you maintain a linked list in FDB, traverse it and confirm every node is reachable. The cycle validation pattern (creating a circular list where nodes point to each other) is a classic technique from &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;apple&#x2F;foundationdb&#x2F;blob&#x2F;231f762&#x2F;fdbserver&#x2F;workloads&#x2F;Cycle.actor.cpp&quot;&gt;FDB&#x27;s own Cycle workload&lt;&#x2F;a&gt;. After chaos, traverse the cycle and verify you visit exactly N nodes.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Operation Logging&lt;&#x2F;strong&gt; solves two problems at once: &lt;code&gt;maybe_committed&lt;&#x2F;code&gt; uncertainty and multi-client coordination. The trick from &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;apple&#x2F;foundationdb&#x2F;blob&#x2F;231f762&#x2F;fdbserver&#x2F;workloads&#x2F;AtomicOps.actor.cpp&quot;&gt;FDB&#x27;s own AtomicOps workload&lt;&#x2F;a&gt;: &lt;strong&gt;log the intent alongside the operation in the same transaction&lt;&#x2F;strong&gt;. Write both your operation AND a log entry recording what you intended. Since they&#x27;re in the same transaction, they either both commit or neither does. No uncertainty. For multi-client workloads, each client logs under its own prefix (e.g., &lt;code&gt;log&#x2F;{client_id}&#x2F;&lt;&#x2F;code&gt;). In &lt;code&gt;check()&lt;&#x2F;code&gt;, client 0 reads all logs from all clients, replays them to compute expected state, and compares against actual state. If they diverge, something went wrong, and you&#x27;ll know exactly which operations succeeded. See the &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;foundationdb-rs&#x2F;foundationdb-rs&#x2F;blob&#x2F;4ed057a&#x2F;foundationdb-simulation&#x2F;examples&#x2F;atomic&#x2F;lib.rs&quot;&gt;Rust atomic workload example&lt;&#x2F;a&gt; for a complete implementation.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-determinism-rules&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#the-determinism-rules&quot; aria-label=&quot;Anchor link for: the-determinism-rules&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;The Determinism Rules&lt;&#x2F;h2&gt;
&lt;p&gt;FDB&#x27;s simulation is deterministic. Same seed, same execution path, same bugs. This is the superpower that lets you reproduce failures. But determinism is fragile. Break it, and you lose reproducibility. Five rules to remember:&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;BTreeMap, not HashMap&lt;&#x2F;strong&gt;: HashMap iteration order is non-deterministic&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;context.rnd(), not rand::random()&lt;&#x2F;strong&gt;: All randomness must come from the seeded PRNG&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;context.now(), not SystemTime::now()&lt;&#x2F;strong&gt;: Use simulation time, not wall clock&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;db.run(), not manual retry loops&lt;&#x2F;strong&gt;: The framework handles retries and &lt;code&gt;maybe_committed&lt;&#x2F;code&gt; correctly&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;No tokio::spawn()&lt;&#x2F;strong&gt;: The simulation runs on a custom executor, spawning breaks it&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;If you take nothing else from this post, memorize these. Break any of them and your failures become unreproducible. You&#x27;ll see a bug once and never find it again.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;architecture-the-three-crate-pattern&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#architecture-the-three-crate-pattern&quot; aria-label=&quot;Anchor link for: architecture-the-three-crate-pattern&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;Architecture: The Three-Crate Pattern&lt;&#x2F;h2&gt;
&lt;p&gt;Real production systems use tokio, gRPC, REST frameworks, all of which break simulation determinism. You can&#x27;t just drop your production binary into the simulator. The solution is separating your FDB operations into a simulation-friendly crate:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;my-project&#x2F;
&lt;&#x2F;span&gt;&lt;span&gt;â”œâ”€â”€ my-fdb-service&#x2F;      # Core FDB operations - NO tokio
&lt;&#x2F;span&gt;&lt;span&gt;â”œâ”€â”€ my-grpc-server&#x2F;      # Production layer (tokio + tonic)
&lt;&#x2F;span&gt;&lt;span&gt;â””â”€â”€ my-fdb-workloads&#x2F;    # Simulation tests
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The service crate contains pure FDB transaction logic with no async runtime dependency. The server crate wraps it for production. The workloads crate tests the actual service logic under simulation chaos. This lets you test your real production code, not a reimplementation that might have different bugs.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;common-pitfalls&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#common-pitfalls&quot; aria-label=&quot;Anchor link for: common-pitfalls&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;Common Pitfalls&lt;&#x2F;h2&gt;
&lt;p&gt;Beyond the determinism rules above, these mistakes will bite you:&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Running setup or check on all clients.&lt;&#x2F;strong&gt; The framework runs multiple clients concurrently. If every client initializes data in &lt;code&gt;setup()&lt;&#x2F;code&gt;, you get duplicate initialization. If every client validates in &lt;code&gt;check()&lt;&#x2F;code&gt;, you get inconsistent results. Use &lt;code&gt;if self.client_id == 0&lt;&#x2F;code&gt; to ensure only one client handles initialization and validation.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Forgetting maybe_committed.&lt;&#x2F;strong&gt; The &lt;code&gt;db.run()&lt;&#x2F;code&gt; closure receives a &lt;code&gt;maybe_committed&lt;&#x2F;code&gt; flag indicating the previous attempt might have succeeded. If you&#x27;re doing non-idempotent operations like atomic increments, you need either truly idempotent transactions or &lt;a href=&quot;&#x2F;posts&#x2F;automatic-txn-fdb-730&#x2F;&quot;&gt;automatic idempotency&lt;&#x2F;a&gt; in FDB 7.3+. Ignoring this flag means your workload might count operations twice.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Storing SimDatabase between phases.&lt;&#x2F;strong&gt; Each phase (&lt;code&gt;setup&lt;&#x2F;code&gt;, &lt;code&gt;start&lt;&#x2F;code&gt;, &lt;code&gt;check&lt;&#x2F;code&gt;) gets a fresh database reference. Storing the old one leads to undefined behavior. Always use the &lt;code&gt;db&lt;&#x2F;code&gt; parameter passed to each method.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Wrapping FdbError in custom error types.&lt;&#x2F;strong&gt; The &lt;code&gt;db.run()&lt;&#x2F;code&gt; retry mechanism checks if errors are retryable via &lt;code&gt;FdbError::is_retryable()&lt;&#x2F;code&gt;. If you wrap &lt;code&gt;FdbError&lt;&#x2F;code&gt; in your own error type (like &lt;code&gt;anyhow::Error&lt;&#x2F;code&gt; or a custom enum), the retry logic can&#x27;t see the underlying error and won&#x27;t retry. Keep &lt;code&gt;FdbError&lt;&#x2F;code&gt; unwrapped in your transaction closures, or ensure your error type preserves retryability information.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Assuming setup is safe from failures.&lt;&#x2F;strong&gt; BUGGIFY is disabled during &lt;code&gt;setup()&lt;&#x2F;code&gt;, so you might think transactions can&#x27;t fail. But simulation randomizes FDB knobs, which can still cause transaction failures. Always use &lt;code&gt;db.run()&lt;&#x2F;code&gt; with retry logic even in setup, or wrap your setup in a retry loop.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-real-value&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#the-real-value&quot; aria-label=&quot;Anchor link for: the-real-value&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;The Real Value&lt;&#x2F;h2&gt;
&lt;p&gt;That &lt;code&gt;commit_unknown_result&lt;&#x2F;code&gt; edge case appeared on our first simulation seed. In production, we&#x27;d still be hunting it months later. But the real value of simulation testing isn&#x27;t just finding bugs, it&#x27;s &lt;strong&gt;forcing you to think about correctness.&lt;&#x2F;strong&gt; When you design a workload, you&#x27;re forced to ask: &quot;What happens when this retries during a partition?&quot; &quot;How do I verify correctness when transactions can commit in any order?&quot; &quot;What invariants must hold no matter what chaos occurs?&quot; Designing for chaos becomes natural. And if it survives simulation, it survives production.&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;p&gt;Feel free to reach out with questions or to share your simulation workloads. You can find me on &lt;a href=&quot;https:&#x2F;&#x2F;twitter.com&#x2F;PierreZ&quot;&gt;Twitter&lt;&#x2F;a&gt;, &lt;a href=&quot;https:&#x2F;&#x2F;bsky.app&#x2F;profile&#x2F;pierrezemb.fr&quot;&gt;Bluesky&lt;&#x2F;a&gt; or through my &lt;a href=&quot;https:&#x2F;&#x2F;pierrezemb.fr&quot;&gt;website&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>Diving into Kubernetes&#x27; Watch Cache</title>
        <published>2025-11-12T00:00:00+00:00</published>
        <updated>2025-11-12T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Pierre Zemb
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://pierrezemb.fr/posts/diving-into-kubernetes-watch-cache/"/>
        <id>https://pierrezemb.fr/posts/diving-into-kubernetes-watch-cache/</id>
        
        <category term="diving-into" schema="https://pierrezemb.fr/tags/" label="diving-into"/>
        <category term="kubernetes" schema="https://pierrezemb.fr/tags/" label="kubernetes"/>
        <category term="distributed-systems" schema="https://pierrezemb.fr/tags/" label="distributed-systems"/>
        <category term="etcd" schema="https://pierrezemb.fr/tags/" label="etcd"/>
        <category term="caching" schema="https://pierrezemb.fr/tags/" label="caching"/>
        <content type="html" xml:base="https://pierrezemb.fr/posts/diving-into-kubernetes-watch-cache/">&lt;hr &#x2F;&gt;
&lt;p&gt;&lt;a href=&quot;&#x2F;tags&#x2F;diving-into&#x2F;&quot;&gt;Diving Into&lt;&#x2F;a&gt; is a blogpost series where we dig into specific parts of a project&#x27;s codebase. In this episode, we dig into Kubernetes&#x27; watch cache implementation.&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;p&gt;While debugging an etcd-shim on FoundationDB, I kept hitting &lt;code&gt;&quot;Timeout: Too large resource version&quot;&lt;&#x2F;code&gt; errors. The cache was stuck at revision 3044, but clients requested 3047. Three seconds later: timeout. This led me into the watch cache internals: specifically the 3-second timeout in &lt;code&gt;waitUntilFreshAndBlock()&lt;&#x2F;code&gt; and how progress notifications solve the problem. Let&#x27;s dig into how it actually works.&lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;&#x2F;strong&gt; Yes, &lt;a href=&quot;https:&#x2F;&#x2F;clever.cloud&quot;&gt;Clever Cloud&lt;&#x2F;a&gt; runs an etcd-shim on top of FoundationDB for Kubernetes. Truth is, we&#x27;re not alone: &lt;a href=&quot;https:&#x2F;&#x2F;aws.amazon.com&#x2F;blogs&#x2F;containers&#x2F;under-the-hood-amazon-eks-ultra-scale-clusters&#x2F;&quot;&gt;AWS&lt;&#x2F;a&gt; and &lt;a href=&quot;https:&#x2F;&#x2F;cloud.google.com&#x2F;blog&#x2F;products&#x2F;containers-kubernetes&#x2F;gke-65k-nodes-and-counting?hl=en&quot;&gt;GKE&lt;&#x2F;a&gt; have custom storage layers too. After &lt;a href=&quot;https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=IrJyrGQ_R9c&quot;&gt;operating etcd at OVHcloud&lt;&#x2F;a&gt;, we chose a different path. I actually wrote a naive PoC during COVID (&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;PierreZ&#x2F;fdb-etcd&quot;&gt;fdb-etcd&lt;&#x2F;a&gt;) without testing it against a real apiserver ðŸ˜… it was mostly an excuse to discover &lt;a href=&quot;https:&#x2F;&#x2F;pierrez.github.io&#x2F;fdb-book&#x2F;the-record-layer&#x2F;what-is-record-layer.html&quot;&gt;the Record-Layer&lt;&#x2F;a&gt;. You can read more about the technical challenges in &lt;a href=&quot;https:&#x2F;&#x2F;forums.foundationdb.org&#x2F;t&#x2F;a-foundationdb-layer-for-apiserver-as-an-alternative-to-etcd&#x2F;2697&quot;&gt;this FoundationDB forum discussion&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;h2 id=&quot;overview-of-the-watch-cache&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#overview-of-the-watch-cache&quot; aria-label=&quot;Anchor link for: overview-of-the-watch-cache&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;Overview of the Watch Cache&lt;&#x2F;h2&gt;
&lt;p&gt;When I first looked at the watch cache implementation, I expected a single monolithic cache sitting between the apiserver and etcd. It took compiling my own apiserver with additional logging to realize the architecture is more interesting: &lt;strong&gt;each resource type gets its own independent Cacher instance&lt;&#x2F;strong&gt;. Pods have one. Services have another. Deployments get their own. Every resource group runs an isolated LIST+WATCH loop, maintaining its own in-memory cache.&lt;&#x2F;p&gt;
&lt;p&gt;As the &lt;a href=&quot;https:&#x2F;&#x2F;kubernetes.io&#x2F;blog&#x2F;2024&#x2F;08&#x2F;15&#x2F;consistent-read-from-cache-beta&#x2F;&quot;&gt;Kubernetes 1.34 blog post&lt;&#x2F;a&gt; explains, this enhancement allows the API server to serve consistent read requests directly from the watch cache, significantly reducing the load on etcd and improving overall cluster performance.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;architecture&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#architecture&quot; aria-label=&quot;Anchor link for: architecture&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;Architecture&lt;&#x2F;h2&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;Client Requests (kubectl, controllers)
&lt;&#x2F;span&gt;&lt;span&gt;          â†“
&lt;&#x2F;span&gt;&lt;span&gt;    Cacher (per resource)
&lt;&#x2F;span&gt;&lt;span&gt;          â†“ In-memory watch cache
&lt;&#x2F;span&gt;&lt;span&gt;          â†“ (on cache miss&#x2F;delegate)
&lt;&#x2F;span&gt;&lt;span&gt;    etcd3&#x2F;Store
&lt;&#x2F;span&gt;&lt;span&gt;          â†“
&lt;&#x2F;span&gt;&lt;span&gt;    etcd &#x2F; etcd-shim
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The main components:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kubernetes&#x2F;kubernetes&#x2F;blob&#x2F;release-1.34&#x2F;staging&#x2F;src&#x2F;k8s.io&#x2F;apiserver&#x2F;pkg&#x2F;storage&#x2F;cacher&#x2F;cacher.go&quot;&gt;cacher.go&lt;&#x2F;a&gt; - The in-memory watch cache&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kubernetes&#x2F;kubernetes&#x2F;blob&#x2F;release-1.34&#x2F;staging&#x2F;src&#x2F;k8s.io&#x2F;apiserver&#x2F;pkg&#x2F;storage&#x2F;etcd3&#x2F;store.go&quot;&gt;store.go&lt;&#x2F;a&gt; - Direct &lt;a href=&quot;&#x2F;posts&#x2F;notes-about-etcd&#x2F;&quot;&gt;etcd&lt;&#x2F;a&gt; communication layer&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;how-the-cache-gets-fed&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#how-the-cache-gets-fed&quot; aria-label=&quot;Anchor link for: how-the-cache-gets-fed&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;How The Cache Gets Fed&lt;&#x2F;h2&gt;
&lt;h3 id=&quot;initialization-the-list-phase&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#initialization-the-list-phase&quot; aria-label=&quot;Anchor link for: initialization-the-list-phase&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;Initialization: The LIST Phase&lt;&#x2F;h3&gt;
&lt;p&gt;&lt;strong&gt;Nothing works until the cache initializes&lt;&#x2F;strong&gt;. When a Cacher starts, every read for that resource blocks until initialization completes. This matters because initialization isn&#x27;t instant: it&#x27;s a paginated LIST operation fetching 10,000 items per page. For a large cluster with thousands of pods, this takes time.&lt;&#x2F;p&gt;
&lt;p&gt;Here&#x27;s the sequence: The Reflector pattern kicks off with a complete LIST operation. Each resource cache fetches all existing objects through paginated requests. Once the LIST completes, &lt;code&gt;watchCache.Replace()&lt;&#x2F;code&gt; populates the in-memory cache with these objects. The &lt;strong&gt;critical moment&lt;&#x2F;strong&gt; happens when the &lt;code&gt;SetOnReplace()&lt;&#x2F;code&gt; callback fires (&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kubernetes&#x2F;kubernetes&#x2F;blob&#x2F;release-1.34&#x2F;staging&#x2F;src&#x2F;k8s.io&#x2F;apiserver&#x2F;pkg&#x2F;storage&#x2F;cacher&#x2F;cacher.go#L468-L478&quot;&gt;cacher.go:468-478&lt;&#x2F;a&gt;), marking the cache as READY. Until that callback fires, every request for that resource waits.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;continuous-sync-the-watch-phase&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#continuous-sync-the-watch-phase&quot; aria-label=&quot;Anchor link for: continuous-sync-the-watch-phase&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;Continuous Sync: The WATCH Phase&lt;&#x2F;h3&gt;
&lt;p&gt;After initialization, the real trick begins: the cache maintains synchronization through a Watch stream that starts at LIST revision + 1. This &lt;strong&gt;guarantees no events are missed&lt;&#x2F;strong&gt; between the LIST and WATCH operations. The watch picks up exactly where the list left off. Events flow from etcd through a buffered channel (capacity: 100 events) and are processed by the &lt;code&gt;dispatchEvents()&lt;&#x2F;code&gt; goroutine, which runs continuously, matching events to interested watchers.&lt;&#x2F;p&gt;
&lt;p&gt;This pattern depends on continuous event flow. When events stop arriving, when resources go quiet, that&#x27;s when progress notifications become essential. See &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kubernetes&#x2F;kubernetes&#x2F;blob&#x2F;release-1.34&#x2F;staging&#x2F;src&#x2F;k8s.io&#x2F;client-go&#x2F;tools&#x2F;cache&#x2F;reflector.go&quot;&gt;Reflector documentation&lt;&#x2F;a&gt; for the complete pattern.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-problem-timeout-too-large-resource-version&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#the-problem-timeout-too-large-resource-version&quot; aria-label=&quot;Anchor link for: the-problem-timeout-too-large-resource-version&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;The Problem: &quot;Timeout: Too large resource version&quot;&lt;&#x2F;h2&gt;
&lt;p&gt;While debugging our etcd-shim, we kept hitting this error:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;Error getting keys: err=&amp;quot;Timeout: Too large resource version: 3047, current: 3044&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;A client was requesting ResourceVersion 3047, but the cache only knew about revision 3044. The cache would wait... and timeout after 3 seconds.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;understanding-cache-freshness&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#understanding-cache-freshness&quot; aria-label=&quot;Anchor link for: understanding-cache-freshness&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;Understanding Cache Freshness&lt;&#x2F;h2&gt;
&lt;h3 id=&quot;the-freshness-check&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#the-freshness-check&quot; aria-label=&quot;Anchor link for: the-freshness-check&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;The Freshness Check&lt;&#x2F;h3&gt;
&lt;p&gt;When a client requests a consistent read at a specific ResourceVersion, Kubernetes needs to ensure the cache is &quot;fresh enough&quot; to serve that request. Here&#x27;s the check: is my current revision at least as high as the requested revision? If not, it calls &lt;code&gt;waitUntilFreshAndBlock()&lt;&#x2F;code&gt; with a 3-second timeout, waiting for Watch events to bring the cache up to date.&lt;&#x2F;p&gt;
&lt;p&gt;From &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kubernetes&#x2F;kubernetes&#x2F;blob&#x2F;release-1.34&#x2F;staging&#x2F;src&#x2F;k8s.io&#x2F;apiserver&#x2F;pkg&#x2F;storage&#x2F;cacher&#x2F;cacher.go#L1257-L1261&quot;&gt;cacher.go:1257-1261&lt;&#x2F;a&gt;:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;go&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-go &quot;&gt;&lt;code class=&quot;language-go&quot; data-lang=&quot;go&quot;&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;if &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;c&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;watchCache&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;notFresh&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;requestedWatchRV&lt;&#x2F;span&gt;&lt;span&gt;) {
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;c&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;watchCache&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;waitingUntilFresh&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;Add&lt;&#x2F;span&gt;&lt;span&gt;()
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;defer &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;c&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;watchCache&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;waitingUntilFresh&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;Remove&lt;&#x2F;span&gt;&lt;span&gt;()
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;err &lt;&#x2F;span&gt;&lt;span&gt;:= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;c&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;watchCache&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;waitUntilFreshAndBlock&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;ctx&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;requestedWatchRV&lt;&#x2F;span&gt;&lt;span&gt;)
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The actual timeout implementation (&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kubernetes&#x2F;kubernetes&#x2F;blob&#x2F;release-1.34&#x2F;staging&#x2F;src&#x2F;k8s.io&#x2F;apiserver&#x2F;pkg&#x2F;storage&#x2F;cacher&#x2F;watch_cache.go#L448-L488&quot;&gt;watch_cache.go:448-488&lt;&#x2F;a&gt;):&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;go&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-go &quot;&gt;&lt;code class=&quot;language-go&quot; data-lang=&quot;go&quot;&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;func &lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;w &lt;&#x2F;span&gt;&lt;span&gt;*&lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;watchCache&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8fa1b3;&quot;&gt;waitUntilFreshAndBlock&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;ctx context&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;Context&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;resourceVersion &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;uint64&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;error &lt;&#x2F;span&gt;&lt;span&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;startTime &lt;&#x2F;span&gt;&lt;span&gt;:= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;w&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;clock&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;Now&lt;&#x2F;span&gt;&lt;span&gt;()
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;defer func&lt;&#x2F;span&gt;&lt;span&gt;() {
&lt;&#x2F;span&gt;&lt;span&gt;        &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;if &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;resourceVersion &lt;&#x2F;span&gt;&lt;span&gt;&amp;gt; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;0 &lt;&#x2F;span&gt;&lt;span&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;            &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;metrics&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;WatchCacheReadWait&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;WithContext&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;ctx&lt;&#x2F;span&gt;&lt;span&gt;).&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;WithLabelValues&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;w&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;groupResource&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;Group&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;w&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;groupResource&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;Resource&lt;&#x2F;span&gt;&lt;span&gt;).&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;Observe&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;w&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;clock&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;Since&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;startTime&lt;&#x2F;span&gt;&lt;span&gt;).&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;Seconds&lt;&#x2F;span&gt;&lt;span&gt;())
&lt;&#x2F;span&gt;&lt;span&gt;        }
&lt;&#x2F;span&gt;&lt;span&gt;    }()
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; In case resourceVersion is 0, we accept arbitrarily stale result.
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; As a result, the condition in the below for loop will never be
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; satisfied (w.resourceVersion is never negative), this call will
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; never hit the w.cond.Wait().
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; As a result - we can optimize the code by not firing the wakeup
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; function (and avoid starting a gorotuine), especially given that
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; resourceVersion=0 is the most common case.
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;if &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;resourceVersion &lt;&#x2F;span&gt;&lt;span&gt;&amp;gt; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;0 &lt;&#x2F;span&gt;&lt;span&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;        &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;go func&lt;&#x2F;span&gt;&lt;span&gt;() {
&lt;&#x2F;span&gt;&lt;span&gt;            &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; Wake us up when the time limit has expired.  The docs
&lt;&#x2F;span&gt;&lt;span&gt;            &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; promise that time.After (well, NewTimer, which it calls)
&lt;&#x2F;span&gt;&lt;span&gt;            &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; will wait *at least* the duration given. Since this go
&lt;&#x2F;span&gt;&lt;span&gt;            &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; routine starts sometime after we record the start time, and
&lt;&#x2F;span&gt;&lt;span&gt;            &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; it will wake up the loop below sometime after the broadcast,
&lt;&#x2F;span&gt;&lt;span&gt;            &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; we don&amp;#39;t need to worry about waking it up before the time
&lt;&#x2F;span&gt;&lt;span&gt;            &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; has expired accidentally.
&lt;&#x2F;span&gt;&lt;span&gt;            &amp;lt;-&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;w&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;clock&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;After&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;blockTimeout&lt;&#x2F;span&gt;&lt;span&gt;)
&lt;&#x2F;span&gt;&lt;span&gt;            &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;w&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;cond&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;Broadcast&lt;&#x2F;span&gt;&lt;span&gt;()
&lt;&#x2F;span&gt;&lt;span&gt;        }()
&lt;&#x2F;span&gt;&lt;span&gt;    }
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;w&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;RLock&lt;&#x2F;span&gt;&lt;span&gt;()
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;span &lt;&#x2F;span&gt;&lt;span&gt;:= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;tracing&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;SpanFromContext&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;ctx&lt;&#x2F;span&gt;&lt;span&gt;)
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;span&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;AddEvent&lt;&#x2F;span&gt;&lt;span&gt;(&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;watchCache locked acquired&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;)
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;for &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;w&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;resourceVersion &lt;&#x2F;span&gt;&lt;span&gt;&amp;lt; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;resourceVersion &lt;&#x2F;span&gt;&lt;span&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;        &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;if &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;w&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;clock&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;Since&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;startTime&lt;&#x2F;span&gt;&lt;span&gt;) &amp;gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;blockTimeout &lt;&#x2F;span&gt;&lt;span&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;            &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; Request that the client retry after &amp;#39;resourceVersionTooHighRetrySeconds&amp;#39; seconds.
&lt;&#x2F;span&gt;&lt;span&gt;            &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;return &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;storage&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;NewTooLargeResourceVersionError&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;resourceVersion&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;w&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;resourceVersion&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;resourceVersionTooHighRetrySeconds&lt;&#x2F;span&gt;&lt;span&gt;)
&lt;&#x2F;span&gt;&lt;span&gt;        }
&lt;&#x2F;span&gt;&lt;span&gt;        &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;w&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;cond&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;Wait&lt;&#x2F;span&gt;&lt;span&gt;()
&lt;&#x2F;span&gt;&lt;span&gt;    }
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;span&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;AddEvent&lt;&#x2F;span&gt;&lt;span&gt;(&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;watchCache fresh enough&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;)
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;return &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;nil
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;If the cache can&#x27;t catch up within those 3 seconds, the request times out.&lt;&#x2F;p&gt;
&lt;p&gt;If you&#x27;ve ever seen kubectl commands hang for exactly 3 seconds before returning data, this is why. The cache is waiting for events that will never come.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;the-problem-with-quiet-resources&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#the-problem-with-quiet-resources&quot; aria-label=&quot;Anchor link for: the-problem-with-quiet-resources&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;The Problem with Quiet Resources&lt;&#x2F;h3&gt;
&lt;p&gt;This is where things get tricky. For infrequently-updated resources (namespaces, configmaps, etc.):&lt;&#x2F;p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Time&lt;&#x2F;th&gt;&lt;th&gt;Component&lt;&#x2F;th&gt;&lt;th&gt;Event&lt;&#x2F;th&gt;&lt;th&gt;Cache RV&lt;&#x2F;th&gt;&lt;th&gt;etcd RV&lt;&#x2F;th&gt;&lt;th&gt;Notes&lt;&#x2F;th&gt;&lt;&#x2F;tr&gt;&lt;&#x2F;thead&gt;&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;T0&lt;&#x2F;td&gt;&lt;td&gt;Namespace cache&lt;&#x2F;td&gt;&lt;td&gt;Idle, no changes&lt;&#x2F;td&gt;&lt;td&gt;3044&lt;&#x2F;td&gt;&lt;td&gt;3044&lt;&#x2F;td&gt;&lt;td&gt;No namespace changes for 5 minutes&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;T1&lt;&#x2F;td&gt;&lt;td&gt;Pod&#x2F;Service caches&lt;&#x2F;td&gt;&lt;td&gt;Resources changing&lt;&#x2F;td&gt;&lt;td&gt;-&lt;&#x2F;td&gt;&lt;td&gt;3047&lt;&#x2F;td&gt;&lt;td&gt;Global etcd revision advances&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;T2&lt;&#x2F;td&gt;&lt;td&gt;Namespace watch&lt;&#x2F;td&gt;&lt;td&gt;Receives nothing&lt;&#x2F;td&gt;&lt;td&gt;3044&lt;&#x2F;td&gt;&lt;td&gt;3047&lt;&#x2F;td&gt;&lt;td&gt;No namespace events to process&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;T3&lt;&#x2F;td&gt;&lt;td&gt;Namespace cache&lt;&#x2F;td&gt;&lt;td&gt;Still waiting&lt;&#x2F;td&gt;&lt;td&gt;3044&lt;&#x2F;td&gt;&lt;td&gt;3047&lt;&#x2F;td&gt;&lt;td&gt;Cache stuck, unaware of global progress&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;T4&lt;&#x2F;td&gt;&lt;td&gt;Client&lt;&#x2F;td&gt;&lt;td&gt;Lists pods successfully&lt;&#x2F;td&gt;&lt;td&gt;-&lt;&#x2F;td&gt;&lt;td&gt;3047&lt;&#x2F;td&gt;&lt;td&gt;Response includes current RV 3047&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;T5&lt;&#x2F;td&gt;&lt;td&gt;Client&lt;&#x2F;td&gt;&lt;td&gt;Requests namespace read at RV â‰¥ 3047&lt;&#x2F;td&gt;&lt;td&gt;-&lt;&#x2F;td&gt;&lt;td&gt;3047&lt;&#x2F;td&gt;&lt;td&gt;Consistent read requirement&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;T6&lt;&#x2F;td&gt;&lt;td&gt;Namespace cache&lt;&#x2F;td&gt;&lt;td&gt;&lt;code&gt;waitUntilFreshAndBlock()&lt;&#x2F;code&gt;&lt;&#x2F;td&gt;&lt;td&gt;3044&lt;&#x2F;td&gt;&lt;td&gt;3047&lt;&#x2F;td&gt;&lt;td&gt;&quot;I&#x27;m at 3044, need 3047... waiting&quot;&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;T7&lt;&#x2F;td&gt;&lt;td&gt;Namespace cache&lt;&#x2F;td&gt;&lt;td&gt;Timeout!&lt;&#x2F;td&gt;&lt;td&gt;3044&lt;&#x2F;td&gt;&lt;td&gt;3047&lt;&#x2F;td&gt;&lt;td&gt;3 seconds elapsed, returns error&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;&#x2F;tbody&gt;&lt;&#x2F;table&gt;
&lt;p&gt;The cache has no way to know if etcd has moved forward. Is the system healthy? Is something broken? It just sees... nothing.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;timeout-behavior-summary&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#timeout-behavior-summary&quot; aria-label=&quot;Anchor link for: timeout-behavior-summary&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;Timeout Behavior Summary&lt;&#x2F;h3&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Scenario&lt;&#x2F;th&gt;&lt;th&gt;Cache RV&lt;&#x2F;th&gt;&lt;th&gt;Requested RV&lt;&#x2F;th&gt;&lt;th&gt;Result&lt;&#x2F;th&gt;&lt;&#x2F;tr&gt;&lt;&#x2F;thead&gt;&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;Fresh cache&lt;&#x2F;td&gt;&lt;td&gt;3047&lt;&#x2F;td&gt;&lt;td&gt;3045&lt;&#x2F;td&gt;&lt;td&gt;âœ“ Serve immediately&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;Stale cache&lt;&#x2F;td&gt;&lt;td&gt;3044&lt;&#x2F;td&gt;&lt;td&gt;3047&lt;&#x2F;td&gt;&lt;td&gt;â± Wait 3s â†’ timeout&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;With progress&lt;&#x2F;td&gt;&lt;td&gt;3044&lt;&#x2F;td&gt;&lt;td&gt;3047&lt;&#x2F;td&gt;&lt;td&gt;âœ“ RequestProgress â†’ serve&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;&#x2F;tbody&gt;&lt;&#x2F;table&gt;
&lt;h2 id=&quot;progress-notifications-keeping-quiet-resources-fresh&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#progress-notifications-keeping-quiet-resources-fresh&quot; aria-label=&quot;Anchor link for: progress-notifications-keeping-quiet-resources-fresh&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;Progress Notifications: Keeping Quiet Resources Fresh&lt;&#x2F;h2&gt;
&lt;h3 id=&quot;what-are-progress-notifications&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#what-are-progress-notifications&quot; aria-label=&quot;Anchor link for: what-are-progress-notifications&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;What Are Progress Notifications?&lt;&#x2F;h3&gt;
&lt;p&gt;Here&#x27;s the trick: progress notifications are &lt;strong&gt;empty Watch responses&lt;&#x2F;strong&gt; that only update the revision:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;go&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-go &quot;&gt;&lt;code class=&quot;language-go&quot; data-lang=&quot;go&quot;&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;WatchResponse &lt;&#x2F;span&gt;&lt;span&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;Header&lt;&#x2F;span&gt;&lt;span&gt;: { &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;Revision&lt;&#x2F;span&gt;&lt;span&gt;: &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;3047 &lt;&#x2F;span&gt;&lt;span&gt;},  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; Current etcd revision
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;Events&lt;&#x2F;span&gt;&lt;span&gt;: []                     &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; No actual data changes
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;They solve the quiet resource problem by telling the cache: &quot;etcd is now at revision X, even though your resource hasn&#x27;t changed.&quot;&lt;&#x2F;p&gt;
&lt;p&gt;This is exactly what we had forgotten to implement in our etcd-shim. We handled regular Watch events perfectly, but didn&#x27;t support progress notifications. The result? Kubernetes&#x27; watch cache would timeout waiting for revisions that would never arrive through normal events. Once we added &lt;code&gt;RequestProgress&lt;&#x2F;code&gt; support and started sending these empty bookmark responses, the timeouts disappeared.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;two-mechanisms&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#two-mechanisms&quot; aria-label=&quot;Anchor link for: two-mechanisms&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;Two Mechanisms&lt;&#x2F;h3&gt;
&lt;h4 id=&quot;1-on-demand-requestwatchprogress&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#1-on-demand-requestwatchprogress&quot; aria-label=&quot;Anchor link for: 1-on-demand-requestwatchprogress&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;1. On-Demand: RequestWatchProgress()&lt;&#x2F;h4&gt;
&lt;p&gt;When the cache needs to catch up, it can explicitly request a progress notification. See &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kubernetes&#x2F;kubernetes&#x2F;blob&#x2F;release-1.34&#x2F;staging&#x2F;src&#x2F;k8s.io&#x2F;apiserver&#x2F;pkg&#x2F;storage&#x2F;etcd3&#x2F;store.go#L99-L103&quot;&gt;store.go:99-103&lt;&#x2F;a&gt;:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;go&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-go &quot;&gt;&lt;code class=&quot;language-go&quot; data-lang=&quot;go&quot;&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;func &lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;s &lt;&#x2F;span&gt;&lt;span&gt;*&lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;store&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8fa1b3;&quot;&gt;RequestWatchProgress&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;ctx context&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;Context&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;error &lt;&#x2F;span&gt;&lt;span&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;return &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;s&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;client&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;RequestProgress&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;s&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;watchContext&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;ctx&lt;&#x2F;span&gt;&lt;span&gt;))
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;When called, etcd responds with a bookmark (also called a progress notification) containing the current revision. The cache at revision 3044 calls &lt;code&gt;RequestProgress()&lt;&#x2F;code&gt;, receives &lt;code&gt;{ Revision: 3047, Events: [] }&lt;&#x2F;code&gt;, and immediately updates its internal state to 3047.&lt;&#x2F;p&gt;
&lt;p&gt;The progress notification is detected in the watch stream (&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kubernetes&#x2F;kubernetes&#x2F;blob&#x2F;release-1.34&#x2F;staging&#x2F;src&#x2F;k8s.io&#x2F;apiserver&#x2F;pkg&#x2F;storage&#x2F;etcd3&#x2F;watcher.go#L401-L404&quot;&gt;watcher.go:401-404&lt;&#x2F;a&gt;):&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;go&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-go &quot;&gt;&lt;code class=&quot;language-go&quot; data-lang=&quot;go&quot;&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; Handle progress notifications (bookmarks)
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;if &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;wres&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;IsProgressNotify&lt;&#x2F;span&gt;&lt;span&gt;() {
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;wc&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;queueEvent&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;progressNotifyEvent&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;wres&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;Header&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;GetRevision&lt;&#x2F;span&gt;&lt;span&gt;()))
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;metrics&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;RecordEtcdBookmark&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;wc&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;watcher&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;groupResource&lt;&#x2F;span&gt;&lt;span&gt;)
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;continue
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h4 id=&quot;2-proactive-periodic-progress-requests&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#2-proactive-periodic-progress-requests&quot; aria-label=&quot;Anchor link for: 2-proactive-periodic-progress-requests&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;2. Proactive: Periodic Progress Requests&lt;&#x2F;h4&gt;
&lt;p&gt;Kubernetes also runs a background component called &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kubernetes&#x2F;kubernetes&#x2F;blob&#x2F;release-1.34&#x2F;staging&#x2F;src&#x2F;k8s.io&#x2F;apiserver&#x2F;pkg&#x2F;storage&#x2F;cacher&#x2F;cacher.go#L425-L428&quot;&gt;progressRequester&lt;&#x2F;a&gt; that monitors quiet watches. This component detects when watches haven&#x27;t received events for a while and periodically calls &lt;code&gt;RequestProgress()&lt;&#x2F;code&gt; to ensure even completely idle resources stay fresh. This proactive approach prevents timeout errors before they happen.&lt;&#x2F;p&gt;
&lt;p&gt;The progress requester is initialized when the Cacher is created (&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kubernetes&#x2F;kubernetes&#x2F;blob&#x2F;release-1.34&#x2F;staging&#x2F;src&#x2F;k8s.io&#x2F;apiserver&#x2F;pkg&#x2F;storage&#x2F;cacher&#x2F;cacher.go#L425-L428&quot;&gt;cacher.go:425-428&lt;&#x2F;a&gt;):&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;go&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-go &quot;&gt;&lt;code class=&quot;language-go&quot; data-lang=&quot;go&quot;&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;progressRequester &lt;&#x2F;span&gt;&lt;span&gt;:= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;progress&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;NewConditionalProgressRequester&lt;&#x2F;span&gt;&lt;span&gt;(
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;config&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;Storage&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;RequestWatchProgress&lt;&#x2F;span&gt;&lt;span&gt;,  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; The function to call
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;config&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;Clock&lt;&#x2F;span&gt;&lt;span&gt;,
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;contextMetadata
&lt;&#x2F;span&gt;&lt;span&gt;)
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;the-complete-flow&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#the-complete-flow&quot; aria-label=&quot;Anchor link for: the-complete-flow&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;The Complete Flow&lt;&#x2F;h2&gt;
&lt;p&gt;&lt;strong&gt;Timeline showing how progress notifications solve the timeout:&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Time&lt;&#x2F;th&gt;&lt;th&gt;Component&lt;&#x2F;th&gt;&lt;th&gt;Action&lt;&#x2F;th&gt;&lt;th&gt;Cache RV&lt;&#x2F;th&gt;&lt;th&gt;etcd RV&lt;&#x2F;th&gt;&lt;th&gt;Details&lt;&#x2F;th&gt;&lt;&#x2F;tr&gt;&lt;&#x2F;thead&gt;&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;T0&lt;&#x2F;td&gt;&lt;td&gt;Namespace watch&lt;&#x2F;td&gt;&lt;td&gt;Established&lt;&#x2F;td&gt;&lt;td&gt;3044&lt;&#x2F;td&gt;&lt;td&gt;3044&lt;&#x2F;td&gt;&lt;td&gt;No namespace changes happening&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;T1&lt;&#x2F;td&gt;&lt;td&gt;Pod resources&lt;&#x2F;td&gt;&lt;td&gt;Creates&#x2F;updates&lt;&#x2F;td&gt;&lt;td&gt;3044&lt;&#x2F;td&gt;&lt;td&gt;3047&lt;&#x2F;td&gt;&lt;td&gt;Namespace watch: silent, cache stuck at 3044&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;T2&lt;&#x2F;td&gt;&lt;td&gt;Client&lt;&#x2F;td&gt;&lt;td&gt;Requests namespace LIST at RV 3047&lt;&#x2F;td&gt;&lt;td&gt;3044&lt;&#x2F;td&gt;&lt;td&gt;3047&lt;&#x2F;td&gt;&lt;td&gt;&lt;code&gt;notFresh(3047)&lt;&#x2F;code&gt; â†’ true, starts &lt;code&gt;waitUntilFreshAndBlock()&lt;&#x2F;code&gt;&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;T3&lt;&#x2F;td&gt;&lt;td&gt;progressRequester&lt;&#x2F;td&gt;&lt;td&gt;Detects quiet watch&lt;&#x2F;td&gt;&lt;td&gt;3044&lt;&#x2F;td&gt;&lt;td&gt;3047&lt;&#x2F;td&gt;&lt;td&gt;Calls &lt;code&gt;RequestProgress()&lt;&#x2F;code&gt; on namespace watch stream&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;T4&lt;&#x2F;td&gt;&lt;td&gt;etcd&lt;&#x2F;td&gt;&lt;td&gt;Sends progress notification&lt;&#x2F;td&gt;&lt;td&gt;3044&lt;&#x2F;td&gt;&lt;td&gt;3047&lt;&#x2F;td&gt;&lt;td&gt;&lt;code&gt;WatchResponse { Header: { Revision: 3047 }, Events: [] }&lt;&#x2F;code&gt;&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;T5&lt;&#x2F;td&gt;&lt;td&gt;Namespace cache&lt;&#x2F;td&gt;&lt;td&gt;Processes bookmark&lt;&#x2F;td&gt;&lt;td&gt;3047&lt;&#x2F;td&gt;&lt;td&gt;3047&lt;&#x2F;td&gt;&lt;td&gt;Updates internal revision 3044 â†’ 3047, signals waiters&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;T6&lt;&#x2F;td&gt;&lt;td&gt;Namespace cache&lt;&#x2F;td&gt;&lt;td&gt;Returns successfully&lt;&#x2F;td&gt;&lt;td&gt;3047&lt;&#x2F;td&gt;&lt;td&gt;3047&lt;&#x2F;td&gt;&lt;td&gt;&lt;code&gt;waitUntilFreshAndBlock()&lt;&#x2F;code&gt; completes, request served from cache&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;&#x2F;tbody&gt;&lt;&#x2F;table&gt;
&lt;h2 id=&quot;key-takeaways&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#key-takeaways&quot; aria-label=&quot;Anchor link for: key-takeaways&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;Key Takeaways&lt;&#x2F;h2&gt;
&lt;p&gt;Here&#x27;s what you need to know: Kubernetes runs a separate watch cache for each resource type (pods, services, deployments, etc.), and each one maintains its own LIST+WATCH loop. When you request a consistent read, the cache performs a freshness check with a &lt;strong&gt;3-second timeout&lt;&#x2F;strong&gt; via &lt;code&gt;waitUntilFreshAndBlock()&lt;&#x2F;code&gt;. Without this mechanism, you&#x27;d see 3-second hangs on every consistent read to quiet resources.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Progress notifications&lt;&#x2F;strong&gt; solve the critical problem of quiet resources: those that don&#x27;t receive updates for extended periods. These empty Watch responses update the cache&#x27;s revision without transferring data. Kubernetes implements this through two mechanisms: &lt;strong&gt;on-demand&lt;&#x2F;strong&gt; (explicit RequestProgress calls when the cache needs to catch up) and &lt;strong&gt;proactive&lt;&#x2F;strong&gt; (periodic monitoring by the progressRequester component).&lt;&#x2F;p&gt;
&lt;p&gt;Without progress notifications, consistent reads must bypass the cache entirely and go directly to etcd, significantly increasing load on the storage layer. This is the difference between a responsive cluster and one where every kubectl command feels sluggish.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;related-posts&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#related-posts&quot; aria-label=&quot;Anchor link for: related-posts&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;Related Posts&lt;&#x2F;h2&gt;
&lt;p&gt;If you enjoyed this deep dive into Kubernetes watch caching, you might also be interested in:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;&#x2F;posts&#x2F;notes-about-etcd&#x2F;&quot;&gt;Notes about ETCD&lt;&#x2F;a&gt; - An overview and collection of resources about etcd, the distributed key-value store that powers Kubernetes&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;&#x2F;posts&#x2F;diving-into-etcd-linearizable&#x2F;&quot;&gt;Diving into ETCD&#x27;s linearizable reads&lt;&#x2F;a&gt; - A deep dive into how etcd implements linearizable reads using Raft consensus&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;hr &#x2F;&gt;
&lt;p&gt;Feel free to reach out with any questions or to share your experiences with Kubernetes watch caching. You can find me on &lt;a href=&quot;https:&#x2F;&#x2F;twitter.com&#x2F;PierreZ&quot;&gt;Twitter&lt;&#x2F;a&gt;, &lt;a href=&quot;https:&#x2F;&#x2F;bsky.app&#x2F;profile&#x2F;pierrezemb.fr&quot;&gt;Bluesky&lt;&#x2F;a&gt; or through my &lt;a href=&quot;https:&#x2F;&#x2F;pierrezemb.fr&quot;&gt;website&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>Diving into FoundationDB&#x27;s Simulation Framework</title>
        <published>2025-10-30T00:00:00+00:00</published>
        <updated>2025-10-30T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Pierre Zemb
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://pierrezemb.fr/posts/diving-into-foundationdb-simulation/"/>
        <id>https://pierrezemb.fr/posts/diving-into-foundationdb-simulation/</id>
        
        <category term="foundationdb" schema="https://pierrezemb.fr/tags/" label="foundationdb"/>
        <category term="testing" schema="https://pierrezemb.fr/tags/" label="testing"/>
        <category term="simulation" schema="https://pierrezemb.fr/tags/" label="simulation"/>
        <category term="deterministic" schema="https://pierrezemb.fr/tags/" label="deterministic"/>
        <category term="distributed-systems" schema="https://pierrezemb.fr/tags/" label="distributed-systems"/>
        <category term="diving-into" schema="https://pierrezemb.fr/tags/" label="diving-into"/>
        <content type="html" xml:base="https://pierrezemb.fr/posts/diving-into-foundationdb-simulation/">&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;&#x2F;tags&#x2F;diving-into&#x2F;&quot;&gt;Diving Into&lt;&#x2F;a&gt; is a blogpost series where we are digging a specific part of the project&#x27;s codebase. In this episode, we will dig into the implementation behind FoundationDB&#x27;s simulation framework.&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;p&gt;After years of on-call shifts running FoundationDB at Clever Cloud, here&#x27;s what I&#x27;ve learned: &lt;strong&gt;I&#x27;ve never been woken up by FDB&lt;&#x2F;strong&gt;. Every production incident traced back to our code, our infrastructure, our mistakes. Never FDB itself. That kind of reliability doesn&#x27;t happen by accident.&lt;&#x2F;p&gt;
&lt;p&gt;The secret? &lt;strong&gt;Deterministic simulation testing&lt;&#x2F;strong&gt;. FoundationDB runs the real database software (not mocks, not stubs) in a discrete-event simulator alongside randomized workloads and aggressive fault injection. All sources of nondeterminism are abstracted: network, disk, time, and random number generation. Multiple FDB servers communicate through a simulated network in a single-threaded process. The simulator injects machine crashes, rack failures, network partitions, disk corruption, bit flips. Every failure mode you can imagine, happening in rapid succession, deterministically. Same seed, same execution path, same bugs, every single time.&lt;&#x2F;p&gt;
&lt;p&gt;After roughly &lt;strong&gt;one trillion CPU-hours of simulation testing&lt;&#x2F;strong&gt;, FoundationDB has been stress-tested under conditions far worse than any production environment will ever encounter. The development environment is deliberately harsher than production: network partitions every few seconds, machine crashes mid-transaction, disks randomly swapped between nodes on reboot. If your code survives the simulator, production is easy.&lt;&#x2F;p&gt;
&lt;p&gt;I&#x27;ve written before about &lt;a href=&quot;&#x2F;posts&#x2F;notes-about-foundationdb&#x2F;&quot;&gt;FoundationDB&lt;&#x2F;a&gt;, &lt;a href=&quot;&#x2F;posts&#x2F;simulation-driven-development&#x2F;&quot;&gt;simulation-driven development&lt;&#x2F;a&gt;, and &lt;a href=&quot;&#x2F;posts&#x2F;testing-prevention-vs-discovery&#x2F;&quot;&gt;testing prevention vs discovery&lt;&#x2F;a&gt;. Those posts cover the concepts and benefits. This post is different: &lt;strong&gt;this is how FoundationDB actually implements deterministic simulation&lt;&#x2F;strong&gt;. Interface swapping, deterministic event loops, BUGGIFY chaos injection, Flow actors, and the architecture that makes it all work. We&#x27;re going deep into the implementation.&lt;&#x2F;p&gt;
&lt;div style=&quot;text-align: center;&quot;&gt;
  &lt;img src=&quot;&#x2F;images&#x2F;fdb-simulation-deep-dive&#x2F;simulator-architecture.jpeg&quot; alt=&quot;FoundationDB Simulator Architecture&quot; &#x2F;&gt;
  &lt;p&gt;&lt;em&gt;FoundationDB&#x27;s simulation architecture: the same FDB server code runs in both the simulator process (using simulated I&#x2F;O) and the real world (using real I&#x2F;O)&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;&#x2F;div&gt;
&lt;h2 id=&quot;the-trick-interface-swapping&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#the-trick-interface-swapping&quot; aria-label=&quot;Anchor link for: the-trick-interface-swapping&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;The Trick: Interface Swapping&lt;&#x2F;h2&gt;
&lt;p&gt;The genius of FDB&#x27;s simulation is surprisingly simple: &lt;strong&gt;the same code runs in both production and simulation by swapping interface implementations&lt;&#x2F;strong&gt;. The global &lt;code&gt;g_network&lt;&#x2F;code&gt; pointer holds an &lt;code&gt;INetwork&lt;&#x2F;code&gt; interface. In production, this points to &lt;code&gt;Net2&lt;&#x2F;code&gt;, which creates real TCP connections using Boost.ASIO. In simulation, it points to &lt;code&gt;Sim2&lt;&#x2F;code&gt; (&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;apple&#x2F;foundationdb&#x2F;blob&#x2F;dfbb0ea72ce01ba87148ef67cf216200e8b249cd&#x2F;fdbrpc&#x2F;sim2.actor.cpp&quot;&gt;sim2.actor.cpp&lt;&#x2F;a&gt;), which creates &lt;code&gt;Sim2Conn&lt;&#x2F;code&gt; objects (fake connections that write to in-memory buffers).&lt;&#x2F;p&gt;
&lt;p&gt;When code needs to send data, it gets a &lt;code&gt;Reference&amp;lt;IConnection&amp;gt;&lt;&#x2F;code&gt; from the network layer. In production, that&#x27;s a real socket. In simulation, it&#x27;s &lt;code&gt;Sim2Conn&lt;&#x2F;code&gt; (&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;apple&#x2F;foundationdb&#x2F;blob&#x2F;dfbb0ea72ce01ba87148ef67cf216200e8b249cd&#x2F;fdbrpc&#x2F;sim2.actor.cpp&quot;&gt;sim2.actor.cpp&lt;&#x2F;a&gt;) with a &lt;code&gt;std::deque&amp;lt;uint8_t&amp;gt;&lt;&#x2F;code&gt; buffer. Network latency? The simulator adds &lt;code&gt;delay()&lt;&#x2F;code&gt; calls with values from &lt;code&gt;deterministicRandom()&lt;&#x2F;code&gt;. Packet loss? Just throw &lt;code&gt;connection_failed()&lt;&#x2F;code&gt;. Network partition? &lt;code&gt;Sim2Conn&lt;&#x2F;code&gt; checks &lt;code&gt;g_clogging.disconnected()&lt;&#x2F;code&gt; and refuses delivery. &lt;strong&gt;It&#x27;s all just memory operations with delays&lt;&#x2F;strong&gt;, running single-threaded and completely deterministic.&lt;&#x2F;p&gt;
&lt;p&gt;What makes this truly deterministic is &lt;code&gt;deterministicRandom()&lt;&#x2F;code&gt;, a seeded PRNG that replaces all randomness. Every network latency value, every backoff delay (like the &lt;code&gt;Peer&lt;&#x2F;code&gt;&#x27;s exponential reconnection timing), every process crash timing goes through the same deterministic stream. Same seed, same execution path, every single time. When a test fails after 1 trillion simulated operations, you can reproduce the exact failure by running with the same seed.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;biasing-the-simulator-buggify&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#biasing-the-simulator-buggify&quot; aria-label=&quot;Anchor link for: biasing-the-simulator-buggify&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;Biasing the Simulator: BUGGIFY&lt;&#x2F;h3&gt;
&lt;p&gt;Most deep bugs need a rare combination of events. A network partition &lt;strong&gt;and&lt;&#x2F;strong&gt; a slow disk &lt;strong&gt;and&lt;&#x2F;strong&gt; a coordinator crash happening at the exact same moment. The probability of all three aligning randomly? Astronomical. You&#x27;d burn CPU-centuries waiting.&lt;&#x2F;p&gt;
&lt;p&gt;FoundationDB solves this with &lt;code&gt;BUGGIFY&lt;&#x2F;code&gt;, spread throughout the codebase. Each &lt;code&gt;BUGGIFY&lt;&#x2F;code&gt; point fires 25% of the time, deterministically, so every test explores a different corner of the state space (Alex Miller&#x27;s &lt;a href=&quot;https:&#x2F;&#x2F;transactional.blog&#x2F;simulation&#x2F;buggify&quot;&gt;excellent post on BUGGIFY&lt;&#x2F;a&gt; covers the implementation details).&lt;&#x2F;p&gt;
&lt;p&gt;Let&#x27;s take timeout handling in data distribution as an example:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;cpp&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-cpp &quot;&gt;&lt;code class=&quot;language-cpp&quot; data-lang=&quot;cpp&quot;&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; DDShardTracker.actor.cpp (fdbserver&#x2F;DDShardTracker.actor.cpp:1508)
&lt;&#x2F;span&gt;&lt;span&gt;choose {
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;when&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;wait&lt;&#x2F;span&gt;&lt;span&gt;(g_network-&amp;gt;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;isSimulated&lt;&#x2F;span&gt;&lt;span&gt;() &amp;amp;&amp;amp; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;BUGGIFY_WITH_PROB&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;0.01&lt;&#x2F;span&gt;&lt;span&gt;) ? &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;Never&lt;&#x2F;span&gt;&lt;span&gt;()
&lt;&#x2F;span&gt;&lt;span&gt;                                                          : &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;fetchTopKShardMetrics_impl&lt;&#x2F;span&gt;&lt;span&gt;(self, req))) {}
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;when&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;wait&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;delay&lt;&#x2F;span&gt;&lt;span&gt;(SERVER_KNOBS-&amp;gt;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;DD_SHARD_METRICS_TIMEOUT&lt;&#x2F;span&gt;&lt;span&gt;))) {
&lt;&#x2F;span&gt;&lt;span&gt;        &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; Timeout path
&lt;&#x2F;span&gt;&lt;span&gt;    }
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The &lt;code&gt;Never()&lt;&#x2F;code&gt; future never completes. Literally hangs forever. This happens only in simulation (&lt;code&gt;g_network-&amp;gt;isSimulated()&lt;&#x2F;code&gt;) and with 1% probability (&lt;code&gt;BUGGIFY_WITH_PROB(0.01)&lt;&#x2F;code&gt;). When it fires, the operation gets stuck, forcing the timeout branch to execute. Simple, elegant failure injection.&lt;&#x2F;p&gt;
&lt;p&gt;But here&#x27;s the trick: &lt;strong&gt;the timeout value itself is also buggified&lt;&#x2F;strong&gt;:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;cpp&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-cpp &quot;&gt;&lt;code class=&quot;language-cpp&quot; data-lang=&quot;cpp&quot;&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; ServerKnobs.cpp
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;init&lt;&#x2F;span&gt;&lt;span&gt;( DD_SHARD_METRICS_TIMEOUT, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;60.0 &lt;&#x2F;span&gt;&lt;span&gt;);  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; Production: 60 seconds
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;if&lt;&#x2F;span&gt;&lt;span&gt;( randomize &amp;amp;&amp;amp; BUGGIFY ) DD_SHARD_METRICS_TIMEOUT = &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;0.1&lt;&#x2F;span&gt;&lt;span&gt;;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; Simulation: 0.1 seconds!
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Production timeout: 60 seconds. BUGGIFY timeout: 0.1 seconds (600x shorter). The shrinking timeout window means legitimate operations are far more likely to hit timeout paths. Even without &lt;code&gt;Never()&lt;&#x2F;code&gt; forcing a hang, simulated network delays and slow operations will trigger timeouts constantly. When &lt;code&gt;Never()&lt;&#x2F;code&gt; does fire, you get guaranteed timeout execution. Every knob marked &lt;code&gt;if (randomize &amp;amp;&amp;amp; BUGGIFY)&lt;&#x2F;code&gt; becomes a chaos variable. Timeouts shrink, cache sizes drop, I&#x2F;O patterns randomize.&lt;&#x2F;p&gt;
&lt;p&gt;This creates &lt;strong&gt;combinatorial explosion&lt;&#x2F;strong&gt;. FoundationDB has hundreds of randomized knobs. Each BUGGIFY-enabled test run picks a different configuration: maybe connection monitors are 4x slower, but file I&#x2F;O is using 32KB blocks, and cache size is 1000 entries, and reconnection delays are doubled. The next run? Completely different knob values. Same code, thousands of different operating environments. After one trillion simulated operations across countless test runs, you&#x27;ve stress-tested your code under scenarios that would take decades to encounter in production.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-developer-workflow-simulation-as-ci-cd&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#the-developer-workflow-simulation-as-ci-cd&quot; aria-label=&quot;Anchor link for: the-developer-workflow-simulation-as-ci-cd&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;The Developer Workflow: Simulation as CI&#x2F;CD&lt;&#x2F;h2&gt;
&lt;p&gt;Here&#x27;s the FoundationDB developer experience: &lt;strong&gt;write code, run a few local simulation tests to catch obvious bugs, submit your merge request, then let the machines do the hard work&lt;&#x2F;strong&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;Every pull request triggers &lt;strong&gt;hundreds of thousands of simulation tests&lt;&#x2F;strong&gt; running on hundreds of cores for hours before a human even begins code review. Different seeds explore different execution paths, different failure timings, different BUGGIFY configurations. Nightly testing runs tens of thousands more simulations, crawling through edge cases you&#x27;d never think to test manually.&lt;&#x2F;p&gt;
&lt;p&gt;In the early days when FoundationDB was still a company, they took this philosophy to its logical extreme: &lt;strong&gt;merge requests were automatically merged if simulation passed&lt;&#x2F;strong&gt;. No human approval needed. The simulation was so trusted that passing tests meant the code was production-ready. (You can hear more about FoundationDB&#x27;s early development culture on &lt;a href=&quot;https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=C1nZzQqcPZw&amp;amp;list=PLh4UhOpNuTJO1S8xkfa3QmQzJemsUhuL8&amp;amp;index=6&quot;&gt;The BugBash Podcast&lt;&#x2F;a&gt;).&lt;&#x2F;p&gt;
&lt;p&gt;This changes how you think about distributed systems development. Instead of spending hours debugging race conditions or trying to mentally model all possible failure scenarios, you focus on building features. The simulation finds the edge cases. It discovers the bugs you&#x27;d never anticipate. It stress-tests your code under conditions that would take years to encounter in production.&lt;&#x2F;p&gt;
&lt;p&gt;The scale ramps up through the development cycle: thousands of seeds during merge request testing, tens of thousands in nightly runs, potentially millions during major release cycles. Each seed represents a completely different execution path through your code. By the time your change reaches production, it&#x27;s survived more chaos than most distributed systems see in their entire lifetime.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;The confidence this gives developers is extraordinary&lt;&#x2F;strong&gt;: if your code survives hundreds of thousands of simulated disasters, production feels easy in comparison.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;flow-actors-and-cooperative-multitasking&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#flow-actors-and-cooperative-multitasking&quot; aria-label=&quot;Anchor link for: flow-actors-and-cooperative-multitasking&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;Flow: Actors and Cooperative Multitasking&lt;&#x2F;h2&gt;
&lt;p&gt;FoundationDB doesn&#x27;t use traditional threads. It uses Flow, a custom actor model built on C++. Here&#x27;s a simple example:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;cpp&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-cpp &quot;&gt;&lt;code class=&quot;language-cpp&quot; data-lang=&quot;cpp&quot;&gt;&lt;span&gt;ACTOR Future&amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;int&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8fa1b3;&quot;&gt;asyncAdd&lt;&#x2F;span&gt;&lt;span&gt;(Future&amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;int&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;f&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;int &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;offset&lt;&#x2F;span&gt;&lt;span&gt;) {
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;int&lt;&#x2F;span&gt;&lt;span&gt; value = &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;wait&lt;&#x2F;span&gt;&lt;span&gt;(f);  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; Suspend until f completes, then resume with its value
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;return&lt;&#x2F;span&gt;&lt;span&gt; value + offset;
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The &lt;code&gt;ACTOR&lt;&#x2F;code&gt; keyword marks functions that can use &lt;code&gt;wait()&lt;&#x2F;code&gt;. When you call &lt;code&gt;wait(f)&lt;&#x2F;code&gt;, the actor &lt;strong&gt;suspends&lt;&#x2F;strong&gt;. It returns control to the event loop and resumes later when the &lt;code&gt;Future&lt;&#x2F;code&gt; completes, continuing with the result. No blocking. All asynchronous. Use the &lt;code&gt;state&lt;&#x2F;code&gt; keyword for variables that need to persist across multiple &lt;code&gt;wait()&lt;&#x2F;code&gt; calls.&lt;&#x2F;p&gt;
&lt;p&gt;If you know Rust&#x27;s async&#x2F;await, Flow is the same concept. &lt;code&gt;ACTOR&lt;&#x2F;code&gt; functions are like &lt;code&gt;async fn&lt;&#x2F;code&gt;, &lt;code&gt;wait()&lt;&#x2F;code&gt; is like &lt;code&gt;.await&lt;&#x2F;code&gt;, and &lt;code&gt;Future&amp;lt;T&amp;gt;&lt;&#x2F;code&gt; is like Rust&#x27;s &lt;code&gt;Future&lt;&#x2F;code&gt;. The difference? Flow was built in 2009 for C++, and gets compiled by &lt;code&gt;actorcompiler.h&lt;&#x2F;code&gt; into state machines rather than relying on language support.&lt;&#x2F;p&gt;
&lt;p&gt;The same Flow code runs in both production and simulation. An actor waiting for network I&#x2F;O gets a real socket in production, a simulated buffer in simulation. The code doesn&#x27;t know the difference. The Flow documentation at &lt;a href=&quot;https:&#x2F;&#x2F;apple.github.io&#x2F;foundationdb&#x2F;flow.html&quot;&gt;apple.github.io&#x2F;foundationdb&#x2F;flow.html&lt;&#x2F;a&gt; covers the full programming model.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;single-threaded-time-travel-the-event-loop&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#single-threaded-time-travel-the-event-loop&quot; aria-label=&quot;Anchor link for: single-threaded-time-travel-the-event-loop&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;Single-Threaded Time Travel: The Event Loop&lt;&#x2F;h2&gt;
&lt;p&gt;Hundreds of actors running concurrently. Coordinators electing leaders, transaction logs replicating commits, storage servers handling reads. All happening in &lt;strong&gt;one thread&lt;&#x2F;strong&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;The trick is cooperative multitasking. Actors yield control with &lt;code&gt;wait()&lt;&#x2F;code&gt;. When all actors are waiting, the event loop can &lt;strong&gt;advance simulated time&lt;&#x2F;strong&gt;:&lt;&#x2F;p&gt;
&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;pre class=&quot;mermaid&quot;&gt;
        flowchart TD
    Start([Event Loop]) --&amp;gt; CheckReady{Any actors&amp;lt;br&amp;#x2F;&amp;gt;ready to run?}
    CheckReady --&amp;gt;|Yes| RunActor[Run next ready actor&amp;lt;br&amp;#x2F;&amp;gt;until it hits wait]
    RunActor --&amp;gt; CheckReady
    CheckReady --&amp;gt;|No, all waiting| CheckPending{Any pending&amp;lt;br&amp;#x2F;&amp;gt;futures?}
    CheckPending --&amp;gt;|Yes| AdvanceTime[Advance simulated clock&amp;lt;br&amp;#x2F;&amp;gt;to next event]
    AdvanceTime --&amp;gt; CheckReady
    CheckPending --&amp;gt;|No| Done([Simulation complete])
    &lt;&#x2F;pre&gt;
&lt;&#x2F;div&gt;
&lt;p&gt;Here&#x27;s the key insight: when all actors are blocked waiting on futures, the event loop finds the next scheduled event (the earliest timestamp) and &lt;strong&gt;jumps the simulated clock forward&lt;&#x2F;strong&gt; to that time. Then it wakes the actors waiting for that event and runs them until they &lt;code&gt;wait()&lt;&#x2F;code&gt; again.&lt;&#x2F;p&gt;
&lt;p&gt;Example: 100 storage servers each execute &lt;code&gt;wait(delay(deterministicRandom()-&amp;gt;random01() * 60.0))&lt;&#x2F;code&gt;. In wall-clock time, this takes microseconds. In simulated time, these delays are spread across 60 seconds. The event loop processes them in order, advancing time as it goes. &lt;strong&gt;Zero wall-clock time has passed. 60 simulated seconds have passed.&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;This gives you:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Compressed time&lt;&#x2F;strong&gt;: Years of uptime in seconds of testing. &lt;code&gt;wait(delay(86400.0))&lt;&#x2F;code&gt; simulates 24 hours instantly.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Perfect determinism&lt;&#x2F;strong&gt;: Single-threaded execution means no race conditions. Same seed, same event ordering, exact same execution path.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Reproducibility&lt;&#x2F;strong&gt;: Test fails after 1 trillion simulated operations? Run again with the same seed, get the exact same failure at the exact same point.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;No actor ever blocks. They all cooperate, yielding control back to the event loop. This is the foundation that makes realistic cluster simulation possible.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;building-the-simulated-cluster&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#building-the-simulated-cluster&quot; aria-label=&quot;Anchor link for: building-the-simulated-cluster&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;Building the Simulated Cluster&lt;&#x2F;h2&gt;
&lt;p&gt;Now that we understand Flow actors and the event loop, let&#x27;s see what runs on it. SimulatedCluster &lt;strong&gt;builds an entire distributed cluster in memory&lt;&#x2F;strong&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;code&gt;SimulatedCluster&lt;&#x2F;code&gt; starts by generating a random cluster configuration: 1-5 datacenters, 1-10+ machines per DC, different storage engines (memory, ssd, redwood-1), different replication modes (single, double, triple). Every test run gets a different topology.&lt;&#x2F;p&gt;
&lt;p&gt;The actor hierarchy looks like this: SimulatedCluster creates machine actors (&lt;code&gt;simulatedMachine&lt;&#x2F;code&gt;). Each machine actor creates process actors (&lt;code&gt;simulatedFDBDRebooter&lt;&#x2F;code&gt;). Each process actor runs &lt;strong&gt;actual fdbserver code&lt;&#x2F;strong&gt;. The machine actor sits in an infinite loop: wait for all processes to die, delay 10 simulated seconds, reboot.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;The same fdbserver code that runs in production runs here&lt;&#x2F;strong&gt;. No mocks. No stubs. Real transaction logs writing to simulated disk. Real storage engines (RocksDB, Redwood). Real Paxos consensus. The only difference? &lt;code&gt;Sim2&lt;&#x2F;code&gt; network instead of &lt;code&gt;Net2&lt;&#x2F;code&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;And of course, BUGGIFY shows up here too. Remember how BUGGIFY shrinks timeouts and injects failures? It also does something &lt;strong&gt;completely insane&lt;&#x2F;strong&gt; during machine reboots. When a machine reboots, the simulator can &lt;strong&gt;swap its disks&lt;&#x2F;strong&gt;:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;cpp&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-cpp &quot;&gt;&lt;code class=&quot;language-cpp&quot; data-lang=&quot;cpp&quot;&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; SimulatedCluster.actor.cpp - machine reboot
&lt;&#x2F;span&gt;&lt;span&gt;state &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;bool&lt;&#x2F;span&gt;&lt;span&gt; swap = killType == ISimulator::KillType::Reboot &amp;amp;&amp;amp;
&lt;&#x2F;span&gt;&lt;span&gt;                  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;BUGGIFY_WITH_PROB&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;0.75&lt;&#x2F;span&gt;&lt;span&gt;) &amp;amp;&amp;amp;
&lt;&#x2F;span&gt;&lt;span&gt;                  g_simulator-&amp;gt;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;canSwapToMachine&lt;&#x2F;span&gt;&lt;span&gt;(localities.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;zoneId&lt;&#x2F;span&gt;&lt;span&gt;());
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;if &lt;&#x2F;span&gt;&lt;span&gt;(swap) {
&lt;&#x2F;span&gt;&lt;span&gt;    availableFolders[localities.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;dcId&lt;&#x2F;span&gt;&lt;span&gt;()].&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;push_back&lt;&#x2F;span&gt;&lt;span&gt;(myFolders);  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; Return my disks to pool
&lt;&#x2F;span&gt;&lt;span&gt;    myFolders = availableFolders[localities.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;dcId&lt;&#x2F;span&gt;&lt;span&gt;()][randomIndex];  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; Get random disks from pool
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;75% of the time when BUGGIFY is enabled, a rebooting machine gets &lt;strong&gt;random disks from the datacenter pool&lt;&#x2F;strong&gt;. Maybe it gets its own disks back. Maybe it gets another machine&#x27;s disks with completely different data. Maybe it gets the disks from a machine that was destroyed 10 minutes ago. Your storage server just woke up with someone else&#x27;s data (or no data at all). Can the cluster handle this? Can it detect the mismatch and rebuild correctly?&lt;&#x2F;p&gt;
&lt;p&gt;For extra chaos, there&#x27;s also &lt;code&gt;RebootAndDelete&lt;&#x2F;code&gt; which gives the machine &lt;strong&gt;brand new empty folders&lt;&#x2F;strong&gt;. No data. Fresh disks. This tests the actual failure mode of replacing a dead drive or provisioning a new machine.&lt;&#x2F;p&gt;
&lt;p&gt;Read that again. During testing, FoundationDB &lt;strong&gt;randomly swaps or deletes storage server data on reboot&lt;&#x2F;strong&gt;. If your distributed database doesn&#x27;t assume storage servers occasionally come back with amnesia or someone else&#x27;s memories, you&#x27;re not testing the real world. Because surely, no one has ever accidentally mounted the wrong volume in a Kubernetes deployment, right?&lt;&#x2F;p&gt;
&lt;p&gt;What you get from all this:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Real cluster behavior&lt;&#x2F;strong&gt;: Coordinators elect leaders, transaction logs replicate commits, storage servers handle reads&#x2F;writes, backup agents run&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Real failure modes&lt;&#x2F;strong&gt;: Process crashes, machine reboots, network partitions (via &lt;code&gt;g_clogging&lt;&#x2F;code&gt;), slow disks (via &lt;code&gt;AsyncFileNonDurable&lt;&#x2F;code&gt;), disk swaps, data loss&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Realistic topologies&lt;&#x2F;strong&gt;: Multi-region configurations, different storage engines, different replication modes, different machine counts&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;When you run a simulation test, SimulatedCluster boots this entire virtual cluster, lets it stabilize, runs workloads against it while injecting chaos, then validates correctness.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;workloads-stress-testing-under-chaos&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#workloads-stress-testing-under-chaos&quot; aria-label=&quot;Anchor link for: workloads-stress-testing-under-chaos&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;Workloads: Stress Testing Under Chaos&lt;&#x2F;h2&gt;
&lt;p&gt;30 seconds. 2500 transactions per second. Concurrent machines swapping edges in a distributed data structure while chaos engines inject failures. Let&#x27;s see if the database survives.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;Simulation Overview
&lt;&#x2F;span&gt;&lt;span&gt;â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
&lt;&#x2F;span&gt;&lt;span&gt;â”‚ Seed       â”† Replication      â”† Simulated Time â”† Real Time       â”† Storage Engine â”‚
&lt;&#x2F;span&gt;&lt;span&gt;â•žâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
&lt;&#x2F;span&gt;&lt;span&gt;â”‚ 1876983470 â”† triple           â”† 5m 47s         â”† 18s 891ms       â”† ssd-2          â”‚
&lt;&#x2F;span&gt;&lt;span&gt;â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;Timeline of Chaos Events
&lt;&#x2F;span&gt;&lt;span&gt;â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
&lt;&#x2F;span&gt;&lt;span&gt;â”‚ Time (s) â”† Event Type         â”† Details                              â”‚
&lt;&#x2F;span&gt;&lt;span&gt;â•žâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
&lt;&#x2F;span&gt;&lt;span&gt;â”‚ 87.234   â”† Coordinator Change â”† Triggering leader election           â”‚
&lt;&#x2F;span&gt;&lt;span&gt;â”‚ 92.156   â”† Process Reboot     â”† KillInstantly process at 10.0.4.2:3  â”‚
&lt;&#x2F;span&gt;&lt;span&gt;â”‚ 92.156   â”† Process Reboot     â”† KillInstantly process at 10.0.4.2:1  â”‚
&lt;&#x2F;span&gt;&lt;span&gt;â”‚ 95.871   â”† Coordinator Change â”† Triggering leader election           â”‚
&lt;&#x2F;span&gt;&lt;span&gt;â”‚ 103.445  â”† Process Reboot     â”† RebootAndDelete process at 10.0.2.1:4â”‚
&lt;&#x2F;span&gt;&lt;span&gt;â”‚ 103.445  â”† Process Reboot     â”† RebootAndDelete process at 10.0.2.1:2â”‚
&lt;&#x2F;span&gt;&lt;span&gt;â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;Chaos Summary
&lt;&#x2F;span&gt;&lt;span&gt;  Network Partitions: 187 events (max duration: 5.2s)
&lt;&#x2F;span&gt;&lt;span&gt;  Process Kills: 2 KillInstantly, 2 RebootAndDelete
&lt;&#x2F;span&gt;&lt;span&gt;  Coordinator Changes: 2
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;&lt;strong&gt;The cluster survived.&lt;&#x2F;strong&gt; 187 network partitions. 4 process kills. 2 coordinator changes. 5 minutes of simulated time compressed into 18 seconds of wall-clock time. Every transaction completed correctly. The cycle invariant never broke.&lt;&#x2F;p&gt;
&lt;p&gt;How did we unleash this chaos? Here&#x27;s the test configuration:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;toml&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-toml &quot;&gt;&lt;code class=&quot;language-toml&quot; data-lang=&quot;toml&quot;&gt;&lt;span&gt;[configuration]
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;buggify &lt;&#x2F;span&gt;&lt;span&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;true
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;minimumReplication &lt;&#x2F;span&gt;&lt;span&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;3
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;[[test]]
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;testTitle &lt;&#x2F;span&gt;&lt;span&gt;= &amp;#39;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;CycleWithAttrition&lt;&#x2F;span&gt;&lt;span&gt;&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    [[test.workload]]
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;testName &lt;&#x2F;span&gt;&lt;span&gt;= &amp;#39;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Cycle&lt;&#x2F;span&gt;&lt;span&gt;&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;testDuration &lt;&#x2F;span&gt;&lt;span&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;30.0
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;transactionsPerSecond &lt;&#x2F;span&gt;&lt;span&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;2500.0
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    [[test.workload]]
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;testName &lt;&#x2F;span&gt;&lt;span&gt;= &amp;#39;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;RandomClogging&lt;&#x2F;span&gt;&lt;span&gt;&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;testDuration &lt;&#x2F;span&gt;&lt;span&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;30.0
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    [[test.workload]]
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;testName &lt;&#x2F;span&gt;&lt;span&gt;= &amp;#39;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Attrition&lt;&#x2F;span&gt;&lt;span&gt;&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;testDuration &lt;&#x2F;span&gt;&lt;span&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;30.0
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    [[test.workload]]
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;testName &lt;&#x2F;span&gt;&lt;span&gt;= &amp;#39;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Rollback&lt;&#x2F;span&gt;&lt;span&gt;&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;testDuration &lt;&#x2F;span&gt;&lt;span&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;30.0
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h3 id=&quot;what-just-happened&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#what-just-happened&quot; aria-label=&quot;Anchor link for: what-just-happened&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;What Just Happened?&lt;&#x2F;h3&gt;
&lt;p&gt;Four concurrent workloads ran on the same simulated cluster for 30 seconds. &lt;strong&gt;Workloads&lt;&#x2F;strong&gt; are reusable scenario templates (180+ built-in in &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;apple&#x2F;foundationdb&#x2F;tree&#x2F;dfbb0ea72ce01ba87148ef67cf216200e8b249cd&#x2F;fdbserver&#x2F;workloads&quot;&gt;fdbserver&#x2F;workloads&#x2F;&lt;&#x2F;a&gt;) that either generate transactions or inject chaos.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;The application workload&lt;&#x2F;strong&gt; we ran:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Cycle&lt;&#x2F;strong&gt; (&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;apple&#x2F;foundationdb&#x2F;blob&#x2F;dfbb0ea72ce01ba87148ef67cf216200e8b249cd&#x2F;fdbserver&#x2F;workloads&#x2F;Cycle.actor.cpp&quot;&gt;Cycle.actor.cpp&lt;&#x2F;a&gt;): Hammered the database with 2500 transactions&#x2F;second, each one swapping edges in a distributed graph. Tests SERIALIZABLE isolation by maintaining a cycle invariant. If isolation breaks, the cycle splits or nodes vanish. We&#x27;ll dive deep into how this works below.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;&lt;strong&gt;The chaos workloads&lt;&#x2F;strong&gt; that tried to break it:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;RandomClogging&lt;&#x2F;strong&gt; (&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;apple&#x2F;foundationdb&#x2F;blob&#x2F;dfbb0ea72ce01ba87148ef67cf216200e8b249cd&#x2F;fdbserver&#x2F;workloads&#x2F;RandomClogging.actor.cpp&quot;&gt;RandomClogging.actor.cpp&lt;&#x2F;a&gt;): Calls &lt;code&gt;g_simulator-&amp;gt;clogInterface(ip, duration)&lt;&#x2F;code&gt; to partition machines. Those &lt;strong&gt;187 network partitions&lt;&#x2F;strong&gt; we saw? This workload. Some lasted over 5 seconds.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Attrition&lt;&#x2F;strong&gt; (&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;apple&#x2F;foundationdb&#x2F;blob&#x2F;dfbb0ea72ce01ba87148ef67cf216200e8b249cd&#x2F;fdbserver&#x2F;workloads&#x2F;MachineAttrition.actor.cpp&quot;&gt;MachineAttrition.actor.cpp&lt;&#x2F;a&gt;): Calls &lt;code&gt;g_simulator-&amp;gt;killMachine()&lt;&#x2F;code&gt; and &lt;code&gt;g_simulator-&amp;gt;rebootMachine()&lt;&#x2F;code&gt;. The &lt;strong&gt;4 process kills&lt;&#x2F;strong&gt; (2 instant, 2 with deleted data)? This workload.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Rollback&lt;&#x2F;strong&gt; (&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;apple&#x2F;foundationdb&#x2F;blob&#x2F;dfbb0ea72ce01ba87148ef67cf216200e8b249cd&#x2F;fdbserver&#x2F;workloads&#x2F;Rollback.actor.cpp&quot;&gt;Rollback.actor.cpp&lt;&#x2F;a&gt;): Forces proxy-to-TLog failures, triggering coordinator recovery. The &lt;strong&gt;2 coordinator changes&lt;&#x2F;strong&gt;? This workload.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Workloads are composable. The TOML format lets you stack them: &lt;code&gt;[configuration]&lt;&#x2F;code&gt; sets global parameters (BUGGIFY, replication), each &lt;code&gt;[[test.workload]]&lt;&#x2F;code&gt; adds another concurrent workload. Want to test atomic operations under network partitions? Stack &lt;code&gt;AtomicOps&lt;&#x2F;code&gt; + &lt;code&gt;RandomClogging&lt;&#x2F;code&gt;. Want to test backup during machine failures? Combine &lt;code&gt;BackupToBlob&lt;&#x2F;code&gt; + &lt;code&gt;Attrition&lt;&#x2F;code&gt;. Test files live in &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;apple&#x2F;foundationdb&#x2F;tree&#x2F;dfbb0ea72ce01ba87148ef67cf216200e8b249cd&#x2F;tests&quot;&gt;tests&#x2F;&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;how-does-cycle-work&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#how-does-cycle-work&quot; aria-label=&quot;Anchor link for: how-does-cycle-work&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;How Does Cycle Work?&lt;&#x2F;h3&gt;
&lt;p&gt;Remember that test we just ran? Let&#x27;s break down how the &lt;code&gt;Cycle&lt;&#x2F;code&gt; workload actually works. It creates a directed graph where every node points to exactly one other node, forming a single cycle: &lt;code&gt;0â†’1â†’2â†’...â†’Nâ†’0&lt;&#x2F;code&gt;. Then it runs 2500 concurrent transactions per second, each one randomly swapping edges in the graph. Meanwhile, chaos workloads kill machines, partition the network, and force coordinator changes. &lt;strong&gt;If SERIALIZABLE isolation works correctly, the cycle never breaks&lt;&#x2F;strong&gt;. You always have exactly N nodes in one ring, never split cycles or dangling pointers.&lt;&#x2F;p&gt;
&lt;p&gt;Every workload implements four phases (&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;apple&#x2F;foundationdb&#x2F;blob&#x2F;dfbb0ea72ce01ba87148ef67cf216200e8b249cd&#x2F;fdbserver&#x2F;include&#x2F;fdbserver&#x2F;workloads&#x2F;workloads.actor.h&quot;&gt;workloads.actor.h&lt;&#x2F;a&gt;):&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;SETUP&lt;&#x2F;strong&gt; (&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;apple&#x2F;foundationdb&#x2F;blob&#x2F;dfbb0ea72ce01ba87148ef67cf216200e8b249cd&#x2F;fdbserver&#x2F;workloads&#x2F;Cycle.actor.cpp&quot;&gt;Cycle.actor.cpp&lt;&#x2F;a&gt;): Creates &lt;code&gt;nodeCount&lt;&#x2F;code&gt; nodes. Each key stores the index of the next node in the cycle. Key 0 â†’ value 1, key 1 â†’ value 2, ..., key N-1 â†’ value 0.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;EXECUTION&lt;&#x2F;strong&gt;: Multiple concurrent &lt;code&gt;cycleClient&lt;&#x2F;code&gt; actors run this loop:&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;Pick random node &lt;code&gt;r&lt;&#x2F;code&gt;&lt;&#x2F;li&gt;
&lt;li&gt;Read three hops: &lt;code&gt;râ†’r2â†’r3â†’r4&lt;&#x2F;code&gt;&lt;&#x2F;li&gt;
&lt;li&gt;Swap the middle two edges: make &lt;code&gt;râ†’r3&lt;&#x2F;code&gt; and &lt;code&gt;r2â†’r4&lt;&#x2F;code&gt;&lt;&#x2F;li&gt;
&lt;li&gt;Commit&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;This transaction reads 3 keys and writes 2. If isolation breaks, you could create cycles of the wrong length or lose nodes entirely.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;CHECK&lt;&#x2F;strong&gt;: One client reads the entire graph in a single transaction. Starting from node 0, follow pointers: 0â†’nextâ†’nextâ†’next. Count the hops. After exactly &lt;code&gt;nodeCount&lt;&#x2F;code&gt; hops, you must be back at node 0. If you get there earlier (cycle too short) or can&#x27;t get there (broken chain), the test fails. Also verifies transaction throughput met the expected rate.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;METRICS&lt;&#x2F;strong&gt;: Reports transactions completed, retry counts, latency percentiles.&lt;&#x2F;p&gt;
&lt;p&gt;This is the pattern all workloads follow: SETUP initializes data, EXECUTION generates load, CHECK verifies correctness, METRICS reports results. When you execute a test, SimulatedCluster boots the cluster, runs SETUP phases sequentially, then runs all EXECUTION phases concurrently (they&#x27;re Flow actors on the same event loop). After &lt;code&gt;testDuration&lt;&#x2F;code&gt;, CHECK phases verify correctness.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;This is what runs before every FoundationDB commit.&lt;&#x2F;strong&gt; Not once. Not a few times. Thousands of test runs with different seeds, different cluster configurations, different workload combinations. Application workloads generate realistic transactions. Chaos workloads inject failures. The CHECK phases prove correctness survived the chaos. This is why FoundationDB doesn&#x27;t fail in production. The simulator has already broken it every possible way, and every bug got fixed before shipping.&lt;&#x2F;p&gt;
&lt;p&gt;I generated that simulation output using &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;PierreZ&#x2F;fdb-sim-visualizer&quot;&gt;fdb-sim-visualizer&lt;&#x2F;a&gt;, a tool I wrote to parse simulation trace logs and understand what happened during testing.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;verifying-correctness-building-reliable-workloads&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#verifying-correctness-building-reliable-workloads&quot; aria-label=&quot;Anchor link for: verifying-correctness-building-reliable-workloads&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;Verifying Correctness: Building Reliable Workloads&lt;&#x2F;h2&gt;
&lt;p&gt;&lt;strong&gt;But here&#x27;s the hard part: proving correctness when everything is randomized.&lt;&#x2F;strong&gt; The cluster survived. Transactions completed. The cycle invariant never broke... or did it? When you&#x27;re running 2500 transactions per second with random edge swaps under 187 network partitions, how do you &lt;strong&gt;prove&lt;&#x2F;strong&gt; nothing went wrong? You can&#x27;t just check if the database &quot;looks okay.&quot; You need &lt;strong&gt;proof&lt;&#x2F;strong&gt; the invariants held.&lt;&#x2F;p&gt;
&lt;p&gt;FoundationDB&#x27;s approach: &lt;strong&gt;track during EXECUTION, verify in CHECK.&lt;&#x2F;strong&gt; Three patterns emerge across the codebase:&lt;&#x2F;p&gt;
&lt;h3 id=&quot;pattern-1-reference-implementation&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#pattern-1-reference-implementation&quot; aria-label=&quot;Anchor link for: pattern-1-reference-implementation&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;Pattern 1: Reference Implementation&lt;&#x2F;h3&gt;
&lt;p&gt;&lt;strong&gt;The challenge&lt;&#x2F;strong&gt;: How do you verify complex API behavior under chaos?&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;The solution&lt;&#x2F;strong&gt;: Run every operation twice. &lt;code&gt;ApiCorrectness&lt;&#x2F;code&gt; (&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;apple&#x2F;foundationdb&#x2F;blob&#x2F;dfbb0ea72ce01ba87148ef67cf216200e8b249cd&#x2F;fdbserver&#x2F;workloads&#x2F;ApiCorrectness.actor.cpp&quot;&gt;ApiCorrectness.actor.cpp&lt;&#x2F;a&gt;) mirrors all operations in a simple &lt;code&gt;MemoryKeyValueStore&lt;&#x2F;code&gt; (just a &lt;code&gt;std::map&amp;lt;Key, Value&amp;gt;&lt;&#x2F;code&gt;). Every &lt;code&gt;transaction-&amp;gt;set(k, v)&lt;&#x2F;code&gt; also executes &lt;code&gt;store.set(k, v)&lt;&#x2F;code&gt; in memory. The CHECK phase reads from FDB and compares with the memory model. Mismatch = bug found.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;pattern-2-operation-logging&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#pattern-2-operation-logging&quot; aria-label=&quot;Anchor link for: pattern-2-operation-logging&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;Pattern 2: Operation Logging&lt;&#x2F;h3&gt;
&lt;p&gt;&lt;strong&gt;The challenge&lt;&#x2F;strong&gt;: How do you verify atomic operations executed in the right order?&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;The solution&lt;&#x2F;strong&gt;: Log everything. &lt;code&gt;AtomicOps&lt;&#x2F;code&gt; (&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;apple&#x2F;foundationdb&#x2F;blob&#x2F;dfbb0ea72ce01ba87148ef67cf216200e8b249cd&#x2F;fdbserver&#x2F;workloads&#x2F;AtomicOps.actor.cpp&quot;&gt;AtomicOps.actor.cpp&lt;&#x2F;a&gt;) logs every operation to a separate keyspace. During EXECUTION: &lt;code&gt;atomicOp(ops_key, value)&lt;&#x2F;code&gt; on real data, &lt;code&gt;set(log_key, value)&lt;&#x2F;code&gt; to track what happened. During CHECK: replay all logged operations, compute what the final state should be, compare with actual database state.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;pattern-3-invariant-tracking&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#pattern-3-invariant-tracking&quot; aria-label=&quot;Anchor link for: pattern-3-invariant-tracking&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;Pattern 3: Invariant Tracking&lt;&#x2F;h3&gt;
&lt;p&gt;&lt;strong&gt;The challenge&lt;&#x2F;strong&gt;: How do you prove SERIALIZABLE isolation worked during chaos?&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;The solution&lt;&#x2F;strong&gt;: Maintain a mathematical invariant that breaks if isolation fails. &lt;code&gt;Cycle&lt;&#x2F;code&gt; (from our test earlier) maintains &quot;exactly N nodes in one ring.&quot; During EXECUTION, random edge swaps must preserve the invariant. During CHECK, walk the graph: 0â†’nextâ†’nextâ†’next. After exactly N hops, you must be back at node 0. If you arrive earlier (cycle split) or can&#x27;t arrive (broken chain), isolation failed. The CHECK phase catches this immediately.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;using-clientid-for-work-distribution&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#using-clientid-for-work-distribution&quot; aria-label=&quot;Anchor link for: using-clientid-for-work-distribution&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;Using clientId for Work Distribution&lt;&#x2F;h3&gt;
&lt;p&gt;Every workload gets &lt;code&gt;clientId&lt;&#x2F;code&gt; (0, 1, 2...) and &lt;code&gt;clientCount&lt;&#x2F;code&gt; (total clients). Three patterns:&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Client 0 only&lt;&#x2F;strong&gt; (&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;apple&#x2F;foundationdb&#x2F;blob&#x2F;dfbb0ea72ce01ba87148ef67cf216200e8b249cd&#x2F;fdbserver&#x2F;workloads&#x2F;AtomicOps.actor.cpp&quot;&gt;AtomicOps.actor.cpp&lt;&#x2F;a&gt;):&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;cpp&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-cpp &quot;&gt;&lt;code class=&quot;language-cpp&quot; data-lang=&quot;cpp&quot;&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;if &lt;&#x2F;span&gt;&lt;span&gt;(clientId != &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;0&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;return &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;true&lt;&#x2F;span&gt;&lt;span&gt;;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; Common for CHECK phases
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;&lt;strong&gt;Partition keyspace&lt;&#x2F;strong&gt; (&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;apple&#x2F;foundationdb&#x2F;blob&#x2F;dfbb0ea72ce01ba87148ef67cf216200e8b249cd&#x2F;fdbserver&#x2F;workloads&#x2F;WatchAndWait.actor.cpp&quot;&gt;WatchAndWait.actor.cpp&lt;&#x2F;a&gt;):&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;cpp&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-cpp &quot;&gt;&lt;code class=&quot;language-cpp&quot; data-lang=&quot;cpp&quot;&gt;&lt;span&gt;uint64_t startNode = (nodeCount * clientId) &#x2F; clientCount;
&lt;&#x2F;span&gt;&lt;span&gt;uint64_t endNode = (nodeCount * (clientId + &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;)) &#x2F; clientCount;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; Client 0: nodes 0-33, Client 1: nodes 34-66, Client 2: nodes 67-99
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;&lt;strong&gt;Round-robin&lt;&#x2F;strong&gt; (&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;apple&#x2F;foundationdb&#x2F;blob&#x2F;dfbb0ea72ce01ba87148ef67cf216200e8b249cd&#x2F;fdbserver&#x2F;workloads&#x2F;Watches.actor.cpp&quot;&gt;Watches.actor.cpp&lt;&#x2F;a&gt;):&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;cpp&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-cpp &quot;&gt;&lt;code class=&quot;language-cpp&quot; data-lang=&quot;cpp&quot;&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;if &lt;&#x2F;span&gt;&lt;span&gt;(i % clientCount == clientId)
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; Client 0: keys 0,3,6,9... Client 1: keys 1,4,7,10...
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Use &lt;code&gt;clientId&lt;&#x2F;code&gt; to create concurrency (multiple clients hitting different keys) or coordinate work (one client checks, others generate load).&lt;&#x2F;p&gt;
&lt;h3 id=&quot;randomize-everything&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#randomize-everything&quot; aria-label=&quot;Anchor link for: randomize-everything&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;Randomize Everything&lt;&#x2F;h3&gt;
&lt;p&gt;The key to finding bugs: &lt;strong&gt;randomize every decision&lt;&#x2F;strong&gt;. Which keys to read? Random. How many operations per transaction? Random. Which atomic operation type? Random. Order of operations? Random. When to inject chaos? Random.&lt;&#x2F;p&gt;
&lt;p&gt;But use &lt;code&gt;deterministicRandom()&lt;&#x2F;code&gt; for all randomness. It&#x27;s a seeded PRNG. Same seed = same random choices = reproducible failures. When a test fails after 10 million operations, rerun with the same seed, get the exact same failure at the exact same point.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;pattern-selection-guide&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#pattern-selection-guide&quot; aria-label=&quot;Anchor link for: pattern-selection-guide&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;Pattern Selection Guide&lt;&#x2F;h3&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Testing&lt;&#x2F;th&gt;&lt;th&gt;Use Pattern&lt;&#x2F;th&gt;&lt;th&gt;Example Workload&lt;&#x2F;th&gt;&lt;&#x2F;tr&gt;&lt;&#x2F;thead&gt;&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;API correctness&lt;&#x2F;td&gt;&lt;td&gt;Reference implementation&lt;&#x2F;td&gt;&lt;td&gt;ApiCorrectness&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;Atomic operations&lt;&#x2F;td&gt;&lt;td&gt;Operation logging&lt;&#x2F;td&gt;&lt;td&gt;AtomicOps&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;ACID guarantees&lt;&#x2F;td&gt;&lt;td&gt;Invariant tracking&lt;&#x2F;td&gt;&lt;td&gt;Cycle&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;Backup&#x2F;restore&lt;&#x2F;td&gt;&lt;td&gt;Absence checking&lt;&#x2F;td&gt;&lt;td&gt;BackupCorrectness&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;&#x2F;tbody&gt;&lt;&#x2F;table&gt;
&lt;p&gt;Chaos workloads (&lt;code&gt;RandomClogging&lt;&#x2F;code&gt;, &lt;code&gt;Attrition&lt;&#x2F;code&gt;, &lt;code&gt;Rollback&lt;&#x2F;code&gt;) don&#x27;t need CHECK phases. They just return &lt;code&gt;true&lt;&#x2F;code&gt;. They inject failures. Application workloads verify that correctness survived the chaos.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;writing-workloads-in-rust&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#writing-workloads-in-rust&quot; aria-label=&quot;Anchor link for: writing-workloads-in-rust&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;Writing Workloads in Rust&lt;&#x2F;h2&gt;
&lt;p&gt;Remember those chaos workloads hammering the Cycle test? &lt;code&gt;RandomClogging&lt;&#x2F;code&gt;, &lt;code&gt;Attrition&lt;&#x2F;code&gt;, &lt;code&gt;Rollback&lt;&#x2F;code&gt;. All written in C++ Flow. But you can write workloads in &lt;strong&gt;Rust&lt;&#x2F;strong&gt; and compile them directly into the simulator. At Clever Cloud, we open-sourced &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;foundationdb-rs&#x2F;foundationdb-rs&#x2F;tree&#x2F;main&#x2F;foundationdb-simulation&quot;&gt;foundationdb-simulation&lt;&#x2F;a&gt;, which lets you implement the &lt;code&gt;RustWorkload&lt;&#x2F;code&gt; trait with &lt;code&gt;setup()&lt;&#x2F;code&gt;, &lt;code&gt;start()&lt;&#x2F;code&gt;, and &lt;code&gt;check()&lt;&#x2F;code&gt; methods using Rust&#x27;s async&#x2F;await:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;rust&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-rust &quot;&gt;&lt;code class=&quot;language-rust&quot; data-lang=&quot;rust&quot;&gt;&lt;span&gt;#[&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;async_trait&lt;&#x2F;span&gt;&lt;span&gt;]
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;impl &lt;&#x2F;span&gt;&lt;span&gt;RustWorkload &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;for &lt;&#x2F;span&gt;&lt;span&gt;MyWorkload {
&lt;&#x2F;span&gt;&lt;span&gt;    async &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;fn &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8fa1b3;&quot;&gt;setup&lt;&#x2F;span&gt;&lt;span&gt;(&amp;amp;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;mut &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;self&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;db&lt;&#x2F;span&gt;&lt;span&gt;: Database, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;_ctx&lt;&#x2F;span&gt;&lt;span&gt;: Context) -&amp;gt; Result&amp;lt;()&amp;gt; {
&lt;&#x2F;span&gt;&lt;span&gt;        &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; Initialize test data
&lt;&#x2F;span&gt;&lt;span&gt;        db.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#96b5b4;&quot;&gt;run&lt;&#x2F;span&gt;&lt;span&gt;(|&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;tx&lt;&#x2F;span&gt;&lt;span&gt;, _| async &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;move &lt;&#x2F;span&gt;&lt;span&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;            tx.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#96b5b4;&quot;&gt;set&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;b&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;key&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;b&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;value&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;);
&lt;&#x2F;span&gt;&lt;span&gt;            Ok(())
&lt;&#x2F;span&gt;&lt;span&gt;        }).await
&lt;&#x2F;span&gt;&lt;span&gt;    }
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    async &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;fn &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8fa1b3;&quot;&gt;start&lt;&#x2F;span&gt;&lt;span&gt;(&amp;amp;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;mut &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;self&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;db&lt;&#x2F;span&gt;&lt;span&gt;: Database, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;ctx&lt;&#x2F;span&gt;&lt;span&gt;: Context) -&amp;gt; Result&amp;lt;()&amp;gt; {
&lt;&#x2F;span&gt;&lt;span&gt;        &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; Generate load under simulation
&lt;&#x2F;span&gt;&lt;span&gt;        &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;for &lt;&#x2F;span&gt;&lt;span&gt;_ in &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;0&lt;&#x2F;span&gt;&lt;span&gt;..ctx.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#96b5b4;&quot;&gt;get_option&lt;&#x2F;span&gt;&lt;span&gt;(&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;nodeCount&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;100&lt;&#x2F;span&gt;&lt;span&gt;) {
&lt;&#x2F;span&gt;&lt;span&gt;            db.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#96b5b4;&quot;&gt;run&lt;&#x2F;span&gt;&lt;span&gt;(|&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;tx&lt;&#x2F;span&gt;&lt;span&gt;, _| async &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;move &lt;&#x2F;span&gt;&lt;span&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;                &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;let&lt;&#x2F;span&gt;&lt;span&gt; value = tx.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#96b5b4;&quot;&gt;get&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;b&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;key&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;false&lt;&#x2F;span&gt;&lt;span&gt;).await?;
&lt;&#x2F;span&gt;&lt;span&gt;                &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; Your workload logic here
&lt;&#x2F;span&gt;&lt;span&gt;                Ok(())
&lt;&#x2F;span&gt;&lt;span&gt;            }).await?;
&lt;&#x2F;span&gt;&lt;span&gt;        }
&lt;&#x2F;span&gt;&lt;span&gt;        Ok(())
&lt;&#x2F;span&gt;&lt;span&gt;    }
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    async &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;fn &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8fa1b3;&quot;&gt;check&lt;&#x2F;span&gt;&lt;span&gt;(&amp;amp;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;mut &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;self&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;db&lt;&#x2F;span&gt;&lt;span&gt;: Database, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;_ctx&lt;&#x2F;span&gt;&lt;span&gt;: Context) -&amp;gt; Result&amp;lt;()&amp;gt; {
&lt;&#x2F;span&gt;&lt;span&gt;        &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; Verify correctness after chaos
&lt;&#x2F;span&gt;&lt;span&gt;        Ok(())
&lt;&#x2F;span&gt;&lt;span&gt;    }
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Your Rust code compiles to a shared library, FDB&#x27;s &lt;code&gt;ExternalWorkload&lt;&#x2F;code&gt; loads it at runtime via FFI, and your Rust async functions run on the same Flow event loop as the C++ cluster. The FFI boundary is managed by the &lt;code&gt;foundationdb-simulation&lt;&#x2F;code&gt; crate, which handles marshaling between Flow&#x27;s event loop and Rust futures. Same determinism, same reproducibility, same chaos injection. But you&#x27;re writing &lt;code&gt;async fn&lt;&#x2F;code&gt; instead of &lt;code&gt;ACTOR Future&amp;lt;Void&amp;gt;&lt;&#x2F;code&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;Here&#x27;s a &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;foundationdb-rs&#x2F;foundationdb-rs&#x2F;blob&#x2F;main&#x2F;foundationdb-simulation&#x2F;examples&#x2F;atomic&#x2F;lib.rs&quot;&gt;complete example workload&lt;&#x2F;a&gt; testing atomic operations in ~100 lines of Rust.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;simulation-at-clever-cloud-building-materia&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#simulation-at-clever-cloud-building-materia&quot; aria-label=&quot;Anchor link for: simulation-at-clever-cloud-building-materia&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;Simulation at Clever Cloud: Building Materia&lt;&#x2F;h3&gt;
&lt;p&gt;At Clever Cloud, we use simulation to build &lt;a href=&quot;https:&#x2F;&#x2F;www.clever-cloud.com&#x2F;blog&#x2F;features&#x2F;2024&#x2F;06&#x2F;11&#x2F;materia-kv-our-easy-to-use-serverless-key-value-database-is-available-to-all&#x2F;&quot;&gt;Materia&lt;&#x2F;a&gt;, our serverless database products. I&#x27;m the lead engineer behind Materia and the main maintainer of &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;foundationdb-rs&#x2F;foundationdb-rs&quot;&gt;foundationdb-rs&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;We built a Rust SDK on top of FDB, similar to Apple&#x27;s &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;FoundationDB&#x2F;fdb-record-layer&quot;&gt;Record Layer&lt;&#x2F;a&gt;. It provides structured records, secondary indexes, query planning, and multi-tenant isolation. The result: a distributed transactional database built on FoundationDB&#x27;s guarantees.&lt;&#x2F;p&gt;
&lt;p&gt;FoundationDB is a hidden technology: you don&#x27;t use it directly, you build layers on top. But here&#x27;s the trick: &lt;strong&gt;patterns like index design, quota management, and schema management should be written once and consumed, not reimplemented in every product&lt;&#x2F;strong&gt;. Our SDK abstracts these patterns. Need secondary indexes? The SDK handles keyspace layout, index updates, and query planning. Need multi-tenant isolation? The SDK provides it. Need quota enforcement or permission management? &lt;strong&gt;We built a common control plane that works across all products&lt;&#x2F;strong&gt; built on the SDK. Write the hard distributed systems logic once, simulate it until it&#x27;s bulletproof, then reuse it everywhere.&lt;&#x2F;p&gt;
&lt;p&gt;Every merge request runs simulation tests in CI. We test SDK scenarios (indexing, query planning) and full product workloads under chaos. Multi-tenant isolation, concurrent queries, network partitions, machine crashes. The bugs we catch vary by layer. SDK changes catch nasty bugs like duplicated indexes during &lt;code&gt;maybe_committed&lt;&#x2F;code&gt; transactions. Product changes catch simpler errors like accidentally blocking FDB&#x27;s retry logic or breaking atomicity.&lt;&#x2F;p&gt;
&lt;p&gt;But the real value isn&#x27;t just bug detection. &lt;strong&gt;Instead of writing hundreds of unit tests, we write workloads that fuzz our code under chaos.&lt;&#x2F;strong&gt; One workload with randomized operations and deterministic chaos replaces dozens of hand-crafted test cases. When engineers write workloads for their features, they&#x27;re forced to think: &quot;What happens when this retries during a partition?&quot; &quot;How do I verify correctness when transactions can commit in any order?&quot; &lt;strong&gt;Designing for chaos&lt;&#x2F;strong&gt; becomes natural. The act of writing simulation workloads improves the design itself.&lt;&#x2F;p&gt;
&lt;p&gt;The confidence this gives a small team is extraordinary. When you can prove your code survives hundreds of network partitions and machine crashes before shipping, you sleep better at night. Our latest layer, an etcd-compatible API for managed Kubernetes, was built from the ground up with simulation in mind. We&#x27;re even &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;apple&#x2F;foundationdb&#x2F;issues&#x2F;12343&quot;&gt;contributing features back to FoundationDB&lt;&#x2F;a&gt; to better support layers like ours.&lt;&#x2F;p&gt;
&lt;p&gt;If it survives simulation, it survives production.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;running-simulations-yourself&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#running-simulations-yourself&quot; aria-label=&quot;Anchor link for: running-simulations-yourself&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;Running Simulations Yourself&lt;&#x2F;h2&gt;
&lt;p&gt;Think you can break FoundationDB? You don&#x27;t need to build from source or set up a cluster. Download a prebuilt &lt;code&gt;fdbserver&lt;&#x2F;code&gt; binary from the &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;apple&#x2F;foundationdb&#x2F;releases&quot;&gt;releases page&lt;&#x2F;a&gt;, create a test file, and unleash chaos:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# Download fdbserver (Linux example, adjust for your platform)
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;wget&lt;&#x2F;span&gt;&lt;span&gt; https:&#x2F;&#x2F;github.com&#x2F;apple&#x2F;foundationdb&#x2F;releases&#x2F;download&#x2F;7.3.27&#x2F;fdbserver.x86_64
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;chmod&lt;&#x2F;span&gt;&lt;span&gt; +x fdbserver.x86_64
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# Create the folder for traces
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;mkdir&lt;&#x2F;span&gt;&lt;span&gt; events
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# Run a simulation test with JSON trace output
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;.&#x2F;fdbserver.x86_64 -r&lt;&#x2F;span&gt;&lt;span&gt; simulation&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt; -f&lt;&#x2F;span&gt;&lt;span&gt; Attritions.toml&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt; --trace-format&lt;&#x2F;span&gt;&lt;span&gt; json&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt; -L&lt;&#x2F;span&gt;&lt;span&gt; .&#x2F;events&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt; --logsize&lt;&#x2F;span&gt;&lt;span&gt; 1GiB
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Here are two test files to get you started. Save either as a &lt;code&gt;.toml&lt;&#x2F;code&gt; file and run with the command above.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Attritions.toml&lt;&#x2F;strong&gt; - Network partitions + machine crashes + database reconfigurations (the NemesisTest shown earlier):&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;toml&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-toml &quot;&gt;&lt;code class=&quot;language-toml&quot; data-lang=&quot;toml&quot;&gt;&lt;span&gt;[configuration]
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;buggify &lt;&#x2F;span&gt;&lt;span&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;true
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;minimumReplication &lt;&#x2F;span&gt;&lt;span&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;3
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;[[test]]
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;testTitle &lt;&#x2F;span&gt;&lt;span&gt;= &amp;#39;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;NemesisTest&lt;&#x2F;span&gt;&lt;span&gt;&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;    [[test.workload]]
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;testName &lt;&#x2F;span&gt;&lt;span&gt;= &amp;#39;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;ReadWrite&lt;&#x2F;span&gt;&lt;span&gt;&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;testDuration &lt;&#x2F;span&gt;&lt;span&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;30.0
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;transactionsPerSecond &lt;&#x2F;span&gt;&lt;span&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;1000.0
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    [[test.workload]]
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;testName &lt;&#x2F;span&gt;&lt;span&gt;= &amp;#39;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;RandomClogging&lt;&#x2F;span&gt;&lt;span&gt;&amp;#39;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# Network partitions
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;testDuration &lt;&#x2F;span&gt;&lt;span&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;30.0
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;swizzle &lt;&#x2F;span&gt;&lt;span&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;1  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# Unclog in reversed order
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    [[test.workload]]
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;testName &lt;&#x2F;span&gt;&lt;span&gt;= &amp;#39;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Attrition&lt;&#x2F;span&gt;&lt;span&gt;&amp;#39;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# Machine crashes
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;testDuration &lt;&#x2F;span&gt;&lt;span&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;30.0
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    [[test.workload]]
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;testName &lt;&#x2F;span&gt;&lt;span&gt;= &amp;#39;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Rollback&lt;&#x2F;span&gt;&lt;span&gt;&amp;#39;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# Proxy-to-TLog errors
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;testDuration &lt;&#x2F;span&gt;&lt;span&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;30
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    [[test.workload]]
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;testName &lt;&#x2F;span&gt;&lt;span&gt;= &amp;#39;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;ChangeConfig&lt;&#x2F;span&gt;&lt;span&gt;&amp;#39;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# Database reconfigurations
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;coordinators &lt;&#x2F;span&gt;&lt;span&gt;= &amp;#39;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;auto&lt;&#x2F;span&gt;&lt;span&gt;&amp;#39;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;&lt;strong&gt;DiskFailureCycle.toml&lt;&#x2F;strong&gt; - Disk failures + bit flips during the Cycle workload:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;toml&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-toml &quot;&gt;&lt;code class=&quot;language-toml&quot; data-lang=&quot;toml&quot;&gt;&lt;span&gt;[configuration]
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;minimumReplication &lt;&#x2F;span&gt;&lt;span&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;3
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;minimumRegions &lt;&#x2F;span&gt;&lt;span&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;3
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;[[test]]
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;testTitle &lt;&#x2F;span&gt;&lt;span&gt;= &amp;#39;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;DiskFailureCycle&lt;&#x2F;span&gt;&lt;span&gt;&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;    [[test.workload]]
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;testName &lt;&#x2F;span&gt;&lt;span&gt;= &amp;#39;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Cycle&lt;&#x2F;span&gt;&lt;span&gt;&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;transactionsPerSecond &lt;&#x2F;span&gt;&lt;span&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;2500.0
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;testDuration &lt;&#x2F;span&gt;&lt;span&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;30.0
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    [[test.workload]]
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;testName &lt;&#x2F;span&gt;&lt;span&gt;= &amp;#39;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;DiskFailureInjection&lt;&#x2F;span&gt;&lt;span&gt;&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;testDuration &lt;&#x2F;span&gt;&lt;span&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;120.0
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;stallInterval &lt;&#x2F;span&gt;&lt;span&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;5.0
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;stallPeriod &lt;&#x2F;span&gt;&lt;span&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;5.0
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;throttlePeriod &lt;&#x2F;span&gt;&lt;span&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;30.0
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;corruptFile &lt;&#x2F;span&gt;&lt;span&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;true
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;percentBitFlips &lt;&#x2F;span&gt;&lt;span&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;10
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The simulation generates JSON trace logs in &lt;code&gt;.&#x2F;events&#x2F;&lt;&#x2F;code&gt;. Parse them with &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;PierreZ&#x2F;fdb-sim-visualizer&quot;&gt;fdb-sim-visualizer&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;For more test examples, check FoundationDB&#x27;s &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;apple&#x2F;foundationdb&#x2F;tree&#x2F;dfbb0ea72ce01ba87148ef67cf216200e8b249cd&#x2F;tests&quot;&gt;tests&#x2F;&lt;&#x2F;a&gt; directory. Hundreds of workload combinations testing every corner of the system.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;why-i-ve-never-been-woken-up-by-fdb&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#why-i-ve-never-been-woken-up-by-fdb&quot; aria-label=&quot;Anchor link for: why-i-ve-never-been-woken-up-by-fdb&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;Why I&#x27;ve Never Been Woken Up by FDB&lt;&#x2F;h2&gt;
&lt;p&gt;After years of on-call and one trillion CPU-hours of simulation, I&#x27;ve never been woken up by FoundationDB. Now you know why.&lt;&#x2F;p&gt;
&lt;p&gt;Interface swapping lets the same code run in both production and simulation. Flow actors enable single-threaded determinism. The event loop compresses years into seconds. BUGGIFY injects chaos into every corner of the codebase. SimulatedCluster builds entire distributed systems in memory. Workloads generate realistic transactions while chaos engines try to break everything. And deterministic randomness guarantees every bug can be reproduced, diagnosed, and fixed before shipping.&lt;&#x2F;p&gt;
&lt;p&gt;The simulator has already broken FoundationDB in every possible way. Network partitions during coordinator elections. Machine crashes mid-transaction. Disks swapped between nodes on reboot. Bit flips. Slow I&#x2F;O. Every edge case, every race condition, every distributed systems nightmare. Found, fixed, and verified before production ever sees it.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Want to try breaking FoundationDB yourself?&lt;&#x2F;strong&gt; Grab a test config from above, run the simulator, inject chaos, and see if you can find a bug that survived one trillion CPU-hours. If you do, the FDB team would love to hear about it.&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;p&gt;Feel free to reach out with any questions or to share your simulation testing experiences or FDB workloads. You can find me on &lt;a href=&quot;https:&#x2F;&#x2F;twitter.com&#x2F;PierreZ&quot;&gt;Twitter&lt;&#x2F;a&gt;, &lt;a href=&quot;https:&#x2F;&#x2F;bsky.app&#x2F;profile&#x2F;pierrezemb.fr&quot;&gt;Bluesky&lt;&#x2F;a&gt; or through my &lt;a href=&quot;https:&#x2F;&#x2F;pierrezemb.fr&quot;&gt;website&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>A Practical Guide to Application Metrics: Where to Put Your Instrumentation</title>
        <published>2025-09-24T00:00:00+00:00</published>
        <updated>2025-09-24T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Pierre Zemb
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://pierrezemb.fr/posts/practical-guide-to-application-metrics/"/>
        <id>https://pierrezemb.fr/posts/practical-guide-to-application-metrics/</id>
        
        <category term="observability" schema="https://pierrezemb.fr/tags/" label="observability"/>
        <category term="metrics" schema="https://pierrezemb.fr/tags/" label="metrics"/>
        <category term="monitoring" schema="https://pierrezemb.fr/tags/" label="monitoring"/>
        <category term="distributed-systems" schema="https://pierrezemb.fr/tags/" label="distributed-systems"/>
        <content type="html" xml:base="https://pierrezemb.fr/posts/practical-guide-to-application-metrics/">&lt;p&gt;I keep having the same conversation with junior developers. They&#x27;re building their first production service, and they ask: &quot;Where should I put metrics in my application?&quot; Then, inevitably: &quot;What should I actually measure?&quot;&lt;&#x2F;p&gt;
&lt;p&gt;After mentoring dozens of engineers and running distributed systems for years, I&#x27;ve learned these aren&#x27;t just beginner questions. Even experienced developers struggle with metrics placement because most of us learned observability as an afterthought, not as a core design principle.&lt;&#x2F;p&gt;
&lt;p&gt;I&#x27;ve been on both sides: deploying services with no metrics and scrambling at 3 AM to understand what broke, and also building comprehensive monitoring that caught issues before users noticed. The difference isn&#x27;t just about sleep quality; it&#x27;s about building systems you can actually operate with confidence.&lt;&#x2F;p&gt;
&lt;p&gt;This post gives you a practical framework for where to instrument your applications. No theory, just patterns I&#x27;ve learned from years of production incidents.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-five-essential-metric-types&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#the-five-essential-metric-types&quot; aria-label=&quot;Anchor link for: the-five-essential-metric-types&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;The Five Essential Metric Types&lt;&#x2F;h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Quick note on naming:&lt;&#x2F;strong&gt; Throughout this post, I use dots (&lt;code&gt;.&lt;&#x2F;code&gt;) as metric separators like &lt;code&gt;api.requests.total&lt;&#x2F;code&gt;. This works perfectly for us because we&#x27;re heavy &lt;a href=&quot;https:&#x2F;&#x2F;warp10.io&#x2F;&quot;&gt;Warp 10&lt;&#x2F;a&gt; users, and Warp 10 handles dots beautifully. If you&#x27;re using Prometheus or other systems that prefer underscores, just replace the dots with underscores (&lt;code&gt;api_requests_total&lt;&#x2F;code&gt;). The patterns remain the same!&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;p&gt;All useful application metrics fall into five categories. Understanding these helps you decide what to instrument and where:&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;1. Operational Counters&lt;&#x2F;strong&gt; track discrete events in your system. Every time something happens (a request arrives, a job finishes, an error occurs), you increment a counter. The most critical insight here is measuring both success and failure paths. Most developers remember to count successful operations but forget the errors, leaving them blind when things break. Examples include &lt;code&gt;api.requests.total&lt;&#x2F;code&gt;, &lt;code&gt;db.queries.executed&lt;&#x2F;code&gt;, &lt;code&gt;auth.failures.count&lt;&#x2F;code&gt;, &lt;code&gt;payments.declined.count&lt;&#x2F;code&gt;, &lt;code&gt;jobs.started&lt;&#x2F;code&gt;, and &lt;code&gt;cache.evictions&lt;&#x2F;code&gt;. Always include labels like &lt;code&gt;method&lt;&#x2F;code&gt;, &lt;code&gt;endpoint&lt;&#x2F;code&gt;, &lt;code&gt;error_type&lt;&#x2F;code&gt; to provide context.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;2. Resource Utilization&lt;&#x2F;strong&gt; answers &quot;how much of X am I using right now?&quot; These are your early warning system for capacity problems. Track current values with gauges, cumulative usage with counters. The key is monitoring resources before they&#x27;re completely exhausted. A connection pool might support 100 connections, but if 95 are active, you&#x27;re in trouble. Monitor &lt;code&gt;memory.used.bytes&lt;&#x2F;code&gt;, &lt;code&gt;db.connections.active&lt;&#x2F;code&gt;, &lt;code&gt;cache.size.entries&lt;&#x2F;code&gt;, &lt;code&gt;thread_pool.active_threads&lt;&#x2F;code&gt;, and &lt;code&gt;disk.space.available.bytes&lt;&#x2F;code&gt;. Watch for patterns like steadily increasing memory usage or connection counts approaching pool limits.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;3. Performance and Latency&lt;&#x2F;strong&gt; shows how fast (or slow) things are running. Users feel latency immediately, making these often your most-watched dashboards. Always include units in metric names (&lt;code&gt;.ms&lt;&#x2F;code&gt;, &lt;code&gt;.seconds&lt;&#x2F;code&gt;, &lt;code&gt;.bytes&lt;&#x2F;code&gt;) to make dashboards self-documenting. Track &lt;code&gt;api.response_time.ms&lt;&#x2F;code&gt;, &lt;code&gt;db.query.duration.ms&lt;&#x2F;code&gt;, &lt;code&gt;jobs.processing_time.seconds&lt;&#x2F;code&gt;, and &lt;code&gt;external_api.call.duration.ms&lt;&#x2F;code&gt;. Monitor percentiles (p50, p95, p99) not just averages: a 1ms average with a 5-second p99 indicates serious problems.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;4. Data Volume and Throughput&lt;&#x2F;strong&gt; tracks data flow through your system. These metrics are crucial for capacity planning and spotting bottlenecks before they cause user-visible problems. Monitor both input and output rates to understand processing efficiency. Focus on &lt;code&gt;queue.messages.consumed&lt;&#x2F;code&gt;, &lt;code&gt;network.bytes.sent&lt;&#x2F;code&gt;, &lt;code&gt;database.rows.processed&lt;&#x2F;code&gt;, &lt;code&gt;file_processor.files.completed&lt;&#x2F;code&gt;, and &lt;code&gt;batch_processor.records.per_batch&lt;&#x2F;code&gt;. Compare input vs output rates to identify accumulating backlogs.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;5. Business Logic&lt;&#x2F;strong&gt; captures domain-specific metrics that relate to your actual business value. These are often the most valuable metrics for understanding how your application is really being used and whether technical problems are affecting business outcomes. Track &lt;code&gt;orders.placed&lt;&#x2F;code&gt;, &lt;code&gt;users.registered&lt;&#x2F;code&gt;, &lt;code&gt;searches.executed&lt;&#x2F;code&gt;, &lt;code&gt;documents.uploaded&lt;&#x2F;code&gt;, and &lt;code&gt;subscriptions.activated&lt;&#x2F;code&gt;. Don&#x27;t underestimate these: they&#x27;re what your executives care about and often reveal problems that technical metrics miss.&lt;&#x2F;p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Type&lt;&#x2F;th&gt;&lt;th&gt;Examples&lt;&#x2F;th&gt;&lt;th&gt;Key Insight&lt;&#x2F;th&gt;&lt;&#x2F;tr&gt;&lt;&#x2F;thead&gt;&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;Operational&lt;&#x2F;td&gt;&lt;td&gt;&lt;code&gt;api.requests.total&lt;&#x2F;code&gt;, &lt;code&gt;auth.failures&lt;&#x2F;code&gt;&lt;&#x2F;td&gt;&lt;td&gt;Track success AND failure paths&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;Resource&lt;&#x2F;td&gt;&lt;td&gt;&lt;code&gt;memory.used.bytes&lt;&#x2F;code&gt;, &lt;code&gt;db.connections.active&lt;&#x2F;code&gt;&lt;&#x2F;td&gt;&lt;td&gt;Early warning for capacity issues&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;Performance&lt;&#x2F;td&gt;&lt;td&gt;&lt;code&gt;api.response_time.ms&lt;&#x2F;code&gt;, &lt;code&gt;db.query.duration.ms&lt;&#x2F;code&gt;&lt;&#x2F;td&gt;&lt;td&gt;Users feel latency immediately&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;Throughput&lt;&#x2F;td&gt;&lt;td&gt;&lt;code&gt;queue.messages.consumed&lt;&#x2F;code&gt;, &lt;code&gt;network.bytes.sent&lt;&#x2F;code&gt;&lt;&#x2F;td&gt;&lt;td&gt;Understand data flow patterns&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;Business&lt;&#x2F;td&gt;&lt;td&gt;&lt;code&gt;orders.placed&lt;&#x2F;code&gt;, &lt;code&gt;users.login&lt;&#x2F;code&gt;&lt;&#x2F;td&gt;&lt;td&gt;What executives actually care about&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;&#x2F;tbody&gt;&lt;&#x2F;table&gt;
&lt;h2 id=&quot;where-to-instrument-a-component-guide&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#where-to-instrument-a-component-guide&quot; aria-label=&quot;Anchor link for: where-to-instrument-a-component-guide&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;Where to Instrument: A Component Guide&lt;&#x2F;h2&gt;
&lt;h3 id=&quot;api-endpoints-and-http-requests&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#api-endpoints-and-http-requests&quot; aria-label=&quot;Anchor link for: api-endpoints-and-http-requests&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;API Endpoints and HTTP Requests&lt;&#x2F;h3&gt;
&lt;p&gt;Your application&#x27;s front door deserves comprehensive monitoring. Every HTTP request tells a story from arrival to completion, and you want to capture that entire narrative, not just the happy path. Track &lt;code&gt;api.requests.total&lt;&#x2F;code&gt; with labels for &lt;code&gt;method&lt;&#x2F;code&gt;, &lt;code&gt;endpoint&lt;&#x2F;code&gt;, and &lt;code&gt;status_code&lt;&#x2F;code&gt; to understand usage patterns. Monitor &lt;code&gt;api.response_time.ms&lt;&#x2F;code&gt; to show user experience, and &lt;code&gt;api.errors.count&lt;&#x2F;code&gt; with &lt;code&gt;error_type&lt;&#x2F;code&gt; labels to reveal reliability issues. Include &lt;code&gt;auth.failures.count&lt;&#x2F;code&gt; with &lt;code&gt;failure_reason&lt;&#x2F;code&gt; to catch security problems, and &lt;code&gt;api.concurrent_requests&lt;&#x2F;code&gt; to identify when you&#x27;re approaching capacity limits. The common mistake is only instrumenting successful requests; the real value comes from measuring what happens when things go wrong: network timeouts, validation errors, service dependencies failing.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;database-layer&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#database-layer&quot; aria-label=&quot;Anchor link for: database-layer&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;Database Layer&lt;&#x2F;h3&gt;
&lt;p&gt;Database calls are often your biggest bottleneck and cause more production incidents than any other component. For connection management, track &lt;code&gt;db.connections.active&lt;&#x2F;code&gt; (critical for pool management), &lt;code&gt;db.connections.idle&lt;&#x2F;code&gt; (available connections), and &lt;code&gt;db.connections.wait_time.ms&lt;&#x2F;code&gt; (time threads wait for connections). Monitor query performance with &lt;code&gt;db.queries.executed&lt;&#x2F;code&gt; (including &lt;code&gt;operation_type&lt;&#x2F;code&gt; and &lt;code&gt;table&lt;&#x2F;code&gt; labels), &lt;code&gt;db.query.duration.ms&lt;&#x2F;code&gt; (with percentile tracking), &lt;code&gt;db.slow_queries.count&lt;&#x2F;code&gt; (queries exceeding thresholds), and &lt;code&gt;db.query.rows_affected&lt;&#x2F;code&gt; (rows returned or modified). For error monitoring, track &lt;code&gt;db.errors.count&lt;&#x2F;code&gt; by &lt;code&gt;error_type&lt;&#x2F;code&gt; (timeout, deadlock, constraint violation) and &lt;code&gt;db.connection_errors.count&lt;&#x2F;code&gt; for connection failures. Connection pool exhaustion is a classic way to kill your entire application: if you support 100 connections and 95 are active, you&#x27;re in danger. Start alerting when you hit 85% utilization.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;message-queues-and-background-processing&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#message-queues-and-background-processing&quot; aria-label=&quot;Anchor link for: message-queues-and-background-processing&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;Message Queues and Background Processing&lt;&#x2F;h3&gt;
&lt;p&gt;Message queues often hide subtle bugs that manifest as slowly growing delays or stuck processing. Track data flow in both directions to catch issues early. For producers, monitor &lt;code&gt;queue.messages.produced&lt;&#x2F;code&gt; (with &lt;code&gt;topic&lt;&#x2F;code&gt; and &lt;code&gt;producer_id&lt;&#x2F;code&gt; labels), &lt;code&gt;queue.messages.failed&lt;&#x2F;code&gt; (with detailed &lt;code&gt;error_type&lt;&#x2F;code&gt; labels), &lt;code&gt;queue.producer.wait_time.ms&lt;&#x2F;code&gt; (time waiting for producer availability), and &lt;code&gt;queue.batch_size&lt;&#x2F;code&gt; (messages sent per batch). For consumers, track &lt;code&gt;queue.messages.consumed&lt;&#x2F;code&gt; (successfully processed), &lt;code&gt;queue.processing.time.ms&lt;&#x2F;code&gt; (per-message duration), &lt;code&gt;queue.processing.errors&lt;&#x2F;code&gt; (failures with &lt;code&gt;error_type&lt;&#x2F;code&gt; and recovery action), &lt;code&gt;jobs.queue.depth&lt;&#x2F;code&gt; (messages waiting), and &lt;code&gt;consumer.lag.ms&lt;&#x2F;code&gt; (how far behind real-time). Background jobs need additional metrics: &lt;code&gt;jobs.started&lt;&#x2F;code&gt;, &lt;code&gt;jobs.completed&lt;&#x2F;code&gt;, &lt;code&gt;jobs.failed&lt;&#x2F;code&gt; (with failure reason), &lt;code&gt;jobs.retry.count&lt;&#x2F;code&gt;, and &lt;code&gt;jobs.execution_time.seconds&lt;&#x2F;code&gt;. Growing queue depth usually means you&#x27;re processing jobs slower than they&#x27;re being created, leading to increasing delays and eventual system overload. Consumer lag helps you understand if you&#x27;re keeping up with real-time processing needs.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;caching-and-locks&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#caching-and-locks&quot; aria-label=&quot;Anchor link for: caching-and-locks&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;Caching and Locks&lt;&#x2F;h3&gt;
&lt;p&gt;For cache performance, track &lt;code&gt;cache.requests.total&lt;&#x2F;code&gt; (with &lt;code&gt;operation&lt;&#x2F;code&gt; labels for get, set, delete), &lt;code&gt;cache.hits&lt;&#x2F;code&gt; and &lt;code&gt;cache.misses&lt;&#x2F;code&gt; (for calculating hit ratio), &lt;code&gt;cache.size.entries&lt;&#x2F;code&gt; (current cached items), &lt;code&gt;cache.size.bytes&lt;&#x2F;code&gt; (memory usage), &lt;code&gt;cache.evictions&lt;&#x2F;code&gt; (items removed with &lt;code&gt;eviction_reason&lt;&#x2F;code&gt;), and &lt;code&gt;cache.operation.duration.ms&lt;&#x2F;code&gt; (time for operations). Hit ratio below 80% usually indicates problems: either you&#x27;re caching the wrong things, cache TTL is too short, or your working set exceeds cache capacity.&lt;&#x2F;p&gt;
&lt;p&gt;For lock and synchronization, monitor &lt;code&gt;locks.acquire.duration.ms&lt;&#x2F;code&gt; (time from requesting to getting lock), &lt;code&gt;locks.held.duration.ms&lt;&#x2F;code&gt; (how long locks are held), &lt;code&gt;locks.contention.count&lt;&#x2F;code&gt; (threads waiting), and &lt;code&gt;locks.timeouts.count&lt;&#x2F;code&gt; (failed acquisitions within timeout). Lock contention can kill your entire application, but it stays invisible without metrics. I&#x27;ve debugged more performance issues with lock metrics than almost any other single type. High acquisition times mean contention; long hold times suggest you&#x27;re doing too much work while holding the lock.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;real-world-instrumentation-patterns&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#real-world-instrumentation-patterns&quot; aria-label=&quot;Anchor link for: real-world-instrumentation-patterns&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;Real-World Instrumentation Patterns&lt;&#x2F;h2&gt;
&lt;h3 id=&quot;the-request-lifecycle-pattern&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#the-request-lifecycle-pattern&quot; aria-label=&quot;Anchor link for: the-request-lifecycle-pattern&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;The Request Lifecycle Pattern&lt;&#x2F;h3&gt;
&lt;p&gt;For every user-facing operation, track the complete journey from entry to exit. This means instrumenting not just the success path, but every branch your code can take. Increment &lt;code&gt;api.requests.received&lt;&#x2F;code&gt; the moment a request hits your service, track &lt;code&gt;auth.attempts.count&lt;&#x2F;code&gt; and &lt;code&gt;auth.failures.count&lt;&#x2F;code&gt; separately to show both volume and failure rate, monitor &lt;code&gt;authorization.decisions.count&lt;&#x2F;code&gt; with labels for &lt;code&gt;granted&lt;&#x2F;code&gt; vs &lt;code&gt;denied&lt;&#x2F;code&gt;, measure &lt;code&gt;business_logic.duration.ms&lt;&#x2F;code&gt; to isolate your application logic performance, and record final &lt;code&gt;response.status_code&lt;&#x2F;code&gt; distribution to understand your error patterns. Most developers instrument the happy path but forget edge cases. A request that fails authentication never reaches your business logic, but it still uses resources and affects user experience. The real value comes from measuring what happens when things go wrong: network timeouts, validation errors, service dependencies failing.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;the-resource-exhaustion-pattern&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#the-resource-exhaustion-pattern&quot; aria-label=&quot;Anchor link for: the-resource-exhaustion-pattern&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;The Resource Exhaustion Pattern&lt;&#x2F;h3&gt;
&lt;p&gt;Systems fail when they run out of resources. The trick is measuring resources before they&#x27;re completely exhausted, giving you time to react. For connection pools, track &lt;code&gt;db.connections.active&lt;&#x2F;code&gt; vs &lt;code&gt;db.connections.max&lt;&#x2F;code&gt; and don&#x27;t wait until you hit 100% utilization: start alerting at 85%. Monitor &lt;code&gt;db.connections.wait_time.ms&lt;&#x2F;code&gt; because long waits indicate you&#x27;re close to exhaustion even if you haven&#x27;t hit the limit. For memory pressure, monitor both &lt;code&gt;memory.heap.used.bytes&lt;&#x2F;code&gt; and &lt;code&gt;gc.frequency.per_minute&lt;&#x2F;code&gt; since high GC frequency often predicts memory pressure before OutOfMemory errors occur. Track &lt;code&gt;memory.allocation.rate.bytes_per_second&lt;&#x2F;code&gt; to understand if your allocation rate is sustainable. For queue management, a growing &lt;code&gt;jobs.queue.depth&lt;&#x2F;code&gt; indicates you&#x27;re processing work slower than it arrives, eventually leading to timeouts and system overload. Track &lt;code&gt;queue.processing.rate.per_second&lt;&#x2F;code&gt; and &lt;code&gt;queue.arrival.rate.per_second&lt;&#x2F;code&gt;: the relationship between these rates tells you if you&#x27;re keeping up. For disk space, track &lt;code&gt;disk.available.bytes&lt;&#x2F;code&gt; and &lt;code&gt;disk.usage.rate.bytes_per_hour&lt;&#x2F;code&gt;. Linear growth can be predicted and prevented, while sudden spikes indicate immediate problems.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;the-business-context-pattern&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#the-business-context-pattern&quot; aria-label=&quot;Anchor link for: the-business-context-pattern&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;The Business Context Pattern&lt;&#x2F;h3&gt;
&lt;p&gt;Technical metrics tell you &lt;em&gt;what&lt;&#x2F;em&gt; is happening; business metrics tell you &lt;em&gt;why&lt;&#x2F;em&gt; it matters. Always pair technical instrumentation with business context to understand the real impact of technical problems. Track &lt;code&gt;api.errors.count&lt;&#x2F;code&gt; alongside &lt;code&gt;orders.lost.count&lt;&#x2F;code&gt; to understand how technical problems affect sales, monitor &lt;code&gt;payment_service.response_time.ms&lt;&#x2F;code&gt; alongside &lt;code&gt;checkout.abandonment.rate&lt;&#x2F;code&gt; to see if slow payments drive users away, and measure &lt;code&gt;search.response_time.ms&lt;&#x2F;code&gt; alongside &lt;code&gt;search.result_clicks.count&lt;&#x2F;code&gt; to understand if slow search reduces engagement. For user experience correlation, pair &lt;code&gt;cache.misses.count&lt;&#x2F;code&gt; with &lt;code&gt;page.load.time.ms&lt;&#x2F;code&gt; to quantify cache performance impact, track &lt;code&gt;db.slow_queries.count&lt;&#x2F;code&gt; alongside &lt;code&gt;user.session.duration.minutes&lt;&#x2F;code&gt; to see if database performance affects user retention, and monitor &lt;code&gt;auth.failures.count&lt;&#x2F;code&gt; with &lt;code&gt;support.tickets.count&lt;&#x2F;code&gt; to predict support load from technical issues. For capacity planning, correlate &lt;code&gt;server.cpu.usage.percent&lt;&#x2F;code&gt; with &lt;code&gt;concurrent.users.count&lt;&#x2F;code&gt; to understand scaling requirements, track &lt;code&gt;memory.usage.bytes&lt;&#x2F;code&gt; alongside &lt;code&gt;active.sessions.count&lt;&#x2F;code&gt; to predict memory needs, and monitor &lt;code&gt;network.bandwidth.used.mbps&lt;&#x2F;code&gt; with &lt;code&gt;file.uploads.count&lt;&#x2F;code&gt; to plan infrastructure scaling. This pairing helps you understand the business impact of technical problems and prioritize fixes based on actual user and revenue impact.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;the-error-classification-pattern&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#the-error-classification-pattern&quot; aria-label=&quot;Anchor link for: the-error-classification-pattern&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;The Error Classification Pattern&lt;&#x2F;h3&gt;
&lt;p&gt;Not all errors are created equal. Classify errors by their impact and actionability to build appropriate response strategies. User errors (4xx) like &lt;code&gt;auth.invalid_credentials&lt;&#x2F;code&gt;, &lt;code&gt;validation.missing_field&lt;&#x2F;code&gt;, or &lt;code&gt;resource.not_found&lt;&#x2F;code&gt; are usually not your fault, but track patterns to identify UX issues. High rates might indicate confusing interfaces or inadequate client-side validation; alert on unusual spikes that might indicate attacks or system confusion. System errors (5xx) like &lt;code&gt;db.connection_timeout&lt;&#x2F;code&gt;, &lt;code&gt;service.unavailable&lt;&#x2F;code&gt;, or &lt;code&gt;memory.exhausted&lt;&#x2F;code&gt; are your responsibility to fix immediately. They&#x27;re always actionable and usually indicate infrastructure or code problems that should trigger immediate alerts and investigation. External dependency errors like &lt;code&gt;payment_gateway.timeout&lt;&#x2F;code&gt;, &lt;code&gt;third_party_api.rate_limited&lt;&#x2F;code&gt;, or &lt;code&gt;cdn.unavailable&lt;&#x2F;code&gt; are outside your direct control but affect users. They require fallback strategies and user communication, and help predict when to escalate with external providers. Distinguish transient errors (&lt;code&gt;network.timeout&lt;&#x2F;code&gt;, &lt;code&gt;rate_limit.exceeded&lt;&#x2F;code&gt; that often resolve themselves) from persistent errors (&lt;code&gt;config.invalid&lt;&#x2F;code&gt;, &lt;code&gt;database.schema_mismatch&lt;&#x2F;code&gt; that require immediate intervention). Each category needs different alerting strategies, escalation procedures, and response timeframes: user errors might warrant daily review, system errors need immediate alerts, external errors require monitoring trends and fallback activation.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;best-practices-for-production-metrics&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#best-practices-for-production-metrics&quot; aria-label=&quot;Anchor link for: best-practices-for-production-metrics&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;Best Practices for Production Metrics&lt;&#x2F;h2&gt;
&lt;h3 id=&quot;naming-conventions-that-scale&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#naming-conventions-that-scale&quot; aria-label=&quot;Anchor link for: naming-conventions-that-scale&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;Naming Conventions That Scale&lt;&#x2F;h3&gt;
&lt;p&gt;Consistent naming prevents the confusion that kills metrics adoption. Use a clear hierarchy: &lt;code&gt;&amp;lt;system&amp;gt;.&amp;lt;component&amp;gt;.&amp;lt;operation&amp;gt;.&amp;lt;metric_type&amp;gt;&lt;&#x2F;code&gt;. Examples include &lt;code&gt;api.auth.requests.count&lt;&#x2F;code&gt;, &lt;code&gt;db.user_queries.duration.ms&lt;&#x2F;code&gt;, &lt;code&gt;cache.metadata.hits.total&lt;&#x2F;code&gt;, and &lt;code&gt;queue.order_processing.messages.consumed&lt;&#x2F;code&gt;. Standardize your suffixes: &lt;code&gt;.count&#x2F;.total&lt;&#x2F;code&gt; for event counters, &lt;code&gt;.current&#x2F;.active&lt;&#x2F;code&gt; for current gauge values, &lt;code&gt;.duration&#x2F;.ms&#x2F;.seconds&lt;&#x2F;code&gt; for time measurements, &lt;code&gt;.bytes&#x2F;.mb&#x2F;.gb&lt;&#x2F;code&gt; for data volume, &lt;code&gt;.errors&#x2F;.failures&lt;&#x2F;code&gt; for error counters, and &lt;code&gt;.ratio&#x2F;.rate&lt;&#x2F;code&gt; for ratios and rates. Avoid mixing naming styles (&lt;code&gt;requestCount&lt;&#x2F;code&gt; vs &lt;code&gt;request_total&lt;&#x2F;code&gt;), ambiguous units (&lt;code&gt;response_time&lt;&#x2F;code&gt; without units), and inconsistent hierarchies (&lt;code&gt;api_requests&lt;&#x2F;code&gt; vs &lt;code&gt;requests.api&lt;&#x2F;code&gt;). This consistency pays off during 3 AM troubleshooting when you don&#x27;t want to waste mental energy remembering naming schemes.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;critical-mistakes-to-avoid&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#critical-mistakes-to-avoid&quot; aria-label=&quot;Anchor link for: critical-mistakes-to-avoid&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;Critical Mistakes to Avoid&lt;&#x2F;h3&gt;
&lt;p&gt;The biggest mistake is using unbounded values as labels. Don&#x27;t tag metrics with user IDs, session tokens, IP addresses, or other unlimited values; your metrics system will eventually explode from too many unique series. Use &lt;code&gt;api.requests{user_type=&quot;premium&quot;, region=&quot;us-west&quot;}&lt;&#x2F;code&gt; instead of &lt;code&gt;api.requests{user_id=&quot;12345&quot;, session=&quot;abc123xyz&quot;}&lt;&#x2F;code&gt;. Always instrument failure cases, not just success paths. Track both &lt;code&gt;payments.succeeded&lt;&#x2F;code&gt; AND &lt;code&gt;payments.failed&lt;&#x2F;code&gt; with error type labels, monitor &lt;code&gt;auth.attempts&lt;&#x2F;code&gt; alongside &lt;code&gt;auth.failures&lt;&#x2F;code&gt; to understand failure rates, and count &lt;code&gt;file.uploads.completed&lt;&#x2F;code&gt; and &lt;code&gt;file.uploads.failed&lt;&#x2F;code&gt; to see processing reliability. Every metric has a cost in storage, network bandwidth, and cognitive load. If you can&#x27;t explain why a metric matters for operations or business decisions, skip it. Ask yourself: &quot;Would this metric help me during an incident?&quot; Metrics that stop updating can be worse than no metrics at all. Always include heartbeat or health check metrics to verify your instrumentation is working; track &lt;code&gt;metrics.last_updated.timestamp&lt;&#x2F;code&gt; to detect collection failures.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;a-note-on-histograms-or-why-they-re-not-here&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#a-note-on-histograms-or-why-they-re-not-here&quot; aria-label=&quot;Anchor link for: a-note-on-histograms-or-why-they-re-not-here&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;A Note on Histograms (Or: Why They&#x27;re Not Here)&lt;&#x2F;h2&gt;
&lt;p&gt;I know what some of you are thinking: &quot;Where are the histograms?&quot; After all, this is a comprehensive guide to application metrics, and histograms are everywhere in monitoring discussions. Well, I deliberately left them out, and here&#x27;s why.&lt;&#x2F;p&gt;
&lt;p&gt;Prometheus histograms are fundamentally broken in ways that make them more dangerous than useful. The core problem is what I call the bucket pre-configuration paradox: you must define bucket boundaries before you know your data distribution. As LinuxCzar eloquently put it in his &lt;a href=&quot;https:&#x2F;&#x2F;linuxczar.net&#x2F;blog&#x2F;2017&#x2F;06&#x2F;15&#x2F;prometheus-histogram-2&#x2F;&quot;&gt;&quot;tale of woe&quot;&lt;&#x2F;a&gt;, this creates an impossible choice between accuracy (many buckets) and operability (few buckets). Get it wrong, and you either lose precision or crash your Prometheus server with &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;prometheus&#x2F;prometheus&#x2F;discussions&#x2F;10598&quot;&gt;cardinality explosion&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;But the problems run deeper. You &lt;a href=&quot;https:&#x2F;&#x2F;www.solarwinds.com&#x2F;blog&#x2F;why-percentiles-dont-work-the-way-you-think&quot;&gt;mathematically cannot aggregate percentiles&lt;&#x2F;a&gt; across instances because the underlying event data is lost. The linear interpolation algorithm produces &lt;a href=&quot;https:&#x2F;&#x2F;prometheus.io&#x2F;docs&#x2F;practices&#x2F;histograms&#x2F;&quot;&gt;significant estimation errors&lt;&#x2F;a&gt;, and Prometheus&#x27;s scraping architecture introduces &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;prometheus&#x2F;prometheus&#x2F;issues&#x2F;1887&quot;&gt;data corruption&lt;&#x2F;a&gt; where histogram buckets update inconsistently. The &lt;a href=&quot;https:&#x2F;&#x2F;chronosphere.io&#x2F;learn&#x2F;histograms-for-complex-systems&#x2F;&quot;&gt;operational burden&lt;&#x2F;a&gt; never ends: every performance improvement potentially invalidates your bucket choices, forcing constant manual reconfiguration.&lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;bsky.app&#x2F;profile&#x2F;catwell.info&quot;&gt;Pierre Chapuis&lt;&#x2F;a&gt; &lt;a href=&quot;https:&#x2F;&#x2F;bsky.app&#x2F;profile&#x2F;catwell.info&#x2F;post&#x2F;3lzxliivegs2k&quot;&gt;pointed out&lt;&#x2F;a&gt; the root cause I missed: Prometheus implements an outdated 2005 algorithm from Cormode et al. for histogram summaries and quantiles. There are much better algorithms available now, including improved versions from the same authors. Check out &lt;a href=&quot;https:&#x2F;&#x2F;cs.uwaterloo.ca&#x2F;~kdaudjee&#x2F;Daudjee_Sketches.pdf&quot;&gt;this paper&lt;&#x2F;a&gt; for a good overview of modern sketch algorithms. The estimation errors and operational problems I described are symptoms of using this old algorithm.&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;p&gt;Instead, I prefer the combination of simple counters and gauges paired with distributed tracing. Trace-derived global metrics give you actual data distributions without guessing bucket boundaries, eliminate the aggregation problem by preserving request context, and adapt automatically as your system evolves. You get better insights with less operational overhead, which seems like a better deal to me.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;quick-reference-metrics-by-component&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#quick-reference-metrics-by-component&quot; aria-label=&quot;Anchor link for: quick-reference-metrics-by-component&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;Quick Reference: Metrics by Component&lt;&#x2F;h2&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Component&lt;&#x2F;th&gt;&lt;th&gt;Essential Metrics&lt;&#x2F;th&gt;&lt;th&gt;Purpose&lt;&#x2F;th&gt;&lt;th&gt;Key Labels&lt;&#x2F;th&gt;&lt;&#x2F;tr&gt;&lt;&#x2F;thead&gt;&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;&lt;strong&gt;API Endpoints&lt;&#x2F;strong&gt;&lt;&#x2F;td&gt;&lt;td&gt;&lt;code&gt;api.requests.total&lt;&#x2F;code&gt;&lt;br&gt;&lt;code&gt;api.response_time.ms&lt;&#x2F;code&gt;&lt;br&gt;&lt;code&gt;api.errors.count&lt;&#x2F;code&gt;&lt;br&gt;&lt;code&gt;auth.failures.count&lt;&#x2F;code&gt;&lt;&#x2F;td&gt;&lt;td&gt;Track every request lifecycle&lt;br&gt;Monitor user-facing performance&lt;br&gt;Catch errors before users complain&lt;br&gt;Security monitoring&lt;&#x2F;td&gt;&lt;td&gt;&lt;code&gt;method&lt;&#x2F;code&gt;, &lt;code&gt;endpoint&lt;&#x2F;code&gt;, &lt;code&gt;status_code&lt;&#x2F;code&gt;&lt;br&gt;&lt;code&gt;endpoint&lt;&#x2F;code&gt;, &lt;code&gt;user_type&lt;&#x2F;code&gt;&lt;br&gt;&lt;code&gt;error_type&lt;&#x2F;code&gt;, &lt;code&gt;endpoint&lt;&#x2F;code&gt;&lt;br&gt;&lt;code&gt;failure_reason&lt;&#x2F;code&gt;&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Database&lt;&#x2F;strong&gt;&lt;&#x2F;td&gt;&lt;td&gt;&lt;code&gt;db.connections.active&lt;&#x2F;code&gt;&lt;br&gt;&lt;code&gt;db.queries.executed&lt;&#x2F;code&gt;&lt;br&gt;&lt;code&gt;db.query.duration.ms&lt;&#x2F;code&gt;&lt;br&gt;&lt;code&gt;db.errors.count&lt;&#x2F;code&gt;&lt;br&gt;&lt;code&gt;db.slow_queries.count&lt;&#x2F;code&gt;&lt;&#x2F;td&gt;&lt;td&gt;Prevent connection exhaustion&lt;br&gt;Track database usage patterns&lt;br&gt;Identify performance bottlenecks&lt;br&gt;Monitor database health&lt;br&gt;Catch expensive queries&lt;&#x2F;td&gt;&lt;td&gt;&lt;code&gt;pool_name&lt;&#x2F;code&gt;&lt;br&gt;&lt;code&gt;operation_type&lt;&#x2F;code&gt;, &lt;code&gt;table&lt;&#x2F;code&gt;&lt;br&gt;&lt;code&gt;operation_type&lt;&#x2F;code&gt;, &lt;code&gt;table&lt;&#x2F;code&gt;&lt;br&gt;&lt;code&gt;error_type&lt;&#x2F;code&gt;, &lt;code&gt;operation&lt;&#x2F;code&gt;&lt;br&gt;&lt;code&gt;table&lt;&#x2F;code&gt;, &lt;code&gt;query_type&lt;&#x2F;code&gt;&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Message Queues&lt;&#x2F;strong&gt;&lt;&#x2F;td&gt;&lt;td&gt;&lt;code&gt;queue.messages.produced&lt;&#x2F;code&gt;&lt;br&gt;&lt;code&gt;queue.messages.consumed&lt;&#x2F;code&gt;&lt;br&gt;&lt;code&gt;queue.processing.time.ms&lt;&#x2F;code&gt;&lt;br&gt;&lt;code&gt;queue.processing.errors&lt;&#x2F;code&gt;&lt;br&gt;&lt;code&gt;jobs.queue.depth&lt;&#x2F;code&gt;&lt;&#x2F;td&gt;&lt;td&gt;Track producer health&lt;br&gt;Monitor consumer throughput&lt;br&gt;Identify processing bottlenecks&lt;br&gt;Catch processing failures&lt;br&gt;Detect backlog buildup&lt;&#x2F;td&gt;&lt;td&gt;&lt;code&gt;topic&lt;&#x2F;code&gt;, &lt;code&gt;producer_id&lt;&#x2F;code&gt;&lt;br&gt;&lt;code&gt;topic&lt;&#x2F;code&gt;, &lt;code&gt;consumer_group&lt;&#x2F;code&gt;&lt;br&gt;&lt;code&gt;topic&lt;&#x2F;code&gt;, &lt;code&gt;message_type&lt;&#x2F;code&gt;&lt;br&gt;&lt;code&gt;error_type&lt;&#x2F;code&gt;, &lt;code&gt;topic&lt;&#x2F;code&gt;&lt;br&gt;&lt;code&gt;queue_name&lt;&#x2F;code&gt;, &lt;code&gt;priority&lt;&#x2F;code&gt;&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Cache&lt;&#x2F;strong&gt;&lt;&#x2F;td&gt;&lt;td&gt;&lt;code&gt;cache.requests.total&lt;&#x2F;code&gt;&lt;br&gt;&lt;code&gt;cache.hits&lt;&#x2F;code&gt;&lt;br&gt;&lt;code&gt;cache.misses&lt;&#x2F;code&gt;&lt;br&gt;&lt;code&gt;cache.size.entries&lt;&#x2F;code&gt;&lt;br&gt;&lt;code&gt;cache.evictions&lt;&#x2F;code&gt;&lt;&#x2F;td&gt;&lt;td&gt;Monitor cache usage&lt;br&gt;Track cache effectiveness&lt;br&gt;Identify cache problems&lt;br&gt;Monitor memory usage&lt;br&gt;Understand eviction patterns&lt;&#x2F;td&gt;&lt;td&gt;&lt;code&gt;cache_type&lt;&#x2F;code&gt;, &lt;code&gt;operation&lt;&#x2F;code&gt;&lt;br&gt;&lt;code&gt;cache_type&lt;&#x2F;code&gt;, &lt;code&gt;key_prefix&lt;&#x2F;code&gt;&lt;br&gt;&lt;code&gt;cache_type&lt;&#x2F;code&gt;, &lt;code&gt;miss_reason&lt;&#x2F;code&gt;&lt;br&gt;&lt;code&gt;cache_type&lt;&#x2F;code&gt;&lt;br&gt;&lt;code&gt;cache_type&lt;&#x2F;code&gt;, &lt;code&gt;eviction_reason&lt;&#x2F;code&gt;&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Locks&lt;&#x2F;strong&gt;&lt;&#x2F;td&gt;&lt;td&gt;&lt;code&gt;locks.acquire.duration.ms&lt;&#x2F;code&gt;&lt;br&gt;&lt;code&gt;locks.held.duration.ms&lt;&#x2F;code&gt;&lt;br&gt;&lt;code&gt;locks.contention.count&lt;&#x2F;code&gt;&lt;&#x2F;td&gt;&lt;td&gt;Detect lock contention&lt;br&gt;Find locks held too long&lt;br&gt;Monitor thread blocking&lt;&#x2F;td&gt;&lt;td&gt;&lt;code&gt;lock_name&lt;&#x2F;code&gt;, &lt;code&gt;thread_type&lt;&#x2F;code&gt;&lt;br&gt;&lt;code&gt;lock_name&lt;&#x2F;code&gt;, &lt;code&gt;operation&lt;&#x2F;code&gt;&lt;br&gt;&lt;code&gt;lock_name&lt;&#x2F;code&gt;&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Business&lt;&#x2F;strong&gt;&lt;&#x2F;td&gt;&lt;td&gt;&lt;code&gt;orders.placed&lt;&#x2F;code&gt;&lt;br&gt;&lt;code&gt;users.login&lt;&#x2F;code&gt;&lt;br&gt;&lt;code&gt;payments.processed&lt;&#x2F;code&gt;&lt;br&gt;&lt;code&gt;feature.usage.count&lt;&#x2F;code&gt;&lt;br&gt;&lt;code&gt;workflow.state_changes&lt;&#x2F;code&gt;&lt;&#x2F;td&gt;&lt;td&gt;Business KPI tracking&lt;br&gt;User activity monitoring&lt;br&gt;Revenue stream health&lt;br&gt;Feature adoption metrics&lt;br&gt;Process flow monitoring&lt;&#x2F;td&gt;&lt;td&gt;&lt;code&gt;user_type&lt;&#x2F;code&gt;, &lt;code&gt;order_value_range&lt;&#x2F;code&gt;&lt;br&gt;&lt;code&gt;user_type&lt;&#x2F;code&gt;, &lt;code&gt;login_method&lt;&#x2F;code&gt;&lt;br&gt;&lt;code&gt;payment_method&lt;&#x2F;code&gt;, &lt;code&gt;amount_range&lt;&#x2F;code&gt;&lt;br&gt;&lt;code&gt;feature_name&lt;&#x2F;code&gt;, &lt;code&gt;user_segment&lt;&#x2F;code&gt;&lt;br&gt;&lt;code&gt;workflow_name&lt;&#x2F;code&gt;, &lt;code&gt;from_state&lt;&#x2F;code&gt;, &lt;code&gt;to_state&lt;&#x2F;code&gt;&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;&#x2F;tbody&gt;&lt;&#x2F;table&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#conclusion&quot; aria-label=&quot;Anchor link for: conclusion&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;Conclusion&lt;&#x2F;h2&gt;
&lt;p&gt;Effective metrics instrumentation isn&#x27;t about collecting everything; it&#x27;s about collecting the right things in the right places. Start with the five essential metric types, instrument your critical components, and build from there.&lt;&#x2F;p&gt;
&lt;p&gt;Think about metrics as part of your application design, not an afterthought. When writing code, ask yourself: &quot;How will I know if this is working correctly in production?&quot; The answer guides your instrumentation decisions.&lt;&#x2F;p&gt;
&lt;p&gt;The best observability system helps you sleep better at night. If your metrics aren&#x27;t giving you confidence in your system&#x27;s health, you&#x27;re measuring the wrong things.&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;p&gt;Feel free to reach out with any questions or to share your experiences with application metrics. You can find me on &lt;a href=&quot;https:&#x2F;&#x2F;twitter.com&#x2F;PierreZ&quot;&gt;Twitter&lt;&#x2F;a&gt;, &lt;a href=&quot;https:&#x2F;&#x2F;bsky.app&#x2F;profile&#x2F;pierrezemb.fr&quot;&gt;Bluesky&lt;&#x2F;a&gt; or through my &lt;a href=&quot;https:&#x2F;&#x2F;pierrezemb.fr&quot;&gt;website&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>Shipped vs. Operated, or How Many Bash Scripts Does It Take?</title>
        <published>2025-08-18T00:00:00+00:00</published>
        <updated>2025-08-18T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Pierre Zemb
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://pierrezemb.fr/posts/shipped-vs-operated/"/>
        <id>https://pierrezemb.fr/posts/shipped-vs-operated/</id>
        
        <category term="distributed-systems" schema="https://pierrezemb.fr/tags/" label="distributed-systems"/>
        <category term="operation" schema="https://pierrezemb.fr/tags/" label="operation"/>
        <content type="html" xml:base="https://pierrezemb.fr/posts/shipped-vs-operated/">&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Summary:&lt;&#x2F;strong&gt; The difference between shipped and operated software is the difference between something you can run and forget, and something that demands ongoing, hands-on care. Choosing the former protects your teamâ€™s focus and sanity.&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;h2 id=&quot;the-shipped-vs-operated-spectrum&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#the-shipped-vs-operated-spectrum&quot; aria-label=&quot;Anchor link for: the-shipped-vs-operated-spectrum&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;The Shipped vs. Operated Spectrum&lt;&#x2F;h2&gt;
&lt;p&gt;Some technologies arrive as complete systems: you deploy them, give them minimal care, and they quietly do their job. Others arrive like complex machines: powerful, but demanding regular attention and maintenance. Thatâ€™s the difference between &lt;em&gt;shipped&lt;&#x2F;em&gt; and &lt;em&gt;operated&lt;&#x2F;em&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;The distinction isnâ€™t just about features; itâ€™s about the level of operational effort the system will demand over its lifetime. &lt;strong&gt;Operated&lt;&#x2F;strong&gt; technologies require continuous human care to stay healthy. They age, drift, and accumulate operational quirks. They often have sharp edges you only discover at 2 a.m., and when something goes wrong, you need people who already know the failure modes by heart. Think of a self-managed &lt;strong&gt;HBase&lt;&#x2F;strong&gt; or a ZooKeeper ensemble that you &lt;em&gt;really&lt;&#x2F;em&gt; hope never splits brain.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Shipped&lt;&#x2F;strong&gt; technologies are built to reduce that constant overhead. They can still fail, but they tend to fail in ways that are predictable, recoverable, and not existential. You can learn them as you go. Your outages will be frustrating, but they wonâ€™t demand a dedicated handler on payroll. &lt;strong&gt;FoundationDB&lt;&#x2F;strong&gt; is a good example: itâ€™s not magic, but its operational surface area is small enough to fit in a single human brain.&lt;&#x2F;p&gt;
&lt;p&gt;For contrast, Iâ€™ve also spent years with the other kind: &lt;strong&gt;HBase&lt;&#x2F;strong&gt; clusters spread over 250+ nodes, &lt;strong&gt;Ceph&lt;&#x2F;strong&gt;, &lt;strong&gt;Kafka&lt;&#x2F;strong&gt; and &lt;strong&gt;ZooKeeper&lt;&#x2F;strong&gt; in various configurations, &lt;strong&gt;Pulsar&lt;&#x2F;strong&gt;, &lt;strong&gt;Warp10&lt;&#x2F;strong&gt;, &lt;strong&gt;etcd&lt;&#x2F;strong&gt;, &lt;strong&gt;Kubernetes&lt;&#x2F;strong&gt;, &lt;strong&gt;Flink&lt;&#x2F;strong&gt;, and &lt;strong&gt;RabbitMQ&lt;&#x2F;strong&gt;, each with its own set of operational â€œadventures.â€&lt;&#x2F;p&gt;
&lt;h2 id=&quot;identifying-operated-systems&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#identifying-operated-systems&quot; aria-label=&quot;Anchor link for: identifying-operated-systems&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;Identifying Operated Systems&lt;&#x2F;h2&gt;
&lt;p&gt;Some systems live in both worlds depending on how you use them. &lt;strong&gt;PostgreSQL&lt;&#x2F;strong&gt; in standalone mode is usually shipped: itâ€™s simple to run, predictable, and rarely causes surprises. But under certain conditions, like fighting vacuum performance at scale or running it in HA mode under sustained heavy load, it shifts into operated territory. The difference isnâ€™t in the codebase, but in the demands your use case puts on it.&lt;&#x2F;p&gt;
&lt;p&gt;A quick way to tell which camp your system belongs to is the &lt;strong&gt;Bash Script Test&lt;&#x2F;strong&gt;: ask how many bash scripts or home-grown tools are required to survive an on-call shift. If the answer includes a collection of automation to clean up data, shuffle it between nodes, or probe the clusterâ€™s health, youâ€™re probably in operated territory. Iâ€™ve been there: running &lt;code&gt;hbck&lt;&#x2F;code&gt; and manually moving regions in &lt;strong&gt;HBase&lt;&#x2F;strong&gt;, shuffling partitions around in &lt;strong&gt;Kafka&lt;&#x2F;strong&gt; to balance load, or triggering repairs in &lt;strong&gt;Ceph&lt;&#x2F;strong&gt; after failed scrub errors. Many distributed systems quietly rely on these manual interventions, often run weekly, to stay healthy, and thatâ€™s an operational cost you canâ€™t ignore.&lt;&#x2F;p&gt;
&lt;p&gt;By contrast, we have &lt;strong&gt;no&lt;&#x2F;strong&gt; such scripts for &lt;strong&gt;FoundationDB&lt;&#x2F;strong&gt;, and thatâ€™s exactly why it feels shipped.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-strategic-cost-of-operations&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#the-strategic-cost-of-operations&quot; aria-label=&quot;Anchor link for: the-strategic-cost-of-operations&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;The Strategic Cost of Operations&lt;&#x2F;h2&gt;
&lt;p&gt;Each operated system consumes a slice of your teamâ€™s focus. Add too many, and youâ€™ll spend more time keeping the lights on than moving forward. The more you can choose robust, low-maintenance software, the more space you keep for actually building new things.&lt;&#x2F;p&gt;
&lt;p&gt;Iâ€™m not a fan of Kubernetes from an operational perspective. But it does something important for end users: it gives them a standard way to write software that reacts to the state of the infrastructure through &lt;a href=&quot;https:&#x2F;&#x2F;kubernetes.io&#x2F;docs&#x2F;concepts&#x2F;extend-kubernetes&#x2F;operator&#x2F;&quot;&gt;Operators&lt;&#x2F;a&gt;. Operators turn that into continuous automation, with a reconciliation loop that keeps drifting systems aligned with the desired state. Itâ€™s a way to bake SRE knowledge into code, so even complex systems can be run and handed over without months of hand-holding.&lt;&#x2F;p&gt;
&lt;p&gt;The stakes are only going to get higher as LLMs become a common tool for software engineers. Weâ€™ll inevitably build more advanced and complex systems, but that complexity doesnâ€™t disappear; it gets pushed to the people on call. LLMs are good at fixing failures that are reproducible and deterministic, because they can alter the system freely, but most on-call incidents arenâ€™t like that. The only way to keep operational load sustainable is to change how we design and test: building for robustness from the start, and using techniques like &lt;a href=&quot;&#x2F;posts&#x2F;simulation-driven-development&#x2F;&quot;&gt;simulation-driven development&lt;&#x2F;a&gt; to expose failure modes before they reach production.&lt;&#x2F;p&gt;
&lt;p&gt;If you can, choose the system you can deploy and leave alone, not the complex machine that demands your weekends.&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;p&gt;Feel free to reach out with any questions or to share your experiences with shipped&#x2F;operated software. You can find me on &lt;a href=&quot;https:&#x2F;&#x2F;twitter.com&#x2F;PierreZ&quot;&gt;Twitter&lt;&#x2F;a&gt;, &lt;a href=&quot;https:&#x2F;&#x2F;bsky.app&#x2F;profile&#x2F;pierrezemb.fr&quot;&gt;Bluesky&lt;&#x2F;a&gt; or through my &lt;a href=&quot;https:&#x2F;&#x2F;pierrezemb.fr&quot;&gt;website&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>Two Podcast Episodes on Topics Developers Rarely Talk About</title>
        <published>2025-08-11T00:00:00+00:00</published>
        <updated>2025-08-11T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Pierre Zemb
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://pierrezemb.fr/posts/debugging-and-correctness-podcasts/"/>
        <id>https://pierrezemb.fr/posts/debugging-and-correctness-podcasts/</id>
        
        <category term="distributed-systems" schema="https://pierrezemb.fr/tags/" label="distributed-systems"/>
        <category term="debugging" schema="https://pierrezemb.fr/tags/" label="debugging"/>
        <category term="correctness" schema="https://pierrezemb.fr/tags/" label="correctness"/>
        <category term="podcasts" schema="https://pierrezemb.fr/tags/" label="podcasts"/>
        <category term="simulation" schema="https://pierrezemb.fr/tags/" label="simulation"/>
        <content type="html" xml:base="https://pierrezemb.fr/posts/debugging-and-correctness-podcasts/">&lt;p&gt;I was listening to a couple of podcasts the other day and stumbled across two episodes that were so compelling I had to stop my chores and listen. They dive into corners of software engineering that most developers barely think about; not because theyâ€™re unimportant, but because they appear in the hard corners of engineering:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;catastrophic data corruption,&lt;&#x2F;li&gt;
&lt;li&gt;correctness work done before a single line is shipped.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;The first is &lt;a href=&quot;https:&#x2F;&#x2F;oxide-and-friends.transistor.fm&#x2F;episodes&#x2F;adventures-in-data-corruption&quot;&gt;Adventures in Data Corruption&lt;&#x2F;a&gt; from &lt;em&gt;Oxide and Friends&lt;&#x2F;em&gt;. Two years ago, the Oxide team ran into data corruption during what should have been a routine network transfer. The debugging journey that followed went from packet traces to CPU speculation quirks, peeling back the stack layer by layer, hardware, kernel, network, application, asking hard questions at each step. What I love here is the combination of clear storytelling and the rapid-fire hypotheses: they make an assumption, test it, discard it, and immediately move to the next, pulling you along in the investigation until the root cause finally clicks into place.&lt;&#x2F;p&gt;
&lt;p&gt;The second is &lt;a href=&quot;https:&#x2F;&#x2F;x.com&#x2F;AntithesisHQ&#x2F;status&#x2F;1953097721205710918&quot;&gt;Scaling Correctness: Marc Brooker on a Decade of Formal Methods at AWS&lt;&#x2F;a&gt; of &lt;em&gt;The BugBash Podcast&lt;&#x2F;em&gt; by Antithesis. Marc Brooker, who has spent nearly 17 years building core AWS services like S3 and Lambda, shares the companyâ€™s decade-long journey with formal methods, from heavyweight tools like TLA+ to the &lt;em&gt;lightweight&lt;&#x2F;em&gt; approaches that any team can adopt like &lt;a href=&quot;&#x2F;tags&#x2F;simulation&quot;&gt;simulation-based testing&lt;&#x2F;a&gt;. At AWS, theyâ€™ve learned that investing in correctness up front not only improves reliability but actually speeds up delivery. They also touch on deterministic simulation testing, the challenge of verifying UIs and control planes, and the role AI might play in the future of verification.&lt;&#x2F;p&gt;
&lt;p&gt;Iâ€™ve been paged way too many times for metastable failures, data corruption, network meltdowns, or NTP drift in production. These days, Iâ€™d rather tackle the correctness part &lt;em&gt;before&lt;&#x2F;em&gt; those alarms go off. Every new layer I build is designed to be simulated to explore failure modes in a controlled environment before they can hurt real users.&lt;&#x2F;p&gt;
&lt;p&gt;But when things fall apart anyway, and spoilers &lt;strong&gt;they will&lt;&#x2F;strong&gt;, developers have the opportunity to truly understand their software. Being responsible for the systems you build means youâ€™re the one getting paged, and itâ€™s in those moments of crisis that the sharpest debugging skills are forged.&lt;&#x2F;p&gt;
&lt;p&gt;So donâ€™t just bookmark them. Put them at the top of your queue. Listen. And maybe, the next time your system misbehaves, youâ€™ll be ready.&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;p&gt;Feel free to reach out with any questions or to share your experiences with debugging and correctness. You can find me on &lt;a href=&quot;https:&#x2F;&#x2F;twitter.com&#x2F;PierreZ&quot;&gt;Twitter&lt;&#x2F;a&gt;, &lt;a href=&quot;https:&#x2F;&#x2F;bsky.app&#x2F;profile&#x2F;pierrezemb.fr&quot;&gt;Bluesky&lt;&#x2F;a&gt; or through my &lt;a href=&quot;https:&#x2F;&#x2F;pierrezemb.fr&quot;&gt;website&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>Bypassing FoundationDB&#x27;s Transaction Limits with Record Layer Continuations</title>
        <published>2025-06-03T00:30:00+02:00</published>
        <updated>2025-06-03T00:30:00+02:00</updated>
        
        <author>
          <name>
            
              Pierre Zemb
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://pierrezemb.fr/posts/understanding-fdb-record-layer-continuations/"/>
        <id>https://pierrezemb.fr/posts/understanding-fdb-record-layer-continuations/</id>
        
        <category term="foundationdb" schema="https://pierrezemb.fr/tags/" label="foundationdb"/>
        <category term="record-layer" schema="https://pierrezemb.fr/tags/" label="record-layer"/>
        <category term="java" schema="https://pierrezemb.fr/tags/" label="java"/>
        <category term="database" schema="https://pierrezemb.fr/tags/" label="database"/>
        <category term="continuation" schema="https://pierrezemb.fr/tags/" label="continuation"/>
        <category term="pagination" schema="https://pierrezemb.fr/tags/" label="pagination"/>
        <category term="distributed-systems" schema="https://pierrezemb.fr/tags/" label="distributed-systems"/>
        <content type="html" xml:base="https://pierrezemb.fr/posts/understanding-fdb-record-layer-continuations/">&lt;h2 id=&quot;introducing-the-foundationdb-record-layer&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#introducing-the-foundationdb-record-layer&quot; aria-label=&quot;Anchor link for: introducing-the-foundationdb-record-layer&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;Introducing the FoundationDB Record Layer&lt;&#x2F;h2&gt;
&lt;p&gt;Before we dive into the specifics of handling large operations with continuations (the main topic of this post), let&#x27;s briefly introduce the &lt;a href=&quot;https:&#x2F;&#x2F;foundationdb.github.io&#x2F;fdb-record-layer&#x2F;index.html&quot;&gt;&lt;strong&gt;FoundationDB Record Layer&lt;&#x2F;strong&gt;&lt;&#x2F;a&gt;. It&#x27;s a powerful open-source library built atop FoundationDB that brings a structured, record-oriented data model to FDB&#x27;s highly scalable key-value store. Think of it as adding schema management, rich indexing capabilities, and a sophisticated query engine, making it easier to build complex applications.&lt;&#x2F;p&gt;
&lt;p&gt;The Record Layer is versatile and has been adopted for demanding use-cases, most notably by Apple as the core of CloudKit, powering services for millions of users. It allows developers to define their data models using Protocol Buffers and then query them in a flexible manner.&lt;&#x2F;p&gt;
&lt;p&gt;For instance, you can express queries like finding all &#x27;Order&#x27; records for roses costing less than $50 with a declarative API (example in Java):&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;java&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-java &quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;&lt;span style=&quot;color:#ebcb8b;&quot;&gt;RecordQuery&lt;&#x2F;span&gt;&lt;span&gt; query = &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ebcb8b;&quot;&gt;RecordQuery&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;newBuilder&lt;&#x2F;span&gt;&lt;span&gt;()
&lt;&#x2F;span&gt;&lt;span&gt;        .&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;setRecordType&lt;&#x2F;span&gt;&lt;span&gt;(&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Order&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;)
&lt;&#x2F;span&gt;&lt;span&gt;        .&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;setFilter&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ebcb8b;&quot;&gt;Query&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;and&lt;&#x2F;span&gt;&lt;span&gt;(
&lt;&#x2F;span&gt;&lt;span&gt;                &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ebcb8b;&quot;&gt;Query&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;field&lt;&#x2F;span&gt;&lt;span&gt;(&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;price&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;).&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;lessThan&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;50&lt;&#x2F;span&gt;&lt;span&gt;),
&lt;&#x2F;span&gt;&lt;span&gt;                &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ebcb8b;&quot;&gt;Query&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;field&lt;&#x2F;span&gt;&lt;span&gt;(&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;flower&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;).&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;matches&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ebcb8b;&quot;&gt;Query&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;field&lt;&#x2F;span&gt;&lt;span&gt;(&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;type&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;).&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;equalsValue&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ebcb8b;&quot;&gt;FlowerType&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;ROSE&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;name&lt;&#x2F;span&gt;&lt;span&gt;()))))
&lt;&#x2F;span&gt;&lt;span&gt;        .&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;build&lt;&#x2F;span&gt;&lt;span&gt;();
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;To get started and explore its capabilities further, the official &lt;a href=&quot;https:&#x2F;&#x2F;foundationdb.github.io&#x2F;fdb-record-layer&#x2F;GettingStarted.html&quot;&gt;Getting Started Guide&lt;&#x2F;a&gt; is an excellent resource. You can also watch these talks for a deeper understanding:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=SvoUHHM9IKU&quot;&gt;Using FoundationDB and the FDB Record Layer to Build CloudKit - Scott Gray, Apple&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=HLE8chgw6LI&quot;&gt;FoundationDB Record Layer: Open Source Structured Storage on FoundationDB - Nicholas Schiefer, Apple&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;blockquote&gt;
&lt;p&gt;For a detailed academic perspective on its design and how CloudKit uses it, refer to the &lt;a href=&quot;https:&#x2F;&#x2F;www.foundationdb.org&#x2F;files&#x2F;record-layer-paper.pdf&quot;&gt;SIGMOD&#x27;19 paper: FoundationDB Record Layer: A Multi-Tenant Structured Datastore&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;h2 id=&quot;the-challenge-fdb-s-transaction-constraints&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#the-challenge-fdb-s-transaction-constraints&quot; aria-label=&quot;Anchor link for: the-challenge-fdb-s-transaction-constraints&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;The Challenge: FDB&#x27;s Transaction Constraints&lt;&#x2F;h2&gt;
&lt;p&gt;FoundationDB (FDB) imposes strict constraints on its transactions: they must complete within 5 seconds and are limited to 10MB of manipulated data, either writes or reads. These constraints are fundamental to FDB&#x27;s design, ensuring high performance and serializable isolation. However, they pose a significant challenge for operations that inherently require processing large datasets or executing complex queries that cannot complete within these tight boundaries, such as full table scans, large analytical queries, or bulk data exports.&lt;&#x2F;p&gt;
&lt;p&gt;The &lt;strong&gt;FoundationDB Record Layer&lt;&#x2F;strong&gt; addresses this challenge through a mechanism known as &lt;strong&gt;continuations&lt;&#x2F;strong&gt;. Continuations allow a single logical operation to be broken down into a sequence of smaller, independent FDB transactions. Each transaction processes a segment of the total workload and, if more work remains, yields a &lt;strong&gt;continuation token&lt;&#x2F;strong&gt;. This opaque token encapsulates the state required to resume the operation precisely where the previous transaction left off.&lt;&#x2F;p&gt;
&lt;p&gt;This article delves into the technical details of Record Layer continuations, exploring how they function and how to leverage them effectively to build robust, scalable applications on FDB.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;bridging-transactions-the-role-of-continuations&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#bridging-transactions-the-role-of-continuations&quot; aria-label=&quot;Anchor link for: bridging-transactions-the-role-of-continuations&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;Bridging Transactions: The Role of Continuations&lt;&#x2F;h2&gt;
&lt;p&gt;Consider a query to retrieve all records matching a specific filter from a large dataset. Executing this as a single FDB transaction would likely violate the 5-second or 10MB limit. The Record Layer employs continuations to serialize this operation across multiple transactions:&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Initial Request:&lt;&#x2F;strong&gt; The application initiates a query against the Record Layer.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Segmented Execution:&lt;&#x2F;strong&gt; The Record Layer&#x27;s query planner executes the query, but with built-in scan limiters. It processes records until a predefined limit (e.g., row count, time duration, or byte size) is approached, or it nears FDB&#x27;s intrinsic transaction limits.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;State Serialization:&lt;&#x2F;strong&gt; Before the current FDB transaction commits, if the logical operation is incomplete, the Record Layer serializes the execution state of the query plan into a continuation token.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Partial Result &amp;amp; Token:&lt;&#x2F;strong&gt; The application receives the processed segment of data and the continuation token. The FDB transaction for this segment commits successfully.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Resumption:&lt;&#x2F;strong&gt; To fetch the next segment, the application submits a new request, providing the previously received continuation token.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;State Deserialization &amp;amp; Continued Execution:&lt;&#x2F;strong&gt; The Record Layer deserializes the token, restores the query plan&#x27;s state, and resumes execution from the exact point it paused. This typically involves adjusting scan boundaries (e.g., starting a key-range scan from the key after the last one processed).&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;This cycle repeats until the entire logical operation is complete. The continuation token acts as the critical link, enabling a series of short, FDB-compliant transactions to collectively achieve the effect of a single, long-running operation without violating FDB&#x27;s core constraints.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;dissecting-the-continuation-token&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#dissecting-the-continuation-token&quot; aria-label=&quot;Anchor link for: dissecting-the-continuation-token&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;Dissecting the Continuation Token&lt;&#x2F;h2&gt;
&lt;p&gt;While the continuation token is &lt;strong&gt;opaque&lt;&#x2F;strong&gt; to the application (it&#x27;s a &lt;code&gt;byte[]&lt;&#x2F;code&gt; that should not be introspected or modified), it internally contains structured information vital for resuming query execution. The exact format is an implementation detail of the Record Layer and can evolve, but conceptually, it must capture:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Scan Boundaries:&lt;&#x2F;strong&gt; The key (or keys, for multi-dimensional indexes) where the next scan segment should begin. This ensures no data is missed or re-processed unnecessarily.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Query Plan State:&lt;&#x2F;strong&gt; For complex query plans involving joins, filters, aggregations, or in-memory sorting, the token may need to store intermediate state specific to those operators. For instance, a &lt;code&gt;UnionPlan&lt;&#x2F;code&gt; or &lt;code&gt;IntersectionPlan&lt;&#x2F;code&gt; might need to remember which child plan was active and its respective continuation.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Scan Limiter State:&lt;&#x2F;strong&gt; Information about accumulated counts or sizes if the scan was paused due to application-defined limits rather than FDB limits.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Version Information:&lt;&#x2F;strong&gt; To ensure compatibility if the token format changes across Record Layer versions.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;The opacity of the token is a deliberate design choice. It decouples the application from the internal mechanics of the Record Layer, allowing the latter to evolve its continuation strategies (e.g., for efficiency or new features) without breaking client applications. The application&#x27;s responsibility is solely to store and return this token verbatim.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;resuming-query-execution-via-continuations&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#resuming-query-execution-via-continuations&quot; aria-label=&quot;Anchor link for: resuming-query-execution-via-continuations&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;Resuming Query Execution via Continuations&lt;&#x2F;h2&gt;
&lt;p&gt;When a continuation token is provided to a &lt;code&gt;RecordCursor&lt;&#x2F;code&gt; (the Record Layer&#x27;s abstraction for iterating over query results), the underlying &lt;code&gt;RecordQueryPlan&lt;&#x2F;code&gt; uses it to reconstruct its state.&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Plan Identification:&lt;&#x2F;strong&gt; The token typically identifies the specific query plan or sub-plan it pertains to.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;State Restoration:&lt;&#x2F;strong&gt; Each operator in the query plan (e.g., &lt;code&gt;IndexScanPlan&lt;&#x2F;code&gt;, &lt;code&gt;FilterPlan&lt;&#x2F;code&gt;, &lt;code&gt;SortPlan&lt;&#x2F;code&gt;) that can be stateful across transaction boundaries implements logic to initialize itself from the continuation. For an &lt;code&gt;IndexScanPlan&lt;&#x2F;code&gt;, this primarily means setting the &lt;code&gt;ScanComparisons&lt;&#x2F;code&gt; for the next range read. For a &lt;code&gt;UnionPlan&lt;&#x2F;code&gt;, it might mean restoring the continuation for one of its child plans and indicating which child to resume.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Execution Resumption:&lt;&#x2F;strong&gt; Once the plan&#x27;s state is restored, the &lt;code&gt;RecordCursor&lt;&#x2F;code&gt; can proceed to fetch the next batch of records. The execution effectively &quot;jumps&quot; to the point encoded in the continuation.&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;This mechanism allows the Record Layer to transparently manage the complexities of distributed, stateful iteration over potentially vast datasets, all while adhering to FDB&#x27;s transactional model.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;implications-of-non-atomicity&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#implications-of-non-atomicity&quot; aria-label=&quot;Anchor link for: implications-of-non-atomicity&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;Implications of Non-Atomicity&lt;&#x2F;h2&gt;
&lt;p&gt;It&#x27;s important to understand a key implication of this multi-transaction approach: while each individual FDB transaction executed as part of a continued operation is atomic and isolated (typically providing serializable isolation), the overall logical operation spanning multiple continuations is &lt;strong&gt;not atomic&lt;&#x2F;strong&gt; in the same way. Mutations to the data by other concurrent transactions can occur &lt;em&gt;between&lt;&#x2F;em&gt; the FDB transactions of a continued scan. As a result, a long-running operation that uses continuations doesn&#x27;t see the entire dataset at a single, frozen moment in time. Instead, it might see some data that was present or changed &lt;em&gt;after&lt;&#x2F;em&gt; the operation began but &lt;em&gt;before&lt;&#x2F;em&gt; it completed. This is a natural consequence of breaking the work into smaller pieces to fit within FDB&#x27;s transaction limits. Applications should be aware of this behavior, particularly if they need all the data to reflect its state from one specific instant.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#conclusion&quot; aria-label=&quot;Anchor link for: conclusion&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;Conclusion&lt;&#x2F;h2&gt;
&lt;p&gt;The Record Layer&#x27;s continuation feature is a powerful tool for handling large datasets and complex queries in FoundationDB, but it&#x27;s important to understand the implications of non-atomicity. By breaking operations into smaller, FDB-compliant transactions, the Record Layer provides a flexible and scalable solution while maintaining the core principles of FDB&#x27;s transactional model.&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;p&gt;Feel free to reach out with any questions or to share your thoughts. You can find me on &lt;a href=&quot;https:&#x2F;&#x2F;bsky.app&#x2F;profile&#x2F;pierrezemb.fr&quot;&gt;Bluesky&lt;&#x2F;a&gt;, &lt;a href=&quot;https:&#x2F;&#x2F;twitter.com&#x2F;PierreZ&quot;&gt;Twitter&lt;&#x2F;a&gt; or through my &lt;a href=&quot;https:&#x2F;&#x2F;pierrezemb.fr&quot;&gt;website&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
</content>
        
    </entry>
</feed>
