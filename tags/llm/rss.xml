<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
      <title>Pierre Zemb&#x27;s Blog - llm</title>
      <link>https://pierrezemb.fr</link>
      <description>Pierre Zemb personal blog</description>
      <generator>Zola</generator>
      <language>en</language>
      <atom:link href="https://pierrezemb.fr/tags/llm/rss.xml" rel="self" type="application/rss+xml"/>
      <lastBuildDate>Fri, 19 Dec 2025 00:00:00 +0000</lastBuildDate>
      <item>
          <title>Specs Are Back, But We&#x27;re Missing the Tools</title>
          <pubDate>Fri, 19 Dec 2025 00:00:00 +0000</pubDate>
          <author>Pierre Zemb</author>
          <link>https://pierrezemb.fr/posts/specs-are-back/</link>
          <guid>https://pierrezemb.fr/posts/specs-are-back/</guid>
          <description xml:base="https://pierrezemb.fr/posts/specs-are-back/">&lt;p&gt;I truly think LLMs are changing how we write software. For me, it&#x27;s been a massive productivity boost. I can ask Claude to read some piece of code and explain it to me, or make a quick PoC of something, or refactor stuff that would take me hours. I even used it to help me &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;PierreZ&#x2F;moonpool&quot;&gt;backport features from FoundationDB in Rust&lt;&#x2F;a&gt;, and it worked surprisingly well ðŸ¤¯&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;world.hey.com&#x2F;joaoqalves&#x2F;when-software-becomes-fast-food-23147c9b&quot;&gt;JoÃ£o Alves made a great point recently&lt;&#x2F;a&gt;: code is becoming like fast food. Cheap, fast, everywhere. You ask an LLM to generate something, it compiles, the tests pass, and you ship it. For critical systems, &lt;a href=&quot;&#x2F;posts&#x2F;diving-into-foundationdb-simulation&#x2F;&quot;&gt;simulation testing&lt;&#x2F;a&gt; can validate that code actually survives production chaos.&lt;&#x2F;p&gt;
&lt;p&gt;But here&#x27;s what I keep running into: we&#x27;re still using &lt;strong&gt;natural language&lt;&#x2F;strong&gt; to prompt, correct, and guide LLMs. Vague instructions produce vague code. The bottleneck isn&#x27;t writing code anymore, it&#x27;s knowing &lt;strong&gt;what&lt;&#x2F;strong&gt; to write in the first place.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;why-specs-died-in-the-first-place&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#why-specs-died-in-the-first-place&quot; aria-label=&quot;Anchor link for: why-specs-died-in-the-first-place&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;Why specs died in the first place&lt;&#x2F;h2&gt;
&lt;p&gt;Ask any engineering team &quot;where&#x27;s the spec for this service?&quot; and you&#x27;ll probably get one of three answers: blank stares, a link to some 3-year-old Google doc that&#x27;s completely outdated, or my personal favorite, &quot;the code is the spec.&quot;&lt;&#x2F;p&gt;
&lt;p&gt;I think the problem was simple: &lt;strong&gt;specs had no feedback loop&lt;&#x2F;strong&gt;. Code compiles, tests pass, but specs? They just sit there. Nobody validates them, nobody updates them. Six months later, the spec has become archaeology, and new team members learn to ignore it because they can&#x27;t trust it anyway.&lt;&#x2F;p&gt;
&lt;p&gt;What changed is that LLMs can actually &lt;strong&gt;read&lt;&#x2F;strong&gt; specifications now. And suddenly, specs aren&#x27;t dead documents anymore. They&#x27;re instructions that can be executed. I&#x27;ve found two modes that actually work:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Generation&lt;&#x2F;strong&gt;: you give an LLM a structured spec, and it gives you an implementation&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Validation&lt;&#x2F;strong&gt;: you give an LLM some existing code and a spec, and ask &quot;does this implementation actually respect the specification?&quot;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;spec-kit-and-the-right-prompt-chain&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#spec-kit-and-the-right-prompt-chain&quot; aria-label=&quot;Anchor link for: spec-kit-and-the-right-prompt-chain&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;spec-kit and the right prompt chain&lt;&#x2F;h2&gt;
&lt;p&gt;I tried &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;github&#x2F;spec-kit&quot;&gt;spec-kit&lt;&#x2F;a&gt; a while ago and found it pretty useful. What it does well is guide you through a structured chain of prompts: you start with a Constitution (your project principles), then you write Specifications (requirements with acceptance criteria), then Technical Plans, then Tasks, and finally Implementation.&lt;&#x2F;p&gt;
&lt;p&gt;It sounds obvious when I write it like that, but it&#x27;s surprisingly effective. This isn&#x27;t scattered TODO comments. It&#x27;s a queryable structure that builds context progressively, and the LLM can use all of it.&lt;&#x2F;p&gt;
&lt;p&gt;The generated code was actually good, because spec-kit forced me to build the right context first. And here&#x27;s what surprised me: the LLM kept challenging my vague requirements. Every time I wrote something like &quot;handle edge cases,&quot; it would ask &quot;what happens when X? what about Y?&quot; until the spec was actually implementable.&lt;&#x2F;p&gt;
&lt;p&gt;I think that&#x27;s the trick. &lt;strong&gt;Context is everything&lt;&#x2F;strong&gt;. Build the right context, and the LLM produces the right code.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-limits-of-english&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#the-limits-of-english&quot; aria-label=&quot;Anchor link for: the-limits-of-english&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;The limits of English&lt;&#x2F;h2&gt;
&lt;p&gt;Here&#x27;s where I hit a wall though. English-based specs work great for user stories and acceptance criteria, the kind of stuff product managers care about. But for algorithms and system behavior? Natural language gets ambiguous really fast.&lt;&#x2F;p&gt;
&lt;p&gt;&quot;Handle concurrent access&quot; means different things to different people. &quot;Ensure consistency&quot; is even worse. When you&#x27;re designing distributed algorithms with subtle timing constraints, you need precision. English just doesn&#x27;t cut it.&lt;&#x2F;p&gt;
&lt;p&gt;I needed something more engineering-driven. Not formal verification for academic purposes, but practical precision that the whole team could read and reason about.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;finding-an-engineering-driven-approach&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#finding-an-engineering-driven-approach&quot; aria-label=&quot;Anchor link for: finding-an-engineering-driven-approach&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;Finding an engineering-driven approach&lt;&#x2F;h2&gt;
&lt;p&gt;I started looking at formal methods. &lt;a href=&quot;https:&#x2F;&#x2F;lamport.azurewebsites.net&#x2F;video&#x2F;videos.html&quot;&gt;TLA+&lt;&#x2F;a&gt; is the classic choice, but the notation felt like another language to maintain. I didn&#x27;t want to be the only one on the team who could read the specs. I&#x27;ve been there before with other technologies, and it&#x27;s not a great place to be ðŸ˜…&lt;&#x2F;p&gt;
&lt;p&gt;Then &lt;a href=&quot;https:&#x2F;&#x2F;bsky.app&#x2F;profile&#x2F;alexmillerdb.bsky.social&#x2F;post&#x2F;3m6ptancmus2o&quot;&gt;a friend&lt;&#x2F;a&gt; suggested &lt;a href=&quot;https:&#x2F;&#x2F;fizzbee.io&quot;&gt;Fizzbee&lt;&#x2F;a&gt;. It&#x27;s based on Starlark, a Python dialect. Model checking without the TLA+ notation. The whole team can contribute.&lt;&#x2F;p&gt;
&lt;p&gt;Learning new languages with LLMs works well. The trick is to find or generate a spec of the language first, then ask for a tutorial tailored to your specific problem. I asked Claude to write a Starlark reference and a Fizzbee concepts recap. Now we share vocabulary, and the conversations are productive.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-we-re-still-missing&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#what-we-re-still-missing&quot; aria-label=&quot;Anchor link for: what-we-re-still-missing&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;What we&#x27;re still missing&lt;&#x2F;h2&gt;
&lt;p&gt;Fizzbee is great for what it does. For algorithms and concurrency, model checking feels like the Rust compiler but for higher-level design. It explores all possible states and finds bugs before any code exists. Here&#x27;s what an invariant looks like:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;python&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-python &quot;&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# Safety: no duplicate completions
&lt;&#x2F;span&gt;&lt;span&gt;always assertion NoDuplicateCompletions:
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;return &lt;&#x2F;span&gt;&lt;span style=&quot;color:#96b5b4;&quot;&gt;len&lt;&#x2F;span&gt;&lt;span&gt;(completed) == &lt;&#x2F;span&gt;&lt;span style=&quot;color:#96b5b4;&quot;&gt;len&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;set&lt;&#x2F;span&gt;&lt;span&gt;(completed))
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Readable by anyone who knows Python.&lt;&#x2F;p&gt;
&lt;p&gt;But most software isn&#x27;t distributed algorithms. Most of what we build is about storing data in databases, sending messages to queues, calling other services, transforming inputs into outputs.&lt;&#x2F;p&gt;
&lt;p&gt;And we describe this behavior in a dozen different places: C4 diagrams for architecture, OpenAPI for HTTP endpoints, protobuf for message schemas, ADRs for decisions, markdown for everything else. No single notation captures the full picture.&lt;&#x2F;p&gt;
&lt;p&gt;I keep thinking about what this tool would need to be. It should be &lt;strong&gt;compact&lt;&#x2F;strong&gt;, short enough to fit in an LLM&#x27;s context window without eating thousands of tokens. It should work at both levels: service interactions (&quot;UserService stores in Postgres, publishes to Kafka&quot;) and function behavior (&quot;validateUser checks format, queries DB, returns DTO&quot;). It should be the &lt;strong&gt;common language&lt;&#x2F;strong&gt; that both the team and the LLM can read, write, and reason about.&lt;&#x2F;p&gt;
&lt;p&gt;Most importantly, it should be &lt;strong&gt;verifiable&lt;&#x2F;strong&gt;. Not just documentation that sits there, but something that can actually validate whether an implementation matches what we said it would do. The feedback loop that specs never had.&lt;&#x2F;p&gt;
&lt;p&gt;OpenAPI gets close for HTTP APIs. You can validate requests, generate clients, catch breaking changes. But for the rest? For business logic, for service contracts that aren&#x27;t just endpoints, for the behavior that actually matters? The tooling doesn&#x27;t exist yet.&lt;&#x2F;p&gt;
&lt;p&gt;As the old joke goes, &lt;a href=&quot;https:&#x2F;&#x2F;www.commitstrip.com&#x2F;en&#x2F;2016&#x2F;08&#x2F;25&#x2F;a-very-comprehensive-and-precise-spec&#x2F;&quot;&gt;a spec precise enough to generate code is just called code&lt;&#x2F;a&gt;. But there has to be something in between prose and implementation. And yes, I&#x27;m aware that proposing a new format makes me &lt;a href=&quot;https:&#x2F;&#x2F;xkcd.com&#x2F;927&#x2F;&quot;&gt;the 15th competing standard&lt;&#x2F;a&gt;. But if you&#x27;ve found something that fills this gap, or have ideas about what it should look like, I&#x27;d love to hear about it.&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;p&gt;Feel free to reach out to share your thoughts on spec tooling. You can find me on &lt;a href=&quot;https:&#x2F;&#x2F;twitter.com&#x2F;PierreZ&quot;&gt;Twitter&lt;&#x2F;a&gt;, &lt;a href=&quot;https:&#x2F;&#x2F;bsky.app&#x2F;profile&#x2F;pierrezemb.fr&quot;&gt;Bluesky&lt;&#x2F;a&gt; or through my &lt;a href=&quot;https:&#x2F;&#x2F;pierrezemb.fr&quot;&gt;website&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
</description>
          <category domain="tag">software-engineering</category>
          <category domain="tag">llm</category>
          <category domain="tag">specifications</category>
          <category domain="tag">formal-methods</category>
          <category domain="tag">model-checking</category>
          <category domain="tag">fizzbee</category>
      </item>
      <item>
          <title>Testing: prevention vs discovery</title>
          <pubDate>Mon, 08 Sep 2025 00:00:00 +0000</pubDate>
          <author>Pierre Zemb</author>
          <link>https://pierrezemb.fr/posts/testing-prevention-vs-discovery/</link>
          <guid>https://pierrezemb.fr/posts/testing-prevention-vs-discovery/</guid>
          <description xml:base="https://pierrezemb.fr/posts/testing-prevention-vs-discovery/">&lt;p&gt;While working on &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;PierreZ&#x2F;moonpool&quot;&gt;moonpool&lt;&#x2F;a&gt;, my hobby project for studying and backporting FoundationDB&#x27;s low-level engineering concepts (actor model, deterministic simulation, network fault injection), Claude Code did something remarkable: it found a bug I didn&#x27;t know existed on its own. Not through traditional testing, but through active exploration of edge cases I hadn&#x27;t considered.&lt;&#x2F;p&gt;
&lt;div style=&quot;text-align: center;&quot;&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;testing-prevention-vs-discovery&#x2F;claude-moonpool.png&quot; alt=&quot;Claude Code autonomously debugging moonpool&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;&#x2F;div&gt;
&lt;p&gt;Claude identified a faulty seed triggering an edge case, debugged it locally using deterministic replay, and added it to the test suite. All by itself. ðŸ¤¯ &lt;strong&gt;This wasn&#x27;t prevention but discovery.&lt;&#x2F;strong&gt; It&#x27;s time to shift our testing paradigm from preventing regressions to actively discovering unknown bugs.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;building-for-discovery&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#building-for-discovery&quot; aria-label=&quot;Anchor link for: building-for-discovery&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;Building for Discovery&lt;&#x2F;h2&gt;
&lt;p&gt;The difference between prevention and discovery isn&#x27;t just philosophical but requires completely different system design. Moonpool was built from day one around three principles that enable active bug discovery:&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Deterministic simulation&lt;&#x2F;strong&gt;: Every execution is completely reproducible. Given the same seed, the system makes identical decisions every time. This changes debugging from &quot;I can&#x27;t reproduce this&quot; to &quot;let me replay exactly what happened.&quot; More importantly, it lets LLMs explore the state space step by step without getting lost in non-deterministic noise.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Controlled failure injection&lt;&#x2F;strong&gt;: Built-in mechanisms intentionally introduce failures in controlled, reproducible ways. This includes timed failures like network delays and disconnects, plus &lt;a href=&quot;https:&#x2F;&#x2F;transactional.blog&#x2F;simulation&#x2F;buggify&quot;&gt;&quot;buggify&quot; mechanisms&lt;&#x2F;a&gt; that inject faulty internal state at strategic points in the code. Each buggify point is either enabled or disabled for an entire simulation run, creating consistent failure scenarios instead of random chaos. Instead of waiting for production to reveal edge cases, we force the system to encounter dangerous, bug-finding behaviors during development.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Observability through sometimes assertions&lt;&#x2F;strong&gt;: Borrowed from &lt;a href=&quot;https:&#x2F;&#x2F;antithesis.com&#x2F;docs&#x2F;best_practices&#x2F;sometimes_assertions&#x2F;&quot;&gt;Antithesis&lt;&#x2F;a&gt;, these verify we&#x27;re actually discovering the edge cases we think we&#x27;re testing. Here&#x27;s what they look like:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;rust&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-rust &quot;&gt;&lt;code class=&quot;language-rust&quot; data-lang=&quot;rust&quot;&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; Verify that server binds sometimes fail during chaos testing
&lt;&#x2F;span&gt;&lt;span&gt;sometimes_assert!(
&lt;&#x2F;span&gt;&lt;span&gt;    server_bind_fails,
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;self&lt;&#x2F;span&gt;&lt;span&gt;.bind_result.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#96b5b4;&quot;&gt;is_err&lt;&#x2F;span&gt;&lt;span&gt;(),
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Server bind should sometimes fail during chaos testing&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;);
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; Ensure message queues sometimes approach capacity under load
&lt;&#x2F;span&gt;&lt;span&gt;sometimes_assert!(
&lt;&#x2F;span&gt;&lt;span&gt;    peer_queue_near_capacity,
&lt;&#x2F;span&gt;&lt;span&gt;    state.send_queue.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#96b5b4;&quot;&gt;len&lt;&#x2F;span&gt;&lt;span&gt;() &amp;gt;= (&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;self&lt;&#x2F;span&gt;&lt;span&gt;.config.max_queue_size as &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;f64 &lt;&#x2F;span&gt;&lt;span&gt;* &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;0.8&lt;&#x2F;span&gt;&lt;span&gt;) as &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;usize&lt;&#x2F;span&gt;&lt;span&gt;,
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Message queue should sometimes approach capacity limit&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;);
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Traditional code coverage only tells you &quot;this line was reached.&quot; Sometimes assertions verify &quot;this interesting scenario actually happened.&quot; If a sometimes assertion never triggers across thousands of test runs, you know you&#x27;re not discovering the edge cases that matter.&lt;&#x2F;p&gt;
&lt;p&gt;These three elements shift testing from prevention to discovery. Instead of developers writing tests for scenarios they already know about, the system forces them to hit failure modes they haven&#x27;t thought of. For Claude, this meant it could explore the state space step by step, understanding not just what the code does, but what breaks it.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-chaos-environment&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#the-chaos-environment&quot; aria-label=&quot;Anchor link for: the-chaos-environment&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;The Chaos Environment&lt;&#x2F;h2&gt;
&lt;p&gt;Moonpool is currently limited to simulating TCP connections through its Peer abstraction, but even this narrow scope creates a surprisingly rich failure environment. Here&#x27;s what the chaos testing configuration looks like (borrowed from TigerBeetle&#x27;s approach):&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;rust&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-rust &quot;&gt;&lt;code class=&quot;language-rust&quot; data-lang=&quot;rust&quot;&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;impl &lt;&#x2F;span&gt;&lt;span&gt;NetworkRandomizationRanges {
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F;&#x2F; Create chaos testing ranges with connection cutting enabled for distributed systems testing
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;pub fn &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8fa1b3;&quot;&gt;chaos_testing&lt;&#x2F;span&gt;&lt;span&gt;() -&amp;gt; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;Self &lt;&#x2F;span&gt;&lt;span&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;        &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;Self &lt;&#x2F;span&gt;&lt;span&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;            bind_base_range: &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;10&lt;&#x2F;span&gt;&lt;span&gt;..&lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;200&lt;&#x2F;span&gt;&lt;span&gt;,                       &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; 10-200Âµs
&lt;&#x2F;span&gt;&lt;span&gt;            bind_jitter_range: &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;10&lt;&#x2F;span&gt;&lt;span&gt;..&lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;100&lt;&#x2F;span&gt;&lt;span&gt;,                     &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; 10-100Âµs
&lt;&#x2F;span&gt;&lt;span&gt;            accept_base_range: &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;1000&lt;&#x2F;span&gt;&lt;span&gt;..&lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;10000&lt;&#x2F;span&gt;&lt;span&gt;,                 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; 1-10ms in Âµs
&lt;&#x2F;span&gt;&lt;span&gt;            accept_jitter_range: &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;1000&lt;&#x2F;span&gt;&lt;span&gt;..&lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;15000&lt;&#x2F;span&gt;&lt;span&gt;,               &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; 1-15ms in Âµs
&lt;&#x2F;span&gt;&lt;span&gt;            connect_base_range: &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;1000&lt;&#x2F;span&gt;&lt;span&gt;..&lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;50000&lt;&#x2F;span&gt;&lt;span&gt;,                &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; 1-50ms in Âµs
&lt;&#x2F;span&gt;&lt;span&gt;            connect_jitter_range: &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;5000&lt;&#x2F;span&gt;&lt;span&gt;..&lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;100000&lt;&#x2F;span&gt;&lt;span&gt;,             &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; 5-100ms in Âµs
&lt;&#x2F;span&gt;&lt;span&gt;            read_base_range: &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;5&lt;&#x2F;span&gt;&lt;span&gt;..&lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;100&lt;&#x2F;span&gt;&lt;span&gt;,                        &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; 5-100Âµs
&lt;&#x2F;span&gt;&lt;span&gt;            read_jitter_range: &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;10&lt;&#x2F;span&gt;&lt;span&gt;..&lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;200&lt;&#x2F;span&gt;&lt;span&gt;,                     &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; 10-200Âµs
&lt;&#x2F;span&gt;&lt;span&gt;            write_base_range: &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;50&lt;&#x2F;span&gt;&lt;span&gt;..&lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;1000&lt;&#x2F;span&gt;&lt;span&gt;,                     &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; 50-1000Âµs
&lt;&#x2F;span&gt;&lt;span&gt;            write_jitter_range: &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;100&lt;&#x2F;span&gt;&lt;span&gt;..&lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;2000&lt;&#x2F;span&gt;&lt;span&gt;,                  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; 100-2000Âµs
&lt;&#x2F;span&gt;&lt;span&gt;            clogging_probability_range: &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;0.1&lt;&#x2F;span&gt;&lt;span&gt;..&lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;0.3&lt;&#x2F;span&gt;&lt;span&gt;,           &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; 10-30% chance of temporary network congestion
&lt;&#x2F;span&gt;&lt;span&gt;            clogging_base_duration_range: &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;50000&lt;&#x2F;span&gt;&lt;span&gt;..&lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;300000&lt;&#x2F;span&gt;&lt;span&gt;,    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; 50-300ms congestion duration in Âµs
&lt;&#x2F;span&gt;&lt;span&gt;            clogging_jitter_duration_range: &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;100000&lt;&#x2F;span&gt;&lt;span&gt;..&lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;400000&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; 100-400ms additional congestion variance in Âµs
&lt;&#x2F;span&gt;&lt;span&gt;            cutting_probability_range: &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;0.10&lt;&#x2F;span&gt;&lt;span&gt;..&lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;0.20&lt;&#x2F;span&gt;&lt;span&gt;,          &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; 10-20% cutting chance per tick
&lt;&#x2F;span&gt;&lt;span&gt;            cutting_reconnect_base_range: &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;200000&lt;&#x2F;span&gt;&lt;span&gt;..&lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;800000&lt;&#x2F;span&gt;&lt;span&gt;,   &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; 200-800ms in Âµs
&lt;&#x2F;span&gt;&lt;span&gt;            cutting_reconnect_jitter_range: &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;100000&lt;&#x2F;span&gt;&lt;span&gt;..&lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;500000&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; 100-500ms in Âµs
&lt;&#x2F;span&gt;&lt;span&gt;            cutting_max_cuts_range: &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;..&lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;3&lt;&#x2F;span&gt;&lt;span&gt;,                   &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; 1-2 cuts per connection max (exclusive upper bound)
&lt;&#x2F;span&gt;&lt;span&gt;        }
&lt;&#x2F;span&gt;&lt;span&gt;    }
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Even with just TCP simulation, this creates a hostile environment where connections randomly fail, messages get delayed, and network operations experience unpredictable latencies. Each seed represents a different combination of timing and probability, creating unique failure scenarios.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;why-even-simple-network-code-needs-chaos&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#why-even-simple-network-code-needs-chaos&quot; aria-label=&quot;Anchor link for: why-even-simple-network-code-needs-chaos&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;Why Even Simple Network Code Needs Chaos&lt;&#x2F;h3&gt;
&lt;p&gt;You might think testing a simple peer implementation with fault injection is overkill, but production experience and research show otherwise. &lt;a href=&quot;https:&#x2F;&#x2F;www.usenix.org&#x2F;system&#x2F;files&#x2F;osdi18-alquraan.pdf&quot;&gt;&quot;An Analysis of Network-Partitioning Failures in Cloud Systems&quot;&lt;&#x2F;a&gt; (OSDI &#x27;18) studied real-world failures and found:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;80%&lt;&#x2F;strong&gt; of network partition failures have catastrophic impact&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;27%&lt;&#x2F;strong&gt; lead to data loss (the most common consequence)&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;90%&lt;&#x2F;strong&gt; of these failures are silent&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;21%&lt;&#x2F;strong&gt; cause permanent damage that persists even after the partition heals&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;83%&lt;&#x2F;strong&gt; need three additional events to manifest&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;That last point is crucial; exactly the kind of complex interaction that deterministic simulation with fault injection helps uncover.&lt;&#x2F;p&gt;
&lt;p&gt;My peer implementation only does simple ping-pong communication, yet it still took some work to make it robust enough to pass all the checks and assertions. It&#x27;s enough complexity for Claude to discover edge cases in connection handling, retry logic, and recovery mechanisms.&lt;&#x2F;p&gt;
&lt;p&gt;The breakthrough wasn&#x27;t that Claude wrote perfect code but that &lt;strong&gt;Claude could discover and explore failure scenarios I hadn&#x27;t thought to test, then use deterministic replay to debug and fix what went wrong.&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-paradigm-shift&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#the-paradigm-shift&quot; aria-label=&quot;Anchor link for: the-paradigm-shift&quot;&gt;ðŸ”—&lt;&#x2F;a&gt;The Paradigm Shift&lt;&#x2F;h2&gt;
&lt;p&gt;The difference between prevention and discovery completely changes how we think about software quality. &lt;strong&gt;Prevention testing asks &quot;did we break what used to work?&quot; Discovery testing asks &quot;what else is broken that we haven&#x27;t found yet?&quot;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;This shift creates a powerful feedback loop for young engineers and LLMs alike. Both developers and LLMs learn what production failure really looks like, not the sanitized version we imagine. When Claude can explore failure scenarios step by step and immediately see the results through sometimes assertions, it becomes a discovery partner that finds edge cases human intuition misses.&lt;&#x2F;p&gt;
&lt;p&gt;This isn&#x27;t theoretical. It&#x27;s working in my hobby project today. Moonpool is definitely hobby-grade, but if a side project can enable LLM-assisted bug discovery, imagine what&#x27;s possible with production systems designed from the ground up for deterministic testing.&lt;&#x2F;p&gt;
&lt;p&gt;The &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;apple&#x2F;foundationdb&quot;&gt;FoundationDB&lt;&#x2F;a&gt;, &lt;a href=&quot;https:&#x2F;&#x2F;tigerbeetle.com&#x2F;&quot;&gt;TigerBeetle&lt;&#x2F;a&gt;, and &lt;a href=&quot;https:&#x2F;&#x2F;antithesis.com&#x2F;&quot;&gt;Antithesis&lt;&#x2F;a&gt; communities have been practicing discovery-oriented testing for years. FoundationDB&#x27;s legendary reliability comes from exactly this approach; deterministic simulation that actively hunts for bugs rather than just preventing regressions. After operating FoundationDB in production for 3 years, I can confirm it&#x27;s by far the most robust and predictable distributed system I&#x27;ve encountered. Everything behaves exactly as documented, with none of the usual distributed systems surprises. I&#x27;ve written more about these ideas in my posts on &lt;a href=&quot;&#x2F;posts&#x2F;simulation-driven-development&#x2F;&quot;&gt;simulation-driven development&lt;&#x2F;a&gt; and &lt;a href=&quot;&#x2F;posts&#x2F;notes-about-foundationdb&#x2F;&quot;&gt;notes about FoundationDB&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;What&#x27;s new is that LLMs can now participate in this process.&lt;&#x2F;strong&gt; Through deterministic simulation and sometimes assertions, we&#x27;re not just telling the LLM &quot;write good code&quot; but showing it exactly what production failure looks like. If you&#x27;re curious about production-grade implementations of these ideas, check out &lt;a href=&quot;https:&#x2F;&#x2F;antithesis.com&#x2F;&quot;&gt;Antithesis&lt;&#x2F;a&gt;; their best hidden feature is that it works on any existing system without requiring a rewrite.&lt;&#x2F;p&gt;
&lt;p&gt;The tools exist. The techniques are proven. &lt;strong&gt;Testing must evolve from prevention to discovery.&lt;&#x2F;strong&gt; The future isn&#x27;t about writing better test cases but about building systems that actively reveal their own bugs.&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;p&gt;Feel free to reach out with any questions or to share your experiences with deterministic testing. You can find me on &lt;a href=&quot;https:&#x2F;&#x2F;twitter.com&#x2F;PierreZ&quot;&gt;Twitter&lt;&#x2F;a&gt;, &lt;a href=&quot;https:&#x2F;&#x2F;bsky.app&#x2F;profile&#x2F;pierrezemb.fr&quot;&gt;Bluesky&lt;&#x2F;a&gt; or through my &lt;a href=&quot;https:&#x2F;&#x2F;pierrezemb.fr&quot;&gt;website&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
</description>
          <category domain="tag">testing</category>
          <category domain="tag">simulation</category>
          <category domain="tag">deterministic</category>
          <category domain="tag">llm</category>
          <category domain="tag">foundationdb</category>
      </item>
    </channel>
</rss>
