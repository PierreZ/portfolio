<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>All Posts - Pierre Zemb</title>
        <link>http://pierrezemb.fr/posts/</link>
        <description>All Posts | Pierre Zemb</description>
        <generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Sun, 21 Feb 2021 00:24:27 &#43;0100</lastBuildDate><atom:link href="http://pierrezemb.fr/posts/" rel="self" type="application/rss+xml" /><item>
    <title>Crafting row keys in FoundationDB</title>
    <link>http://pierrezemb.fr/posts/crafting-keys-in-fdb/</link>
    <pubDate>Sun, 21 Feb 2021 00:24:27 &#43;0100</pubDate>
    <author>Author</author>
    <guid>http://pierrezemb.fr/posts/crafting-keys-in-fdb/</guid>
    <description><![CDATA[As I&rsquo;m working on my latest contribution around FoundationDB and Rust, I had the chance to dig a bit into how FoundationDB&rsquo;s bindings are offering helpers to generate keys. Their approach is interesting enough to deserve a blogpost ðŸ˜Ž
Row key? When you are using a key/value store, the design of the row key is extremely important, as this will define how well:
 your scans will be optimized, your puts will be spread, you will avoid hot-spotting a shard/region.]]></description>
</item><item>
    <title>Notes about ETCD</title>
    <link>http://pierrezemb.fr/posts/notes-about-etcd/</link>
    <pubDate>Mon, 11 Jan 2021 00:24:27 &#43;0100</pubDate>
    <author>Author</author>
    <guid>http://pierrezemb.fr/posts/notes-about-etcd/</guid>
    <description><![CDATA[Notes About is a blogpost serie you will find a lot of links, videos, quotes, podcasts to click on about a specific topic. Today we will discover ETCD.
Overview of ETCD As stated in the official documentation:
 etcd is a strongly consistent, distributed key-value store that provides a reliable way to store data that needs to be accessed by a distributed system or cluster of machines. It gracefully handles leader elections during network partitions and can tolerate machine failure, even in the leader node.]]></description>
</item><item>
    <title>10 years of programming and counting ðŸš€</title>
    <link>http://pierrezemb.fr/posts/ten-years-programming/</link>
    <pubDate>Wed, 30 Sep 2020 00:24:27 &#43;0100</pubDate>
    <author>Author</author>
    <guid>http://pierrezemb.fr/posts/ten-years-programming/</guid>
    <description><![CDATA[Iâ€™ve just realized that Iâ€™ve spent the last decade programming ðŸ¤¯ While 2020 feels like a strange year, I thought it would be nice to write down a retrospective of the last 10 years ðŸ—“
Learning to program ðŸ‘¨ðŸ»â€ðŸ’» I wrote my first Hello, world program somewhere around September 2010, when I started my engineering school to do some electronics, but that C language got me. I spent 6 months struggling to understand pointers and memory.]]></description>
</item><item>
    <title>Announcing Record-Store, a new (experimental) place for your data</title>
    <link>http://pierrezemb.fr/posts/announcing-record-store/</link>
    <pubDate>Wed, 23 Sep 2020 10:24:27 &#43;0100</pubDate>
    <author>Author</author>
    <guid>http://pierrezemb.fr/posts/announcing-record-store/</guid>
    <description><![CDATA[TL;DR: I&rsquo;m really happy to announce my latest open-source project called Record-Store ðŸš€ Please check it out on https://pierrez.github.io/record-store.
What? Record-Store is a layer running on top of FoundationDB. It provides abstractions to create, load and deletes customer-defined data called records, which are hold into a RecordSpace. We would like to have this kind of flow for developers:
 Opening RecordSpace, for example prod/users Create a protobuf definition which will be used as schema Upsert schema Push records Query records delete records  You need another KeySpace to store another type of data, or maybe a KeySpace dedicated to production env?]]></description>
</item><item>
    <title>Diving into ETCD&#39;s linearizable reads</title>
    <link>http://pierrezemb.fr/posts/diving-into-etcd-linearizable/</link>
    <pubDate>Fri, 18 Sep 2020 05:24:27 &#43;0100</pubDate>
    <author>Author</author>
    <guid>http://pierrezemb.fr/posts/diving-into-etcd-linearizable/</guid>
    <description><![CDATA[Diving Into is a blogpost serie where we are digging a specific part of the project&rsquo;s basecode. In this episode, we will digg into the implementation behind ETCD&rsquo;s Linearizable reads.
 What is ETCD? From the official website:
 etcd is a strongly consistent, distributed key-value store that provides a reliable way to store data that needs to be accessed by a distributed system or cluster of machines. It gracefully handles leader elections during network partitions and can tolerate machine failure, even in the leader node.]]></description>
</item><item>
    <title>Notes about Raft&#39;s paper</title>
    <link>http://pierrezemb.fr/posts/notes-about-raft/</link>
    <pubDate>Thu, 30 Jul 2020 07:24:27 &#43;0100</pubDate>
    <author>Author</author>
    <guid>http://pierrezemb.fr/posts/notes-about-raft/</guid>
    <description><![CDATA[Notes About is a blogpost serie you will find a lot of links, videos, quotes, podcasts to click on about a specific topic. Today we will discover Raft&rsquo;s paper called &lsquo;In Search of an Understandable Consensus Algorithm&rsquo;.
 As I&rsquo;m digging into ETCD, I needed to refresh my memory about Raft. I started by reading the paper located here and I&rsquo;m also playing with the amazing Raft labs made by PingCAP.]]></description>
</item><item>
    <title>Announcing Kafka-on-Pulsar: bring native Kafka protocol support to Apache Pulsar</title>
    <link>http://pierrezemb.fr/posts/announcing-kop/</link>
    <pubDate>Tue, 24 Mar 2020 10:24:27 &#43;0100</pubDate>
    <author>Author</author>
    <guid>http://pierrezemb.fr/posts/announcing-kop/</guid>
    <description><![CDATA[This is a repost from OVHcloud&rsquo;s official blogpost., please read it there to support my company. Thanks Horacio Gonzalez for the awesome drawings!
 This post has been published on both the StreamNative and OVHcloud blogs and was co-authored by Sijie Guo, Jia Zhai and Pierre Zemb. Thanks Horacio Gonzalez for the illustrations!
We are excited to announce that StreamNative and OVHcloud are open-sourcing &ldquo;Kafka on Pulsar&rdquo; (KoP). KoP brings the native Apache Kafka protocol support to Apache Pulsar by introducing a Kafka protocol handler on Pulsar brokers.]]></description>
</item><item>
    <title>Contributing to Apache HBase: custom data balancing</title>
    <link>http://pierrezemb.fr/posts/hbase-custom-data-balancing/</link>
    <pubDate>Fri, 14 Feb 2020 10:24:27 &#43;0100</pubDate>
    <author>Author</author>
    <guid>http://pierrezemb.fr/posts/hbase-custom-data-balancing/</guid>
    <description><![CDATA[This is a repost from OVHcloud&rsquo;s official blogpost., please read it there to support my company. Thanks Horacio Gonzalez for the awesome drawings!
 In today&rsquo;s blogpost, we&rsquo;re going to take a look at our upstream contribution to Apache HBase&rsquo;s stochastic load balancer, based on our experience of running HBase clusters to support OVHcloud&rsquo;s monitoring.
The context Have you ever wondered how:
 we generate the graphs for your OVHcloud server or web hosting package?]]></description>
</item><item>
    <title>Notes about FoundationDB</title>
    <link>http://pierrezemb.fr/posts/notes-about-foundationdb/</link>
    <pubDate>Thu, 30 Jan 2020 10:24:27 &#43;0100</pubDate>
    <author>Author</author>
    <guid>http://pierrezemb.fr/posts/notes-about-foundationdb/</guid>
    <description><![CDATA[Notes About is a blogpost serie you will find a lot of links, videos, quotes, podcasts to click on about a specific topic. Today we will discover FoundationDB.
 Overview of FoundationDB As stated in the official documentation:
 FoundationDB is a distributed database designed to handle large volumes of structured data across clusters of commodity servers. It organizes data as an ordered key-value store and employs ACID transactions for all operations.]]></description>
</item><item>
    <title>Diving into Kafka&#39;s Protocol</title>
    <link>http://pierrezemb.fr/posts/diving-into-kafka-protocol/</link>
    <pubDate>Sun, 08 Dec 2019 15:00:00 &#43;0100</pubDate>
    <author>Author</author>
    <guid>http://pierrezemb.fr/posts/diving-into-kafka-protocol/</guid>
    <description><![CDATA[Diving Into is a blogpost serie where we are digging a specific part of of the project&rsquo;s basecode. In this episode, we will digg into Kafka&rsquo;s protocol.
 The protocol reference For the last few months, I worked a lot around Kafka&rsquo;s protocols, first by creating a fully async Kafka to Pulsar Proxy in Rust, and now by contributing directly to KoP (Kafka On Pulsar). The full Kafka Protocol documentation is available here, but it does not offer a global view of what is happening for a classic Producer and Consumer exchange.]]></description>
</item></channel>
</rss>
