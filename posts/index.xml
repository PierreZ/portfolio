<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Posts on Pierre Zemb</title>
        <link>https://pierrezemb.fr/posts/</link>
        <description>Recent content in Posts on Pierre Zemb</description>
        <generator>Hugo -- gohugo.io</generator>
        <copyright>&lt;a href=&#34;http://creativecommons.org/licenses/by/3.0/&#34;&gt;Some Rights Reserved&lt;/a&gt;</copyright>
        <lastBuildDate>Sun, 21 Feb 2021 00:24:27 +0100</lastBuildDate>
        <atom:link href="https://pierrezemb.fr/posts/index.xml" rel="self" type="application/rss+xml" />
        
        <item>
            <title>Crafting row keys in FoundationDB</title>
            <link>https://pierrezemb.fr/posts/crafting-keys-in-fdb/</link>
            <pubDate>Sun, 21 Feb 2021 00:24:27 +0100</pubDate>
            
            <guid>https://pierrezemb.fr/posts/crafting-keys-in-fdb/</guid>
            <description>As I&amp;rsquo;m working on my latest contribution around FoundationDB and Rust, I had the chance to dig a bit into how FoundationDB&amp;rsquo;s bindings are offering helpers to generate keys. Their approach is interesting enough to deserve a blogpost üòé
Row key? When you are using a key/value store, the design of the row key is extremely important, as this will define how well:
 your scans will be optimized, your puts will be spread, you will avoid hot-spotting a shard/region.</description>
            <content type="html"><![CDATA[<p><img src="/posts/notes-about-foundationdb/images/fdb-white.jpg" alt="fdb image"></p>
<p>As I&rsquo;m working <a href="https://github.com/Clikengo/foundationdb-rs/issues/27">on my latest contribution around FoundationDB and Rust</a>, I had the chance to dig a bit into how FoundationDB&rsquo;s bindings are offering helpers to generate keys. Their approach is interesting enough to deserve a blogpost üòé</p>
<h2 id="row-key">Row key?</h2>
<p>When you are using a key/value store, the design of the <code>row key</code> is extremely important, as this will define how well:</p>
<ul>
<li>your scans will be optimized,</li>
<li>your puts will be spread,</li>
<li>you will avoid <code>hot-spotting</code> a shard/region.</li>
</ul>
<p>If you need more information on <code>row keys</code>, I recommend going through these links before moving on:</p>
<ul>
<li><a href="https://cloud.google.com/bigtable/docs/schema-design">&ldquo;Designing your schema&rdquo; BigTable documentation</a></li>
<li><a href="https://hbase.apache.org/book.html#rowkey.design">&ldquo;Rowkey Design&rdquo; HBase documentation</a></li>
</ul>
<h2 id="hand-crafting-row-keys">Hand-crafting row keys</h2>
<p>Most of the time, you will need to craft the <code>row key</code> &ldquo;by hand&rdquo;, like this for <a href="https://github.com/senx/warp10-platform/blob/879734d7f63791b487f3e535cd79ac4c23e99377/warp10/src/main/java/io/warp10/continuum/store/Store.java#L1215-L1222">an HBase&rsquo;s app</a>:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-java" data-lang="java"><span style="color:#75715e">// Prefix + classId + labelsId + timestamp
</span><span style="color:#75715e">// 128 bits
</span><span style="color:#75715e"></span><span style="color:#66d9ef">byte</span><span style="color:#f92672">[]</span> rowkey <span style="color:#f92672">=</span> <span style="color:#66d9ef">new</span> <span style="color:#66d9ef">byte</span><span style="color:#f92672">[</span>Constants<span style="color:#f92672">.</span><span style="color:#a6e22e">HBASE_RAW_DATA_KEY_PREFIX</span><span style="color:#f92672">.</span><span style="color:#a6e22e">length</span> <span style="color:#f92672">+</span> 8 <span style="color:#f92672">+</span> 8 <span style="color:#f92672">+</span> 8<span style="color:#f92672">];</span>

System<span style="color:#f92672">.</span><span style="color:#a6e22e">arraycopy</span><span style="color:#f92672">(</span>Constants<span style="color:#f92672">.</span><span style="color:#a6e22e">HBASE_RAW_DATA_KEY_PREFIX</span><span style="color:#f92672">,</span> 0<span style="color:#f92672">,</span> rowkey<span style="color:#f92672">,</span> 0<span style="color:#f92672">,</span> Constants<span style="color:#f92672">.</span><span style="color:#a6e22e">HBASE_RAW_DATA_KEY_PREFIX</span><span style="color:#f92672">.</span><span style="color:#a6e22e">length</span><span style="color:#f92672">);</span>
<span style="color:#75715e">// Copy classId/labelsId
</span><span style="color:#75715e"></span>System<span style="color:#f92672">.</span><span style="color:#a6e22e">arraycopy</span><span style="color:#f92672">(</span>Longs<span style="color:#f92672">.</span><span style="color:#a6e22e">toByteArray</span><span style="color:#f92672">(</span>msg<span style="color:#f92672">.</span><span style="color:#a6e22e">getClassId</span><span style="color:#f92672">()),</span> 0<span style="color:#f92672">,</span> rowkey<span style="color:#f92672">,</span> Constants<span style="color:#f92672">.</span><span style="color:#a6e22e">HBASE_RAW_DATA_KEY_PREFIX</span><span style="color:#f92672">.</span><span style="color:#a6e22e">length</span><span style="color:#f92672">,</span> 8<span style="color:#f92672">);</span>
System<span style="color:#f92672">.</span><span style="color:#a6e22e">arraycopy</span><span style="color:#f92672">(</span>Longs<span style="color:#f92672">.</span><span style="color:#a6e22e">toByteArray</span><span style="color:#f92672">(</span>msg<span style="color:#f92672">.</span><span style="color:#a6e22e">getLabelsId</span><span style="color:#f92672">()),</span> 0<span style="color:#f92672">,</span> rowkey<span style="color:#f92672">,</span> Constants<span style="color:#f92672">.</span><span style="color:#a6e22e">HBASE_RAW_DATA_KEY_PREFIX</span><span style="color:#f92672">.</span><span style="color:#a6e22e">length</span> <span style="color:#f92672">+</span> 8<span style="color:#f92672">,</span> 8<span style="color:#f92672">);</span>
</code></pre></div><p>Or maybe you will wrap things in a function <a href="https://github.com/pingcap/tidb/blob/ef57bdbbb04f60a8be744060a99207e08a37514a/tablecodec/tablecodec.go#L80-L86">like this in Go</a>:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-go" data-lang="go"><span style="color:#75715e">// EncodeRowKey encodes the table id and record handle into a kv.Key
</span><span style="color:#75715e"></span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">EncodeRowKey</span>(<span style="color:#a6e22e">tableID</span> <span style="color:#66d9ef">int64</span>, <span style="color:#a6e22e">encodedHandle</span> []<span style="color:#66d9ef">byte</span>) <span style="color:#a6e22e">kv</span>.<span style="color:#a6e22e">Key</span> {
	<span style="color:#a6e22e">buf</span> <span style="color:#f92672">:=</span> make([]<span style="color:#66d9ef">byte</span>, <span style="color:#ae81ff">0</span>, <span style="color:#a6e22e">prefixLen</span><span style="color:#f92672">+</span>len(<span style="color:#a6e22e">encodedHandle</span>))
	<span style="color:#a6e22e">buf</span> = <span style="color:#a6e22e">appendTableRecordPrefix</span>(<span style="color:#a6e22e">buf</span>, <span style="color:#a6e22e">tableID</span>)
	<span style="color:#a6e22e">buf</span> = append(<span style="color:#a6e22e">buf</span>, <span style="color:#a6e22e">encodedHandle</span><span style="color:#f92672">...</span>)
	<span style="color:#66d9ef">return</span> <span style="color:#a6e22e">buf</span>
}
</code></pre></div><p>Each time, you need to wrap the complexity of converting your objects to a row-key, by creating a buffer and write stuff in it.</p>
<p>In our Java example, there is an interesting comment:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-java" data-lang="java"><span style="color:#75715e">// Prefix + classId + labelsId + timestamp
</span></code></pre></div><p>If we are replacing some characters, we are not really far from:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-java" data-lang="java"><span style="color:#75715e">// (Prefix, classId, labelsId, timestamp)
</span></code></pre></div><p>Which looks like a <code>Tuple</code>(a collection of values of different types) and this is what FoundationDB is using as an abstraction to create keys üòç</p>
<h2 id="fdbs-abstractions-and-helpers">FDB&rsquo;s abstractions and helpers</h2>
<h3 id="tuple">Tuple</h3>
<p>Instead of crafting bytes by hand, we are <code>packing</code> a Tuple:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-rust" data-lang="rust"><span style="color:#75715e">// create a Tuple&lt;String, i64&gt; with (&#34;tenant-1&#34;, 1)
</span><span style="color:#75715e"></span><span style="color:#66d9ef">let</span> tuple <span style="color:#f92672">=</span> (String::from(<span style="color:#e6db74">&#34;tenant-1&#34;</span>), <span style="color:#ae81ff">1</span>);

<span style="color:#75715e">// and compute a row-key from the Tuple
</span><span style="color:#75715e"></span><span style="color:#66d9ef">let</span> row_key <span style="color:#f92672">=</span> foundationdb::tuple::pack::<span style="color:#f92672">&lt;</span>(String, <span style="color:#66d9ef">i64</span>)<span style="color:#f92672">&gt;</span>(<span style="color:#f92672">&amp;</span>tuple);
</code></pre></div><p>The generated row-key will be readable from any bindings, as it&rsquo;s construction is standardized. Let&rsquo;s print it:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-rust" data-lang="rust"><span style="color:#75715e">// and print-it in hexa
</span><span style="color:#75715e"></span>println<span style="color:#f92672">!</span>(<span style="color:#e6db74">&#34;{:#04X?}&#34;</span>, row_key);
</code></pre></div><pre><code class="language-log" data-lang="log">// can be verified with https://www.utf8-chartable.de/unicode-utf8-table.pl
[
    0x02,
    0x74, // t
    0x65, // e 
    0x6E, // n
    0x61, // a
    0x6E, // n
    0x74, // t
    0x2D, // -
    0x31, // 1
    0x00, 
    0x15,
    0x2A, // 42
]
</code></pre><p>As you can see, <code>pack</code> added some extra-characters. There are used to recognized the next type, a bit like when you are encoding/decoding some wire protocols. You can find the relevant documentation <a href="https://github.com/apple/foundationdb/blob/master/design/tuple.md">here</a>.</p>
<p>Having this kind of standard means that we can easily decompose/<code>unpack</code> it:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-rust" data-lang="rust"><span style="color:#75715e">// retrieve the user and the magic number In a Tuple (String, i64)
</span><span style="color:#75715e"></span><span style="color:#66d9ef">let</span> from_row_key <span style="color:#f92672">=</span> foundationdb::tuple::unpack::<span style="color:#f92672">&lt;</span>(String, <span style="color:#66d9ef">i64</span>)<span style="color:#f92672">&gt;</span>(<span style="color:#f92672">&amp;</span>row_key)<span style="color:#f92672">?</span>;

println<span style="color:#f92672">!</span>(<span style="color:#e6db74">&#34;user=&#39;{}&#39;, magic_number={}&#34;</span>, from_row_key.<span style="color:#ae81ff">0</span>, from_row_key.<span style="color:#ae81ff">1</span>);
<span style="color:#75715e">// user=&#39;tenant-1&#39;, magic_number=42
</span></code></pre></div><p>Now that we saw <code>Tuples</code>, let&rsquo;s dig in the next abstraction: <code>subspaces</code></p>
<h3 id="subspace">Subspace</h3>
<p>When you are working with key-values store, we are oftenly playing with what we call <code>keyspaces</code>, by dedicating a portion of the key to an usage, like this for example:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">/users/tenant-1/...
/users/tenant-2/...
/users/tenant-3/...
</code></pre></div><p>Here, <code>/users/tenant-1/</code> can be view like a prefix where we will put all the relevant keys. Instead of passing a simple prefix, FoundationDB is offering a dedicated structure called a <code>Subspace</code>:</p>
<blockquote>
<p>A Subspace represents a well-defined region of keyspace in a FoundationDB database</p>
</blockquote>
<blockquote>
<p>It provides a convenient way to use FoundationDB tuples to define namespaces for different categories of data. The namespace is specified by a prefix tuple which is prepended to all tuples packed by the subspace. When unpacking a key with the subspace, the prefix tuple will be removed from the result.</p>
</blockquote>
<p>As you can see, the <code>Subspace</code> is heavily relying on FoundationDB&rsquo;s tuples, as we can <code>pack</code> and <code>unpack</code> it.</p>
<blockquote>
<p>As a best practice, API clients should use at least one subspace for application data.</p>
</blockquote>
<p>Well, as we have now the tools to handle keyspaces easily, it is now futile to craft keys by hand üôÉ Let&rsquo;s create a subspace!</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-rust" data-lang="rust">
<span style="color:#75715e">// create a subspace from the Tuple (&#34;tenant-1&#34;, 42)
</span><span style="color:#75715e"></span><span style="color:#66d9ef">let</span> subspace <span style="color:#f92672">=</span> Subspace::from((String::from(<span style="color:#e6db74">&#34;tenant-1&#34;</span>), <span style="color:#ae81ff">42</span>));

<span style="color:#75715e">// let&#39;s print the range
</span><span style="color:#75715e"></span>println<span style="color:#f92672">!</span>(<span style="color:#e6db74">&#34;start: {:#04X?}\n end: {:#04X?}&#34;</span>, subspace.range().<span style="color:#ae81ff">0</span>, subspace.range().<span style="color:#ae81ff">1</span>);
</code></pre></div><p>We can see observe this:</p>
<pre><code class="language-log" data-lang="log">// can be verified with https://www.utf8-chartable.de/unicode-utf8-table.pl
start: [
    0x02,
    0x74, // t
    0x65, // e 
    0x6E, // n
    0x61, // a
    0x6E, // n
    0x74, // t
    0x2D, // -
    0x31, // 1
    0x00, 
    0x15,
    0x2A, // 42
    0x00,
    0x00, // smallest possible byte
]
end: [
    0x02,
    0x74, // t
    0x65, // e 
    0x6E, // n
    0x61, // a
    0x6E, // n
    0x74, // t
    0x2D, // -
    0x31, // 1
    0x00, 
    0x15,
    0x2A, // 42
    0x00,
    0xFF, // biggest possible byte
]
</code></pre><p>Which make sens, if we take <code>(&quot;tenant-1&quot;, 42)</code> as a prefix, then the range for this subspace will be between <code>(&quot;tenant-1&quot;, 42, 0x00)</code> and <code>(&quot;tenant-1&quot;, 42, 0xFF)</code></p>
<h3 id="directory">Directory</h3>
<p>Now that we know our way around <code>Tuples</code> and <code>Subspaces</code>, we can now talk about what I&rsquo;m working on, which is the <code>Directory</code>. Let&rsquo;s have a look at the relevant <a href="https://apple.github.io/foundationdb/developer-guide.html#directories">documentation</a>:</p>
<blockquote>
<p>FoundationDB provides directories (available in each language binding) as a tool for managing related subspaces.</p>
</blockquote>
<blockquote>
<p>Directories are a recommended approach for administering applications. Each application should create or open at least one directory to manage its subspaces.</p>
</blockquote>
<p>Okay, let&rsquo;s see the API(in Go, as I&rsquo;m working on the Rust API):</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-go" data-lang="go"><span style="color:#a6e22e">subspace</span>, <span style="color:#a6e22e">err</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">directory</span>.<span style="color:#a6e22e">CreateOrOpen</span>(<span style="color:#a6e22e">db</span>, []<span style="color:#66d9ef">string</span>{<span style="color:#e6db74">&#34;application&#34;</span>, <span style="color:#e6db74">&#34;my-app&#34;</span>, <span style="color:#e6db74">&#34;tenant&#34;</span>, <span style="color:#e6db74">&#34;tenant-42&#34;</span>}, <span style="color:#66d9ef">nil</span>)
<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">err</span> <span style="color:#f92672">!=</span> <span style="color:#66d9ef">nil</span> {
	<span style="color:#a6e22e">log</span>.<span style="color:#a6e22e">Fatal</span>(<span style="color:#a6e22e">err</span>)
}

<span style="color:#a6e22e">fmt</span>.<span style="color:#a6e22e">Printf</span>(<span style="color:#e6db74">&#34;%+v\n&#34;</span>, <span style="color:#a6e22e">subspace</span>.<span style="color:#a6e22e">Bytes</span>())
<span style="color:#75715e">// [21 18]
</span></code></pre></div><p>We can see that we have a shorter subspace! The <code>directory</code> allows you to generate some integer that will be bind to a path, like here <code>&quot;application&quot;, &quot;my-app&quot;, &quot;tenant&quot;, &quot;tenant-42&quot;</code>.</p>
<p>There are two advantages to this:</p>
<ul>
<li>shorter keys,</li>
<li>cheap metadata operations like <code>List</code> or <code>Move</code>:</li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-go" data-lang="go"><span style="color:#75715e">// list all tenant in &#34;application&#34;, &#34;my-app&#34;:
</span><span style="color:#75715e"></span><span style="color:#a6e22e">tenants</span>, <span style="color:#a6e22e">err</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">directory</span>.<span style="color:#a6e22e">List</span>(<span style="color:#a6e22e">db</span>, []<span style="color:#66d9ef">string</span>{<span style="color:#e6db74">&#34;application&#34;</span>, <span style="color:#e6db74">&#34;my-app&#34;</span>, <span style="color:#e6db74">&#34;tenant&#34;</span>})
<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">err</span> <span style="color:#f92672">!=</span> <span style="color:#66d9ef">nil</span> {
	<span style="color:#a6e22e">log</span>.<span style="color:#a6e22e">Fatal</span>(<span style="color:#a6e22e">err</span>)
}
<span style="color:#a6e22e">fmt</span>.<span style="color:#a6e22e">Printf</span>(<span style="color:#e6db74">&#34;%+v\n&#34;</span>, <span style="color:#a6e22e">tenants</span>)
<span style="color:#75715e">// [tenant-42]
</span><span style="color:#75715e"></span>
<span style="color:#75715e">// renaming &#39;tenant-42&#39; in &#39;tenant-142&#39;
</span><span style="color:#75715e">// This will NOT move the data, only the metadata is modified
</span><span style="color:#75715e"></span><span style="color:#a6e22e">directorySubspace</span>, <span style="color:#a6e22e">err</span> = <span style="color:#a6e22e">directory</span>.<span style="color:#a6e22e">Move</span>(<span style="color:#a6e22e">db</span>, 
	[]<span style="color:#66d9ef">string</span>{<span style="color:#e6db74">&#34;application&#34;</span>, <span style="color:#e6db74">&#34;my-app&#34;</span>, <span style="color:#e6db74">&#34;tenant&#34;</span>, <span style="color:#e6db74">&#34;tenant-42&#34;</span>},  <span style="color:#75715e">// old path
</span><span style="color:#75715e"></span>	[]<span style="color:#66d9ef">string</span>{<span style="color:#e6db74">&#34;application&#34;</span>, <span style="color:#e6db74">&#34;my-app&#34;</span>, <span style="color:#e6db74">&#34;tenant&#34;</span>, <span style="color:#e6db74">&#34;tenant-142&#34;</span>}) <span style="color:#75715e">// new path
</span><span style="color:#75715e"></span><span style="color:#66d9ef">if</span> <span style="color:#a6e22e">err</span> <span style="color:#f92672">!=</span> <span style="color:#66d9ef">nil</span> {
	<span style="color:#a6e22e">log</span>.<span style="color:#a6e22e">Fatal</span>(<span style="color:#a6e22e">err</span>)
}
<span style="color:#a6e22e">fmt</span>.<span style="color:#a6e22e">Printf</span>(<span style="color:#e6db74">&#34;%+v\n&#34;</span>, <span style="color:#a6e22e">directorySubspace</span>.<span style="color:#a6e22e">Bytes</span>())
<span style="color:#75715e">// still [21 18]
</span></code></pre></div><p>The returned object is actually a <code>DirectorySubspace</code>, which implements both <code>Directory</code> and <code>Subspace</code>, which means that you can use it to recreate many directories and subspaces at will üëå</p>
<blockquote>
<p>If you are wondering about how this integer is generated, I recommend going through this awesome blogpost on <a href="https://activesphere.com/blog/2018/08/05/high-contention-allocator">how high contention allocator works in FoundationDB.</a></p>
</blockquote>
<hr>
<p><strong>Thank you</strong> for reading my post! Feel free to react to this article, I am also available on <a href="https://twitter.com/PierreZ">Twitter</a> if needed.</p>
]]></content>
        </item>
        
        <item>
            <title>Notes about ETCD</title>
            <link>https://pierrezemb.fr/posts/notes-about-etcd/</link>
            <pubDate>Mon, 11 Jan 2021 00:24:27 +0100</pubDate>
            
            <guid>https://pierrezemb.fr/posts/notes-about-etcd/</guid>
            <description>Notes About is a blogpost serie you will find a lot of links, videos, quotes, podcasts to click on about a specific topic. Today we will discover ETCD.
Overview of ETCD As stated in the official documentation:
 etcd is a strongly consistent, distributed key-value store that provides a reliable way to store data that needs to be accessed by a distributed system or cluster of machines. It gracefully handles leader elections during network partitions and can tolerate machine failure, even in the leader node.</description>
            <content type="html"><![CDATA[<p><img src="/posts/notes-about-etcd/images/etcd.png" alt="etcd image"></p>
<p><a href="/tags/notesabout/">Notes About</a> is a blogpost serie  you will find a lot of <strong>links, videos, quotes, podcasts to click on</strong> about a specific topic. Today we will discover ETCD.</p>
<h2 id="overview-of-etcd">Overview of ETCD</h2>
<p>As stated in the <a href="https://etcd.io/">official documentation</a>:</p>
<blockquote>
<p>etcd is a strongly consistent, distributed key-value store that provides a reliable way to store data that needs to be accessed by a distributed system or cluster of machines. It gracefully handles leader elections during network partitions and can tolerate machine failure, even in the leader node.</p>
</blockquote>
<h2 id="history">History</h2>
<p>ETCD was initially developed by CoreOS:</p>
<blockquote>
<p>CoreOS built etcd to solve the problem of shared configuration and service discovery.</p>
</blockquote>
<ul>
<li>July 23, 2013 - announcement</li>
<li>December 27, 2013 - etcd 0.2.0 - new API, new modules and tons of improvements</li>
<li>February 07, 2014 - etcd 0.3.0 - Improved Cluster Discovery, API Enhancements and Windows Support</li>
<li>January 28, 2015 - etcd 2.0 - First Major Stable Release</li>
<li>June 30, 2016 - etcd3 - A New Version of etcd from CoreOS</li>
<li>June 09, 2017 - etcd 3.2 - etcd 3.2 now with massive watch scaling and easy locks</li>
<li>February 01, 2018 - etcd 3.3 - Announcing etcd 3.3, with improvements to stability, performance, and more</li>
<li>August 30, 2019 - etcd 3.4 - Better Storage Backend, concurrent Read, Improved Raft Voting Process, Raft Learner Member</li>
</ul>
<h2 id="overall-architecture">Overall architecture</h2>
<blockquote>
<p>The etcd key-value store is a distributed system intended for use as a coordination primitive. Like Zookeeper and Consul, etcd stores a small volume of infrequently-updated state (by default, up to 8 GB) in a key-value map, and offers strict-serializable reads, writes and micro-transactions across the entire datastore, plus coordination primitives like locks, watches, and leader election. Many distributed systems, such as Kubernetes and OpenStack, use etcd to store cluster metadata, to coordinate consistent views over data, to choose leaders, and so on.</p>
</blockquote>
<p>ETCD is:</p>
<ul>
<li>using <a href="/posts/notes-about-raft/">the raft consensus algorithm</a>,</li>
<li>a single group raft,</li>
<li>using <a href="https://grpc.io/">gRPC</a> for communication,</li>
<li>using a self-made WAL implementation,</li>
<li>storing key-values into bbolt,</li>
<li>optimized for consistency over latency in normal situations and consistency over availability in the case of a partition (<a href="https://en.wikipedia.org/wiki/PACELC_theorem">in terms of the PACELC theorem</a>).</li>
</ul>
<h3 id="consensus-raft">Consensus? Raft?</h3>
<ul>
<li>Raft is a consensus algorithm for managing a replicated log.</li>
<li>consensus involves multiple servers agreeing on values.</li>
<li>two common consensus algorithm are Paxos and Raft</li>
</ul>
<blockquote>
<p>, Paxos is quite difficult to understand, inspite of numerous attempts to make it more approachable.Furthermore, its architecture requires complex changes to support practical systems. As a result, both system builders and students struggle with Paxos.</p>
</blockquote>
<ul>
<li>A common alternative to Paxos/Raft is a non-consensus (aka peer-to-peer) replication protocol.</li>
</ul>
<blockquote>
<p>Raft separates the key elements of consensus, such asleader election, log replication, and safety</p>
</blockquote>
<p>ETCD contains several raft optimizations:</p>
<ul>
<li>Read Index,</li>
<li>Follower reads,</li>
<li>Transfer leader,</li>
<li>Learner role,</li>
<li>Client-side load-balancing.</li>
</ul>
<h3 id="exposed-api">Exposed API</h3>
<p>ETCD is exposing several APIs through different gRPC services:</p>
<ul>
<li>Put(key, value),</li>
<li>Delete(key, Optional(keyRangeEnd)),</li>
<li>Get(key, Optional(keyRangeEnd)),</li>
<li>Watch(key, Optional(keyRangeEnd)),</li>
<li>Transaction(if/then/else ops),</li>
<li>Compact(revision),</li>
<li>Lease:
<ul>
<li>Grant,</li>
<li>Revoke,</li>
<li>KeepAlive</li>
</ul>
</li>
</ul>
<p>Key and values are bytes-oriented but ordered.</p>
<h3 id="transactions">Transactions</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-proto" data-lang="proto"><span style="color:#75715e">// From google paxosdb paper:
</span><span style="color:#75715e">// Our implementation hinges around a powerful primitive which we call MultiOp. All other database
</span><span style="color:#75715e">// operations except for iteration are implemented as a single call to MultiOp. A MultiOp is applied atomically
</span><span style="color:#75715e">// and consists of three components:
</span><span style="color:#75715e">// 1. A list of tests called guard. Each test in guard checks a single entry in the database. It may check
</span><span style="color:#75715e">// for the absence or presence of a value, or compare with a given value. Two different tests in the guard
</span><span style="color:#75715e">// may apply to the same or different entries in the database. All tests in the guard are applied and
</span><span style="color:#75715e">// MultiOp returns the results. If all tests are true, MultiOp executes t op (see item 2 below), otherwise
</span><span style="color:#75715e">// it executes f op (see item 3 below).
</span><span style="color:#75715e">// 2. A list of database operations called t op. Each operation in the list is either an insert, delete, or
</span><span style="color:#75715e">// lookup operation, and applies to a single database entry. Two different operations in the list may apply
</span><span style="color:#75715e">// to the same or different entries in the database. These operations are executed
</span><span style="color:#75715e">// if guard evaluates to
</span><span style="color:#75715e">// true.
</span><span style="color:#75715e">// 3. A list of database operations called f op. Like t op, but executed if guard evaluates to false.
</span><span style="color:#75715e"></span><span style="color:#66d9ef">message</span> <span style="color:#a6e22e">TxnRequest</span> {<span style="color:#960050;background-color:#1e0010">
</span><span style="color:#960050;background-color:#1e0010"></span>  <span style="color:#75715e">// compare is a list of predicates representing a conjunction of terms.
</span><span style="color:#75715e"></span>  <span style="color:#75715e">// If the comparisons succeed, then the success requests will be processed in order,
</span><span style="color:#75715e"></span>  <span style="color:#75715e">// and the response will contain their respective responses in order.
</span><span style="color:#75715e"></span>  <span style="color:#75715e">// If the comparisons fail, then the failure requests will be processed in order,
</span><span style="color:#75715e"></span>  <span style="color:#75715e">// and the response will contain their respective responses in order.
</span><span style="color:#75715e"></span>  <span style="color:#66d9ef">repeated</span> Compare compare <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>;<span style="color:#960050;background-color:#1e0010">
</span><span style="color:#960050;background-color:#1e0010"></span>  <span style="color:#75715e">// success is a list of requests which will be applied when compare evaluates to true.
</span><span style="color:#75715e"></span>  <span style="color:#66d9ef">repeated</span> RequestOp success <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span>;<span style="color:#960050;background-color:#1e0010">
</span><span style="color:#960050;background-color:#1e0010"></span>  <span style="color:#75715e">// failure is a list of requests which will be applied when compare evaluates to false.
</span><span style="color:#75715e"></span>  <span style="color:#66d9ef">repeated</span> RequestOp failure <span style="color:#f92672">=</span> <span style="color:#ae81ff">3</span>;<span style="color:#960050;background-color:#1e0010">
</span><span style="color:#960050;background-color:#1e0010"></span>}<span style="color:#960050;background-color:#1e0010">
</span></code></pre></div><h3 id="versioned-data">Versioned data</h3>
<p>Each Key/Value has a revision. When creating a new key, revision starts at 1, and then will be incremented each time the key is updated.</p>
<p>In order to avoid having a growing keySpace, one can issue the <code>Compact</code> gRPC service:</p>
<blockquote>
<p>Compacting the keyspace history drops all information about keys superseded prior to a given keyspace revision</p>
</blockquote>
<h3 id="lease">Lease</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-proto" data-lang="proto"><span style="color:#75715e">// this message represent a Lease
</span><span style="color:#75715e"></span><span style="color:#66d9ef">message</span> <span style="color:#a6e22e">Lease</span> {<span style="color:#960050;background-color:#1e0010">
</span><span style="color:#960050;background-color:#1e0010"></span>  <span style="color:#75715e">// TTL is the advisory time-to-live in seconds. Expired lease will return -1.
</span><span style="color:#75715e"></span>  <span style="color:#66d9ef">int64</span> TTL <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>;<span style="color:#960050;background-color:#1e0010">
</span><span style="color:#960050;background-color:#1e0010"></span>  <span style="color:#75715e">// ID is the requested ID for the lease. If ID is set to 0, the lessor chooses an ID.
</span><span style="color:#75715e"></span>  <span style="color:#66d9ef">int64</span> ID <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span>;<span style="color:#960050;background-color:#1e0010">
</span><span style="color:#960050;background-color:#1e0010">
</span><span style="color:#960050;background-color:#1e0010"></span>  <span style="color:#66d9ef">int64</span> insert_timestamp <span style="color:#f92672">=</span> <span style="color:#ae81ff">3</span>;<span style="color:#960050;background-color:#1e0010">
</span><span style="color:#960050;background-color:#1e0010"></span>}<span style="color:#960050;background-color:#1e0010">
</span></code></pre></div><h3 id="watches">Watches</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-proto" data-lang="proto"><span style="color:#66d9ef">message</span> <span style="color:#a6e22e">Watch</span> {<span style="color:#960050;background-color:#1e0010">
</span><span style="color:#960050;background-color:#1e0010"></span>  <span style="color:#75715e">// key is the key to register for watching.
</span><span style="color:#75715e"></span>  <span style="color:#66d9ef">bytes</span> key <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>;<span style="color:#960050;background-color:#1e0010">
</span><span style="color:#960050;background-color:#1e0010">
</span><span style="color:#960050;background-color:#1e0010"></span>  <span style="color:#75715e">// range_end is the end of the range [key, range_end) to watch. If range_end is not given,
</span><span style="color:#75715e"></span>  <span style="color:#75715e">// only the key argument is watched. If range_end is equal to &#39;\0&#39;, all keys greater than
</span><span style="color:#75715e"></span>  <span style="color:#75715e">// or equal to the key argument are watched.
</span><span style="color:#75715e"></span>  <span style="color:#75715e">// If the range_end is one bit larger than the given key,
</span><span style="color:#75715e"></span>  <span style="color:#75715e">// then all keys with the prefix (the given key) will be watched.
</span><span style="color:#75715e"></span>  <span style="color:#66d9ef">bytes</span> range_end <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span>;<span style="color:#960050;background-color:#1e0010">
</span><span style="color:#960050;background-color:#1e0010">
</span><span style="color:#960050;background-color:#1e0010"></span>  <span style="color:#75715e">// If watch_id is provided and non-zero, it will be assigned to this watcher.
</span><span style="color:#75715e"></span>  <span style="color:#75715e">// Since creating a watcher in etcd is not a synchronous operation,
</span><span style="color:#75715e"></span>  <span style="color:#75715e">// this can be used ensure that ordering is correct when creating multiple
</span><span style="color:#75715e"></span>  <span style="color:#75715e">// watchers on the same stream. Creating a watcher with an ID already in
</span><span style="color:#75715e"></span>  <span style="color:#75715e">// use on the stream will cause an error to be returned.
</span><span style="color:#75715e"></span>  <span style="color:#66d9ef">int64</span> watch_id <span style="color:#f92672">=</span> <span style="color:#ae81ff">7</span>;<span style="color:#960050;background-color:#1e0010">
</span><span style="color:#960050;background-color:#1e0010"></span>}<span style="color:#960050;background-color:#1e0010">
</span></code></pre></div><h3 id="linearizable-reads">Linearizable reads</h3>
<p>Section 8 of the raft paper explains the issue:</p>
<blockquote>
<p>Read-only operations can be handled without writing anything into the log. However, with no additional measures, this would run the risk of returning stale data, since the leader responding to the request might have been superseded by a newer leader of which it is unaware. Linearizable reads must not return stale data, and Raft needs two extra precautions to guarantee this without using the log. First, a leader must have the latest information on which entries are committed. The Leader Completeness Property guarantees that a leader has all committed entries, but at the start of its term, it may not know which those are. To find out, it needs to commit an entry from its term. Raft handles this by having each leader commit a blank no-op entry into the log at the start of its term. Second,a leader must check whether it has been deposed before processing a read-only request (its information may be stale if a more recent leader has been elected). Raft handles this by having the leader exchange heartbeat messages with a majority of the cluster before responding to read-only requests.</p>
</blockquote>
<p>ETCD implements <code>ReadIndex</code> read(more info on <a href="/posts/diving-into-etcd-linearizable/">Diving into ETCD‚Äôs linearizable reads</a>).</p>
<h3 id="how-etcd-is-using-bbolt">How ETCD is using bbolt</h3>
<p><a href="https://github.com/etcd-io/bbolt">bbolt</a> is the underlying kv used in etcd. <a href="https://github.com/etcd-io/etcd/blob/v3.4.14/mvcc/kvstore_txn.go#L214">A bucket called <code>key</code> is used to store data, and the key is the revision</a>. Then, to find keys, <a href="https://github.com/etcd-io/etcd/blob/v3.4.14/mvcc/index.go#L68">a B-Tree is used</a>.</p>
<blockquote>
<ul>
<li>Bolt allows only one read-write transaction at a time but allows as many read-only transactions as you want at a time.</li>
<li>Each transaction has a consistent view of the data as it existed when the transaction started.</li>
<li>Bolt uses a B+tree internally and only a single file. Both approaches have trade-offs.</li>
<li>If you require a high random write throughput (&gt;10,000 w/sec) or you need to use spinning disks then LevelDB could be a good choice. If your application is read-heavy or does a lot of range scans then Bolt could be a good choice.</li>
<li>Try to avoid long running read transactions. Bolt uses copy-on-write so old pages cannot be reclaimed while an old transaction is using them.</li>
<li>Bolt uses a memory-mapped file so the underlying operating system handles the caching of the data. Typically, the OS will cache as much of the file as it can in memory and will release memory as needed to other processes. This means that Bolt can show very high memory usage when working with large databases.</li>
<li>Etcd implements multi-version-concurrency-control (MVCC) on top of Boltdb</li>
</ul>
</blockquote>
<p><a href="https://github.com/etcd-io/etcd/issues/12169#issuecomment-673292122">From an Github issue</a>:</p>
<blockquote>
<p>Note that the underlying <code>bbolt</code> mmap its file in memory. For better performance, usually it is a good idea to ensure the physical memory available to etcd is larger than its data size.</p>
</blockquote>
<h2 id="etcd-in-k8s">ETCD in K8S</h2>
<blockquote class="twitter-tweet"><p lang="en" dir="ltr">We built Kubernetes upon Etcd due to its similarities to Chubby and to the Omega store. When we exposed Etcd&#39;s watch (<a href="https://t.co/7rdNCKHjbO">https://t.co/7rdNCKHjbO</a>) through the K8s API, we let more Etcd details bleed through than originally intended. We need to clean up some of those details soon</p>&mdash; Brian Grant (@bgrant0607) <a href="https://twitter.com/bgrant0607/status/1118273986956120064?ref_src=twsrc%5Etfw">April 16, 2019</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<p><a href="https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/apiserver/pkg/storage/interfaces.go#L159">The interface can be found here</a>.</p>
<ul>
<li>Create use TTL and Txn</li>
<li>Get use KV.Get</li>
<li>Delete use Get and then for with a Txn</li>
<li>GuaranteedUpdate uses Txn</li>
<li>List uses Get</li>
<li>Watch uses Watch with a channel</li>
</ul>
<h2 id="jepsen">Jepsen</h2>
<p>The Jepsen team tested <a href="https://jepsen.io/analyses/etcd-3.4.3">etcd-3.4.3</a>, here&rsquo;s some quotes:</p>
<blockquote>
<p>In our tests, etcd 3.4.3 lived up to its claims for key-value operations: we observed nothing but strict-serializable consistency for reads, writes, and even multi-key transactions, during process pauses, crashes, clock skew, network partitions, and membership changes.</p>
</blockquote>
<blockquote>
<p>Watches appear correct, at least over single keys. So long as compaction does not destroy historical data while a watch isn‚Äôt running, watches appear to deliver every update to a key in order.</p>
</blockquote>
<blockquote>
<p>However, etcd locks (like all distributed locks) do not provide mutual exclusion. Multiple processes can hold an etcd lock concurrently, even in healthy clusters with perfectly synchronized clocks.</p>
</blockquote>
<blockquote>
<p>If you use etcd locks, consider whether those locks are used to ensure safety, or simply to improve performance by probabilistically limiting concurrency. It‚Äôs fine to use etcd locks for performance, but using them for safety might be risky.</p>
</blockquote>
<h2 id="operation-notes">Operation notes</h2>
<h3 id="deployements-tips">Deployements tips</h3>
<p><a href="https://etcd.io/docs/v3.4.0/faq/">From the official documentation</a>:</p>
<blockquote>
<p>Since etcd writes data to disk, SSD is highly recommended.
To prevent performance degradation or unintentionally overloading the key-value store, etcd enforces a configurable storage size quota set to 2GB by default.
To avoid swapping or running out of memory, the machine should have at least as much RAM to cover the quota.
8GB is a suggested maximum size for normal environments and etcd warns at startup if the configured value exceeds it.</p>
</blockquote>
<h3 id="defrag">Defrag</h3>
<blockquote>
<p>After compacting the keyspace, the backend database may exhibit internal fragmentation.
Defragmentation is issued on a per-member so that cluster-wide latency spikes may be avoided.</p>
</blockquote>
<p>Defrag is basically <a href="https://github.com/etcd-io/etcd/blob/2b79442d8e9fc54b1ac27e7e230ac0e4c132a054/mvcc/backend/backend.go#L349">dumping the bbolt tree on disk and reopening it</a>.</p>
<h3 id="snapshot">Snapshot</h3>
<p>An ETCD snapshot is related to Raft&rsquo;s snapshot:</p>
<blockquote>
<p>Snapshotting is the simplest approach to compaction. In snapshotting, the entire current system state is written to a snapshot on stable storage, then the entire log up to that point is discarded</p>
</blockquote>
<p>Snapshot can be saved using <code>etcdctl</code>:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">etcdctl snapshot save backup.db
</code></pre></div><h3 id="lease-1">Lease</h3>
<p>Be careful on Leader&rsquo;s change and lease, this can <a href="https://github.com/kubernetes/kubernetes/issues/65497">create some issues</a>:</p>
<blockquote>
<p>The new leader extends timeouts automatically for all leases. This mechanism ensures no lease expires due to server side unavailability.</p>
</blockquote>
<h3 id="war-stories">War stories</h3>
<ul>
<li><a href="https://blog.cloudflare.com/a-byzantine-failure-in-the-real-world/">An analysis of the Cloudflare API availability incident on 2020-11-02</a></li>
<li><a href="https://grafana.com/blog/2020/04/07/how-a-production-outage-in-grafana-clouds-hosted-prometheus-service-was-caused-by-a-bad-etcd-client-setup/">How a production outage in Grafana Cloud&rsquo;s Hosted Prometheus service was caused by a bad etcd client setup</a></li>
<li><a href="https://github.com/etcd-io/etcd/issues/11884">Random performance issue on etcd 3.4</a></li>
<li><a href="https://arxiv.org/pdf/2004.00372.pdf">Impact of etcd deployment on Kubernetes, Istio, and application performance</a></li>
</ul>
]]></content>
        </item>
        
        <item>
            <title>10 years of programming and counting üöÄ</title>
            <link>https://pierrezemb.fr/posts/ten-years-programming/</link>
            <pubDate>Wed, 30 Sep 2020 00:24:27 +0100</pubDate>
            
            <guid>https://pierrezemb.fr/posts/ten-years-programming/</guid>
            <description>I‚Äôve just realized that I‚Äôve spent the last decade programming ü§Ø While 2020 feels like a strange year, I thought it would be nice to write down a retrospective of the last 10 years üóì
Learning to program üë®üèª‚Äçüíª I wrote my first Hello, world program somewhere around September 2010, when I started my engineering school to do some electronics, but that C language got me. I spent 6 months struggling to understand pointers and memory.</description>
            <content type="html"><![CDATA[<p>I‚Äôve just realized that I‚Äôve spent the last decade programming ü§Ø While 2020 feels like a strange year, I thought it would be nice to write down a retrospective of the last 10 years üóì</p>
<h2 id="learning-to-program-">Learning to program üë®üèª‚Äçüíª</h2>
<p>I wrote my first <em>Hello, world</em> program somewhere around September 2010, when I started my engineering school to do some electronics, but that C language got me. I spent 6 months struggling to understand pointers and memory. I remember spending nights trying to find a memory leak with valgrind. Of course there were multiples mistakes, but it felt good to dig that far.</p>
<p>I also discovered Linux around that time, and spent many nights playing with Linux commands. I started my journey to Linux with Centos and then Ubuntu 11.04. I think this started the loop I‚Äôm (still!) stuck in:
<code>for {tryNewDistro()}</code>
I‚Äôm pretty sure that if I wanted to go away from distributed systems, I would try to land a job around operating systems. So many things to learn ü§©</p>
<p>After learning C, we started to learn web-based technologies like HTML/CSS/JS/PHP. I remember struggling to generate a calendar with PHP üêò I learned about APIs the week after the project üòÖ I remember digging into cookies, and network calls from popular websites to see how they were using it.</p>
<h2 id="java-and-hadoop-">Java and Hadoop üêò</h2>
<p>I had the chance to land a part-time internship during the third year (out of five) of my engineering school. I joined the Systems team @ Arkea, a french bank.
I remember spending a lot of time with my coworkers, learning things from them, from Hadoop to mainframes and Linux. It was my first time grasping the work around ‚Äúsystem programming‚Äù.</p>
<p>My first task was around writing an installer for a java app on windows, but my tutor tried to push me further. He saw my interest around some specific layers of their perimeter, such as Hadoop and Kafka. He gave to me a chance to work directly on those. A small API that was could load old monitoring data stored in HDFS and expose them back into the ‚Äúreal-time‚Äù visualization tool. I also used Kafka and even deployed a small HBase cluster for testing.</p>
<p>I can&rsquo;t thank my tutor enough for giving me this chance, and for allowing me to discover what will become my focus: distributed systems.</p>
<h2 id="lets-meet-other-people-">Let‚Äôs meet other people üëã</h2>
<p>Around the same time, I discovered tech meetups and conferences. At that time, Google I/O was a major event with people jumping from a plane and streaming it through Google Glass. I found out there was a group of people watching the live together. And this is how I discovered my local GDG/JUG ü•≥ I learned so many things by watching local talks, even if it was difficult to grasp everything at first. I remember taking üìù about what I didn‚Äôt understand, to learn about it later.</p>
<p>I also met amazing persons, that are now friends and/or mentors. I remember feeling humble to be able to learn from them.</p>
<p>I also discovered more global tech conferences. I asked as a birthday üéÅ to go to Devoxx France and DotScale, in 2014. It was awesome üòé</p>
<p>By dint of watching talks, I wanted to give some. I started small, giving talks at my engineering school, then moved to the JUG itself. I learned <strong>a lot</strong> by making a lot of mistakes, but I‚Äôm pretty happy how things turned out, as I‚Äôm now speaking at tech conferences as part of my current work.</p>
<img src="/posts/ten-years-programming/first-talk.jpg" alt="fig1" class="center">
<p>I also started to be involved in events and organizations such as:</p>
<ul>
<li>The JUG/GDG</li>
<li>A coworking place</li>
<li>Startup Weekend</li>
<li>Devoxx4kids</li>
<li>DevFest du bout du monde</li>
</ul>
<h2 id="learning-big-data-">Learning big data üíæ</h2>
<p>After my graduation and a(nother) part-time internship at OVH, I started working on something called Metrics Data Platform. It is the platform massively used internally to store, query and alert on timeseries data. We avoid the Borgmon approach (deploying Prometheus‚Äôs like database for every team), instead we created a unique platform to ingest all OVHcloud‚Äôs datapoints using a big-data approach. Here‚Äôs the key point of Metrics:</p>
<ul>
<li><strong>multi-tenant</strong>: as we said before, a single metrics cluster is handling all telemetry, from servers to applications and smart data centers from OVHcloud.</li>
<li><strong>scalable</strong>: today we are receiving around 1.8 million datapoints per second/s üôà for about 450 million timeseries üôâ. During European daytime, we are reading around 4.5 millions datapoints per seconds thank to Grafana‚Äôs auto-refresh mode üôä</li>
<li><strong>multi-protocol support</strong>: we didn&rsquo;t want to reflect our infrastructure choice to our users, so we wrote some proxies that can translate known protocols to our query language, so users can query and push data using OpenTSDB, Prometheus, InfluxDB and so on.</li>
<li><strong>based on open source</strong> we are using Warp10 as the core of our infrastructure with Kafka and HBase. Alerting was built with Apache flink. We open sourced many software, from agent to our proxies. We also gave many talks about what we learnt.</li>
</ul>
<p>I had the chance to built Metrics from the ground. I started working on the management layer and proxies. Then I wanted to learn operations, so I learned it by deploying Hadoop clusters ü§Ø it took me a while to be able to start doing on-calls. I cannot count how many nights I was up, trying to fix some buggy softwares, or yelling at HBase for an inconsistent <code>hbck</code>, or trying to find a way to handle a side effect of a loosing multiple racks.</p>
<p>Our work was highly technical, and I loved it:</p>
<ul>
<li>We optimized a lot of things, from HBase to our Go‚Äôs based proxies. <code>optimize HBase's data balancer</code> or <code>fix issues with Go‚Äôs gc</code>  was almost a normal task to do</li>
<li>We saw Metrics‚Äôs growth, from hundred to millions of datapoints üòé we saw systems breaking at scale, causing us to rewrite software or change architecture. Production became the final test.</li>
<li>Every software we developed had a <code>keep it simple, yet scalable</code> policy, and doing on-calls was a good way to ensure software quality. We all learned it the hard way I guess ü§£</li>
<li>We were only 4 to 6 to handle ~800 servers, 3 Hadoop clusters, and thousands of lines of Java/Go/Rust/Ansible codes.</li>
</ul>
<p>As always, things were not always magical, and i struggled more time than I can count. I learned that personal struggle is more difficult than technical, as you can always drill-down your tech problems by reading the code. The team was amazing üöÄ, and we were helping each other a lot ü§ù</p>
<h2 id="searching-for-planets--">Searching for planets üî≠ ü™ê</h2>
<p>When I started working on Metrics, we did a lot of internal on boarding. At his core, metrics is usine Warp10, which is coming with his own language to analyze timeseries. This provides heavy query-capabilities, but as it is stack-based, getting started was difficult. I needed a project to dive into timeseries analysis.</p>
<p>I love astronomy üî≠, but there‚Äôs too much ‚òÅÔ∏è (not the servers) in my city. I decided to look for astronomical timeseries. Turns out there is a lot, but one use case triggered my interest: exoplanet‚Äôs search. Almost everything from NASA is Opendata, so we decided to create <a href="https://helloexo.world/">HelloExoWorld</a>.</p>
<p>We imported the <strong>25TB dataset into a Warp10 instance</strong> and start writing some WarpScript to search for transits. We wrote a <a href="https://helloexoworld.github.io/hew-hands-on/">hands-on about it</a>. We also did several labs in french conferences like Devoxx and many others.</p>
<h2 id="io-timeout-">IO timeout üöß</h2>
<p>Around 2018, OVHcloud started Managed Kubernetes, a free K8S control-plane. With this product we saw more developers coming to OVHcloud. We started thinking about how we could help them. Running stateful systems is <strong>hard</strong>, so maybe we could offer them some databases or queues in a As-a-Service fashion. We started to design such products from our Metrics experience. We started the IO Vision to offer <code>popular Storage APIs in front of a scalable storage</code>. Does it sound familiar? üòá I had a lot of fun working on that vision as a Technical Leader.</p>
<p>We started with queuing with ioStream. We wanted something that was:</p>
<ul>
<li>Multi-tenant</li>
<li>Multi-protocol</li>
<li>Geo-replicated natively</li>
<li>Less operation burden at scale than Kafka</li>
</ul>
<p>We built ioStream around Apache Pulsar, and opened the beta around September 2019. As the same time we were working on Kafka‚Äôs support as a proxy in Rust. Writing such a software capable of translating Kafka‚Äôs TCP frames to Pulsar with a state-machine was a <strong>fun and challenging work</strong>. Rust is really a nice language to write such software.</p>
<p>Then we worked with Apache Pulsar‚Äôs PMC to introduce a Kafka protocol handler on Pulsar brokers. I had the chance to work closely to two PMCs, it was an amazing experience for me üöÄ You can read about our collaboration <a href="https://www.ovh.com/blog/announcing-kafka-on-pulsar-bring-native-kafka-protocol-support-to-apache-pulsar/">here</a>.</p>
<p>Unfortunately as stated by the official communication, the project has been shut down:</p>
<pre><code>However, the limited success of the beta service and other strategic focuses,
have resulted in us taking the very difficult decision to close it.
</code></pre><p>I learned a lot of things, both technically and on the product-side, especially considering the fact that it was shutdown.</p>
<h2 id="today">Today</h2>
<p>After ioStream‚Äôs shutdown, most of the team moved to create a new LBaaS. I helped them wrote an operator to schedule HAProxy‚Äôs containers on a Kubernetes cluster. It was a nice introduction to operators.</p>
<p>Then I decided to join the Managed Kubernetes ‚ò∏Ô∏è team. This is my current team now, where I‚Äôm having a lot of fun working around ETCD.</p>
<p>I really hope the next 10 years will be as fun as the last 10 years üòá</p>
<hr>
<p><strong>Thank you</strong> for reading my post! Feel free to react to this article, I am also available on <a href="https://twitter.com/PierreZ">Twitter</a> if needed.</p>
]]></content>
        </item>
        
        <item>
            <title>Announcing Record-Store, a new (experimental) place for your data</title>
            <link>https://pierrezemb.fr/posts/announcing-record-store/</link>
            <pubDate>Wed, 23 Sep 2020 10:24:27 +0100</pubDate>
            
            <guid>https://pierrezemb.fr/posts/announcing-record-store/</guid>
            <description>TL;DR: I&amp;rsquo;m really happy to announce my latest open-source project called Record-Store üöÄ Please check it out on https://pierrez.github.io/record-store.
What? Record-Store is a layer running on top of FoundationDB. It provides abstractions to create, load and deletes customer-defined data called records, which are hold into a RecordSpace. We would like to have this kind of flow for developers:
 Opening RecordSpace, for example prod/users Create a protobuf definition which will be used as schema Upsert schema Push records Query records delete records  You need another KeySpace to store another type of data, or maybe a KeySpace dedicated to production env?</description>
            <content type="html"><![CDATA[<p>TL;DR: I&rsquo;m really happy to announce my latest open-source project called Record-Store üöÄ Please check it out on <a href="https://pierrez.github.io/record-store">https://pierrez.github.io/record-store</a>.</p>
<h2 id="what">What?</h2>
<p><code>Record-Store</code> is a <a href="https://apple.github.io/foundationdb/layer-concept.html">layer</a> running on top of <a href="https://foundationdb.org">FoundationDB</a>. It provides abstractions to create, load and deletes customer-defined data called <code>records</code>, which are hold into a <code>RecordSpace</code>. We would like to have this kind of flow for developers:</p>
<ol>
<li>Opening RecordSpace, for example <code>prod/users</code></li>
<li>Create a protobuf definition which will be used as schema</li>
<li>Upsert schema</li>
<li>Push records</li>
<li>Query records</li>
<li>delete records</li>
</ol>
<p>You need another <code>KeySpace</code> to store another type of data, or maybe a <code>KeySpace</code> dedicated to production env? Juste create it and you are good to go!</p>
<h2 id="features">Features</h2>
<p>It is currently an experiment, but it already has some strong features:</p>
<ul>
<li>
<p><strong>Multi-tenant</strong> A <code>tenant</code> can create as many <code>RecordSpace</code> as we want, and we can have many <code>tenants</code>.</p>
</li>
<li>
<p><strong>Standard API</strong> We are exposing the record-store with standard technologies:</p>
<ul>
<li><a href="https://grpc.io">gRPC</a></li>
<li><em>very experimental</em> <a href="https://graphql.org">GraphQL</a></li>
</ul>
</li>
<li>
<p><strong>Scalable</strong> We are based on the same tech behind <a href="https://www.foundationdb.org/files/record-layer-paper.pdf">CloudKit</a> called the <a href="https://github.com/foundationdb/fdb-record-layer/">Record Layer</a>,</p>
</li>
<li>
<p><strong>Transactional</strong> We are running on top of <a href="https://www.foundationdb.org/">FoundationDB</a>. FoundationDB gives you the power of ACID transactions in a distributed database.</p>
</li>
<li>
<p><strong>Encrypted</strong> Data are encrypted by default.</p>
</li>
<li>
<p><strong>Multi-model</strong> For each <code>RecordSpace</code>, you can define a <code>schema</code>, which is in-fact only a <code>Protobuf</code> definition. You need to store some <code>users</code>, or a more complicated structure? If you can represent it as <a href="https://developers.google.com/protocol-buffers">Protobuf</a>, you are good to go!</p>
</li>
<li>
<p><strong>Index-defined queries</strong> Your queries&rsquo;s capabilities are defined by the indexes you put on your schema.</p>
</li>
<li>
<p><strong>Secured</strong> We are using <a href="https://github.com/CleverCloud/biscuit">Biscuit</a>, a mix of <code>JWT</code> and <code>Macaroons</code> to ensure auth{entication, orization}.</p>
</li>
</ul>
<h2 id="why">Why?</h2>
<p>Lately, I have been playing a lot with my <a href="https://github.com/PierreZ/fdb-etcd">ETCD-Layer</a> that is using the <a href="https://github.com/foundationdb/fdb-record-layer/">Record-Layer</a>. Thanks to it, I was able to bootstrap my ETCD-layer very quickly, but I was not using a tenth of the capacities of this library. So I decided to go deeper. <strong>What would a gRPC abstraction of the Record-Layer look like?</strong></p>
<p>The name of this project itself is a tribute to the Record Layer as we are exposing the layer within a gRPC interface.</p>
<h2 id="try-it-out">Try it out!</h2>
<p>Record-Store is open sourced under Apache License V2 in <a href="https://github.com/PierreZ/record-store">https://github.com/PierreZ/record-store</a> and the documentation can be found <a href="https://pierrez.github.io/record-store">https://pierrez.github.io/record-store</a>.</p>
<hr>
<p><strong>Thank you</strong> for reading my post! Feel free to react to this article, I am also available on <a href="https://twitter.com/PierreZ">Twitter</a> if needed.</p>
]]></content>
        </item>
        
        <item>
            <title>Diving into ETCD&#39;s linearizable reads</title>
            <link>https://pierrezemb.fr/posts/diving-into-etcd-linearizable/</link>
            <pubDate>Fri, 18 Sep 2020 05:24:27 +0100</pubDate>
            
            <guid>https://pierrezemb.fr/posts/diving-into-etcd-linearizable/</guid>
            <description>Diving Into is a blogpost serie where we are digging a specific part of the project&amp;rsquo;s basecode. In this episode, we will digg into the implementation behind ETCD&amp;rsquo;s Linearizable reads.
 What is ETCD? From the official website:
 etcd is a strongly consistent, distributed key-value store that provides a reliable way to store data that needs to be accessed by a distributed system or cluster of machines. It gracefully handles leader elections during network partitions and can tolerate machine failure, even in the leader node.</description>
            <content type="html"><![CDATA[<p><img src="/posts/diving-into-etcd-linearizable/etcd.png" alt="etcd image"></p>
<p><a href="/tags/diving-into/">Diving Into</a> is a blogpost serie where we are digging a specific part of the project&rsquo;s basecode. In this episode, we will digg into the implementation behind ETCD&rsquo;s Linearizable reads.</p>
<hr>
<h2 id="what-is-etcd">What is ETCD?</h2>
<p>From <a href="https://etcd.io/">the official website</a>:</p>
<blockquote>
<p>etcd is a strongly consistent, distributed key-value store that provides a reliable way to store data that needs to be accessed by a distributed system or cluster of machines. It gracefully handles leader elections during network partitions and can tolerate machine failure, even in the leader node.</p>
</blockquote>
<p>ETCD is well-known to be Kubernetes&rsquo;s datastore, and a CNCF incubating project.</p>
<h2 id="linea-what">Linea-what?</h2>
<p><a href="https://jepsen.io/consistency/models/linearizable">Let&rsquo;s quote Kyle Kingsbury, a.k.a &ldquo;Aphyr&rdquo;</a>, for this one:</p>
<blockquote>
<p>Linearizability is one of the strongest single-object consistency models, and implies that every operation appears to take place atomically, in some order, consistent with the real-time ordering of those operations: e.g., if operation A completes before operation B begins, then B should logically take effect after A.</p>
</blockquote>
<h2 id="why">Why?</h2>
<p>ETCD is using <a href="https://raft.github.io/">Raft</a>, a consensus algorithm at his core. As always, the devil is hidden in the details, or when things are going wrong. Here&rsquo;s an example:</p>
<ol>
<li><code>node1</code> is <code>leader</code> and heartbeating properly to <code>node2</code> and <code>node3</code>,</li>
<li>network partition is happening, and <code>node1</code> is isolated from the others.</li>
</ol>
<p>At this moment, all the actions are depending on timeouts and settings. In a (close) future, all nodes will go into <strong>election mode</strong> and node 2 and 3 will be able to create a quorum. This can lead to this situation:</p>
<ul>
<li><code>node1</code> thinks he is a leader as heartbeat timeouts and retry are not yet reached, so he can serve reads üò±</li>
<li><code>node2</code> and <code>node3</code> have elected a new leader and are working again, accepting writes.</li>
</ul>
<p>This situation is violating Linearizable reads, as reads going through <code>node1</code> will not see the last updates from the current leader.</p>
<p>How can we solve this? One way is to use <code>ReadIndex</code>!</p>
<h2 id="readindex">ReadIndex</h2>
<p>The basic idea behind this is to confirm that the <strong>leader is true leader or not</strong> by sending a message to the followers. If a majority of responses are healthy, then the leader can safely serve the reads. Let&rsquo;s dive into the implementation!</p>
<p>All codes are from the current latest release <a href="https://github.com/etcd-io/etcd/releases/tag/v3.4.13">v3.4.13</a>.</p>
<p><a href="https://github.com/etcd-io/etcd/blob/v3.4.13/etcdserver/v3_server.go#L114-L120">Let&rsquo;s take a Range operation</a>:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-go" data-lang="go">	<span style="color:#66d9ef">if</span> !<span style="color:#a6e22e">r</span>.<span style="color:#a6e22e">Serializable</span> {
		<span style="color:#a6e22e">err</span> = <span style="color:#a6e22e">s</span>.<span style="color:#a6e22e">linearizableReadNotify</span>(<span style="color:#a6e22e">ctx</span>)
		<span style="color:#a6e22e">trace</span>.<span style="color:#a6e22e">Step</span>(<span style="color:#e6db74">&#34;agreement among raft nodes before linearized reading&#34;</span>)
		<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">err</span> <span style="color:#f92672">!=</span> <span style="color:#66d9ef">nil</span> {
			<span style="color:#66d9ef">return</span> <span style="color:#66d9ef">nil</span>, <span style="color:#a6e22e">err</span>
		}
	}
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-go" data-lang="go">
<span style="color:#66d9ef">func</span> (<span style="color:#a6e22e">s</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">EtcdServer</span>) <span style="color:#a6e22e">linearizableReadNotify</span>(<span style="color:#a6e22e">ctx</span> <span style="color:#a6e22e">context</span>.<span style="color:#a6e22e">Context</span>) <span style="color:#66d9ef">error</span> {
	<span style="color:#a6e22e">s</span>.<span style="color:#a6e22e">readMu</span>.<span style="color:#a6e22e">RLock</span>()
	<span style="color:#a6e22e">nc</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">s</span>.<span style="color:#a6e22e">readNotifier</span>
	<span style="color:#a6e22e">s</span>.<span style="color:#a6e22e">readMu</span>.<span style="color:#a6e22e">RUnlock</span>()

	<span style="color:#75715e">// signal linearizable loop for current notify if it hasn&#39;t been already
</span><span style="color:#75715e"></span>	<span style="color:#66d9ef">select</span> {
	<span style="color:#66d9ef">case</span> <span style="color:#a6e22e">s</span>.<span style="color:#a6e22e">readwaitc</span> <span style="color:#f92672">&lt;-</span> <span style="color:#66d9ef">struct</span>{}{}:
	<span style="color:#66d9ef">default</span>:
	}

	<span style="color:#75715e">// wait for read state notification
</span><span style="color:#75715e"></span>	<span style="color:#66d9ef">select</span> {
	<span style="color:#66d9ef">case</span> <span style="color:#f92672">&lt;-</span><span style="color:#a6e22e">nc</span>.<span style="color:#a6e22e">c</span>:
		<span style="color:#66d9ef">return</span> <span style="color:#a6e22e">nc</span>.<span style="color:#a6e22e">err</span>
	<span style="color:#66d9ef">case</span> <span style="color:#f92672">&lt;-</span><span style="color:#a6e22e">ctx</span>.<span style="color:#a6e22e">Done</span>():
		<span style="color:#66d9ef">return</span> <span style="color:#a6e22e">ctx</span>.<span style="color:#a6e22e">Err</span>()
	<span style="color:#66d9ef">case</span> <span style="color:#f92672">&lt;-</span><span style="color:#a6e22e">s</span>.<span style="color:#a6e22e">done</span>:
		<span style="color:#66d9ef">return</span> <span style="color:#a6e22e">ErrStopped</span>
	}
}
</code></pre></div><p>So in <a href="https://github.com/etcd-io/etcd/blob/v3.4.13/etcdserver/v3_server.go#L773-L793">linearizableReadNotify</a>, we are waiting for a signal. <code>readwaitc</code> is used in another goroutine called <a href="https://github.com/etcd-io/etcd/blob/v3.4.13/etcdserver/v3_server.go#L672-L771">linearizableReadLoop</a>. This goroutines will call this:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-go" data-lang="go"><span style="color:#66d9ef">func</span> (<span style="color:#a6e22e">n</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">node</span>) <span style="color:#a6e22e">ReadIndex</span>(<span style="color:#a6e22e">ctx</span> <span style="color:#a6e22e">context</span>.<span style="color:#a6e22e">Context</span>, <span style="color:#a6e22e">rctx</span> []<span style="color:#66d9ef">byte</span>) <span style="color:#66d9ef">error</span> {
	<span style="color:#66d9ef">return</span> <span style="color:#a6e22e">n</span>.<span style="color:#a6e22e">step</span>(<span style="color:#a6e22e">ctx</span>, <span style="color:#a6e22e">pb</span>.<span style="color:#a6e22e">Message</span>{<span style="color:#a6e22e">Type</span>: <span style="color:#a6e22e">pb</span>.<span style="color:#a6e22e">MsgReadIndex</span>, <span style="color:#a6e22e">Entries</span>: []<span style="color:#a6e22e">pb</span>.<span style="color:#a6e22e">Entry</span>{{<span style="color:#a6e22e">Data</span>: <span style="color:#a6e22e">rctx</span>}}})
}

</code></pre></div><p>that will create a <code>MsgReadIndex</code> message that will be handled in <a href="https://github.com/etcd-io/etcd/blob/v3.4.13/raft/raft.go#L994">stepLeader</a>, who will send the message to the followers, like this:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-go" data-lang="go">	<span style="color:#66d9ef">case</span> <span style="color:#a6e22e">pb</span>.<span style="color:#a6e22e">MsgReadIndex</span>:
		<span style="color:#75715e">// If more than the local vote is needed, go through a full broadcast,
</span><span style="color:#75715e"></span>		<span style="color:#75715e">// otherwise optimize.
</span><span style="color:#75715e"></span>		<span style="color:#66d9ef">if</span> !<span style="color:#a6e22e">r</span>.<span style="color:#a6e22e">prs</span>.<span style="color:#a6e22e">IsSingleton</span>() {
		    <span style="color:#75715e">// PZ: omitting some code here
</span><span style="color:#75715e"></span>			<span style="color:#66d9ef">switch</span> <span style="color:#a6e22e">r</span>.<span style="color:#a6e22e">readOnly</span>.<span style="color:#a6e22e">option</span> {
			<span style="color:#66d9ef">case</span> <span style="color:#a6e22e">ReadOnlySafe</span>:
				<span style="color:#a6e22e">r</span>.<span style="color:#a6e22e">readOnly</span>.<span style="color:#a6e22e">addRequest</span>(<span style="color:#a6e22e">r</span>.<span style="color:#a6e22e">raftLog</span>.<span style="color:#a6e22e">committed</span>, <span style="color:#a6e22e">m</span>)
				<span style="color:#75715e">// The local node automatically acks the request.
</span><span style="color:#75715e"></span>				<span style="color:#a6e22e">r</span>.<span style="color:#a6e22e">readOnly</span>.<span style="color:#a6e22e">recvAck</span>(<span style="color:#a6e22e">r</span>.<span style="color:#a6e22e">id</span>, <span style="color:#a6e22e">m</span>.<span style="color:#a6e22e">Entries</span>[<span style="color:#ae81ff">0</span>].<span style="color:#a6e22e">Data</span>)
				<span style="color:#a6e22e">r</span>.<span style="color:#a6e22e">bcastHeartbeatWithCtx</span>(<span style="color:#a6e22e">m</span>.<span style="color:#a6e22e">Entries</span>[<span style="color:#ae81ff">0</span>].<span style="color:#a6e22e">Data</span>)
			<span style="color:#66d9ef">case</span> <span style="color:#a6e22e">ReadOnlyLeaseBased</span>:
				<span style="color:#a6e22e">ri</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">r</span>.<span style="color:#a6e22e">raftLog</span>.<span style="color:#a6e22e">committed</span>
				<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">m</span>.<span style="color:#a6e22e">From</span> <span style="color:#f92672">==</span> <span style="color:#a6e22e">None</span> <span style="color:#f92672">||</span> <span style="color:#a6e22e">m</span>.<span style="color:#a6e22e">From</span> <span style="color:#f92672">==</span> <span style="color:#a6e22e">r</span>.<span style="color:#a6e22e">id</span> { <span style="color:#75715e">// from local member
</span><span style="color:#75715e"></span>					<span style="color:#a6e22e">r</span>.<span style="color:#a6e22e">readStates</span> = append(<span style="color:#a6e22e">r</span>.<span style="color:#a6e22e">readStates</span>, <span style="color:#a6e22e">ReadState</span>{<span style="color:#a6e22e">Index</span>: <span style="color:#a6e22e">ri</span>, <span style="color:#a6e22e">RequestCtx</span>: <span style="color:#a6e22e">m</span>.<span style="color:#a6e22e">Entries</span>[<span style="color:#ae81ff">0</span>].<span style="color:#a6e22e">Data</span>})
				} <span style="color:#66d9ef">else</span> {
					<span style="color:#a6e22e">r</span>.<span style="color:#a6e22e">send</span>(<span style="color:#a6e22e">pb</span>.<span style="color:#a6e22e">Message</span>{<span style="color:#a6e22e">To</span>: <span style="color:#a6e22e">m</span>.<span style="color:#a6e22e">From</span>, <span style="color:#a6e22e">Type</span>: <span style="color:#a6e22e">pb</span>.<span style="color:#a6e22e">MsgReadIndexResp</span>, <span style="color:#a6e22e">Index</span>: <span style="color:#a6e22e">ri</span>, <span style="color:#a6e22e">Entries</span>: <span style="color:#a6e22e">m</span>.<span style="color:#a6e22e">Entries</span>})
				}
			}
</code></pre></div><p>So, the <code>leader</code> is sending a heartbeat in <code>ReadOnlySafe</code> mode. Turns out there is two modes:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-go" data-lang="go"><span style="color:#66d9ef">const</span> (
	<span style="color:#75715e">// ReadOnlySafe guarantees the linearizability of the read only request by
</span><span style="color:#75715e"></span>	<span style="color:#75715e">// communicating with the quorum. It is the default and suggested option.
</span><span style="color:#75715e"></span>	<span style="color:#a6e22e">ReadOnlySafe</span> <span style="color:#a6e22e">ReadOnlyOption</span> = <span style="color:#66d9ef">iota</span>
	<span style="color:#75715e">// ReadOnlyLeaseBased ensures linearizability of the read only request by
</span><span style="color:#75715e"></span>	<span style="color:#75715e">// relying on the leader lease. It can be affected by clock drift.
</span><span style="color:#75715e"></span>	<span style="color:#75715e">// If the clock drift is unbounded, leader might keep the lease longer than it
</span><span style="color:#75715e"></span>	<span style="color:#75715e">// should (clock can move backward/pause without any bound). ReadIndex is not safe
</span><span style="color:#75715e"></span>	<span style="color:#75715e">// in that case.
</span><span style="color:#75715e"></span>	<span style="color:#a6e22e">ReadOnlyLeaseBased</span>
)
</code></pre></div><p>Responses from the followers will be handled here:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-go" data-lang="go">	<span style="color:#66d9ef">case</span> <span style="color:#a6e22e">pb</span>.<span style="color:#a6e22e">MsgHeartbeatResp</span>:
		<span style="color:#75715e">// PZ: omitting some code here
</span><span style="color:#75715e"></span>		<span style="color:#a6e22e">rss</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">r</span>.<span style="color:#a6e22e">readOnly</span>.<span style="color:#a6e22e">advance</span>(<span style="color:#a6e22e">m</span>)
		<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">_</span>, <span style="color:#a6e22e">rs</span> <span style="color:#f92672">:=</span> <span style="color:#66d9ef">range</span> <span style="color:#a6e22e">rss</span> {
			<span style="color:#a6e22e">req</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">rs</span>.<span style="color:#a6e22e">req</span>
			<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">req</span>.<span style="color:#a6e22e">From</span> <span style="color:#f92672">==</span> <span style="color:#a6e22e">None</span> <span style="color:#f92672">||</span> <span style="color:#a6e22e">req</span>.<span style="color:#a6e22e">From</span> <span style="color:#f92672">==</span> <span style="color:#a6e22e">r</span>.<span style="color:#a6e22e">id</span> { <span style="color:#75715e">// from local member
</span><span style="color:#75715e"></span>				<span style="color:#a6e22e">r</span>.<span style="color:#a6e22e">readStates</span> = append(<span style="color:#a6e22e">r</span>.<span style="color:#a6e22e">readStates</span>, <span style="color:#a6e22e">ReadState</span>{<span style="color:#a6e22e">Index</span>: <span style="color:#a6e22e">rs</span>.<span style="color:#a6e22e">index</span>, <span style="color:#a6e22e">RequestCtx</span>: <span style="color:#a6e22e">req</span>.<span style="color:#a6e22e">Entries</span>[<span style="color:#ae81ff">0</span>].<span style="color:#a6e22e">Data</span>})
			} <span style="color:#66d9ef">else</span> {
				<span style="color:#a6e22e">r</span>.<span style="color:#a6e22e">send</span>(<span style="color:#a6e22e">pb</span>.<span style="color:#a6e22e">Message</span>{<span style="color:#a6e22e">To</span>: <span style="color:#a6e22e">req</span>.<span style="color:#a6e22e">From</span>, <span style="color:#a6e22e">Type</span>: <span style="color:#a6e22e">pb</span>.<span style="color:#a6e22e">MsgReadIndexResp</span>, <span style="color:#a6e22e">Index</span>: <span style="color:#a6e22e">rs</span>.<span style="color:#a6e22e">index</span>, <span style="color:#a6e22e">Entries</span>: <span style="color:#a6e22e">req</span>.<span style="color:#a6e22e">Entries</span>})
			}
		}
</code></pre></div><p>We are storing things into a <code>ReadState</code>:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-go" data-lang="go"><span style="color:#75715e">// ReadState provides state for read only query.
</span><span style="color:#75715e">// It&#39;s caller&#39;s responsibility to call ReadIndex first before getting
</span><span style="color:#75715e">// this state from ready, it&#39;s also caller&#39;s duty to differentiate if this
</span><span style="color:#75715e">// state is what it requests through RequestCtx, eg. given a unique id as
</span><span style="color:#75715e">// RequestCtx
</span><span style="color:#75715e"></span><span style="color:#66d9ef">type</span> <span style="color:#a6e22e">ReadState</span> <span style="color:#66d9ef">struct</span> {
	<span style="color:#a6e22e">Index</span>      <span style="color:#66d9ef">uint64</span>
	<span style="color:#a6e22e">RequestCtx</span> []<span style="color:#66d9ef">byte</span>
}
</code></pre></div><p>Now that the state has been updated, we need to unblock our <a href="https://github.com/etcd-io/etcd/blob/v3.4.13/etcdserver/v3_server.go#L672-L771">linearizableReadLoop</a>:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-go" data-lang="go">		<span style="color:#66d9ef">for</span> !<span style="color:#a6e22e">timeout</span> <span style="color:#f92672">&amp;&amp;</span> !<span style="color:#a6e22e">done</span> {
			<span style="color:#66d9ef">select</span> {
			<span style="color:#66d9ef">case</span> <span style="color:#a6e22e">rs</span> = <span style="color:#f92672">&lt;-</span><span style="color:#a6e22e">s</span>.<span style="color:#a6e22e">r</span>.<span style="color:#a6e22e">readStateC</span>:
</code></pre></div><p>Cool, another channel! Turns out, <code>readStateC</code> is updated in <a href="https://github.com/etcd-io/etcd/blob/v3.4.13/etcdserver/raft.go#L162">one of the main goroutine</a>:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-go" data-lang="go"><span style="color:#75715e">// start prepares and starts raftNode in a new goroutine. It is no longer safe
</span><span style="color:#75715e">// to modify the fields after it has been started.
</span><span style="color:#75715e"></span><span style="color:#66d9ef">func</span> (<span style="color:#a6e22e">r</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">raftNode</span>) <span style="color:#a6e22e">start</span>(<span style="color:#a6e22e">rh</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">raftReadyHandler</span>) {
	<span style="color:#a6e22e">internalTimeout</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">time</span>.<span style="color:#a6e22e">Second</span>

	<span style="color:#66d9ef">go</span> <span style="color:#66d9ef">func</span>() {
		<span style="color:#66d9ef">defer</span> <span style="color:#a6e22e">r</span>.<span style="color:#a6e22e">onStop</span>()
		<span style="color:#a6e22e">islead</span> <span style="color:#f92672">:=</span> <span style="color:#66d9ef">false</span>

		<span style="color:#66d9ef">for</span> {
			<span style="color:#66d9ef">select</span> {
			<span style="color:#66d9ef">case</span> <span style="color:#f92672">&lt;-</span><span style="color:#a6e22e">r</span>.<span style="color:#a6e22e">ticker</span>.<span style="color:#a6e22e">C</span>:
				<span style="color:#a6e22e">r</span>.<span style="color:#a6e22e">tick</span>()
			<span style="color:#66d9ef">case</span> <span style="color:#a6e22e">rd</span> <span style="color:#f92672">:=</span> <span style="color:#f92672">&lt;-</span><span style="color:#a6e22e">r</span>.<span style="color:#a6e22e">Ready</span>():
				<span style="color:#75715e">// PZ: omitting some code here
</span><span style="color:#75715e"></span>				<span style="color:#66d9ef">if</span> len(<span style="color:#a6e22e">rd</span>.<span style="color:#a6e22e">ReadStates</span>) <span style="color:#f92672">!=</span> <span style="color:#ae81ff">0</span> {
					<span style="color:#66d9ef">select</span> {
					<span style="color:#66d9ef">case</span> <span style="color:#a6e22e">r</span>.<span style="color:#a6e22e">readStateC</span> <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">rd</span>.<span style="color:#a6e22e">ReadStates</span>[len(<span style="color:#a6e22e">rd</span>.<span style="color:#a6e22e">ReadStates</span>)<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>]:
				}
</code></pre></div><p>Perfect, now <code>readStateC</code> is notified, and we can continue on <a href="https://github.com/etcd-io/etcd/blob/v3.4.13/etcdserver/v3_server.go#L672-L771">linearizableReadLoop</a>:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-go" data-lang="go">		<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">ai</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">s</span>.<span style="color:#a6e22e">getAppliedIndex</span>(); <span style="color:#a6e22e">ai</span> &lt; <span style="color:#a6e22e">rs</span>.<span style="color:#a6e22e">Index</span> {
			<span style="color:#66d9ef">select</span> {
			<span style="color:#66d9ef">case</span> <span style="color:#f92672">&lt;-</span><span style="color:#a6e22e">s</span>.<span style="color:#a6e22e">applyWait</span>.<span style="color:#a6e22e">Wait</span>(<span style="color:#a6e22e">rs</span>.<span style="color:#a6e22e">Index</span>):
			<span style="color:#66d9ef">case</span> <span style="color:#f92672">&lt;-</span><span style="color:#a6e22e">s</span>.<span style="color:#a6e22e">stopping</span>:
				<span style="color:#66d9ef">return</span>
			}
		}
		<span style="color:#75715e">// unblock all l-reads requested at indices before rs.Index
</span><span style="color:#75715e"></span>		<span style="color:#a6e22e">nr</span>.<span style="color:#a6e22e">notify</span>(<span style="color:#66d9ef">nil</span>)
</code></pre></div><p>The first part is a safety measure to makes sure the applied index is lower that the index stored in <code>ReadState</code>. And then finally we are unlocking all pending reads ü§©</p>
<h2 id="one-more-thing-follower-read">One more thing: Follower read</h2>
<p>We went through <code>stepLeader</code> a lot, be there is something interesting in <a href="https://github.com/etcd-io/etcd/blob/v4.3.13/raft/raft.go#L1320"><code>stepFollower</code></a>:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-go" data-lang="go">	<span style="color:#66d9ef">case</span> <span style="color:#a6e22e">pb</span>.<span style="color:#a6e22e">MsgReadIndex</span>:
		<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">r</span>.<span style="color:#a6e22e">lead</span> <span style="color:#f92672">==</span> <span style="color:#a6e22e">None</span> {
			<span style="color:#a6e22e">r</span>.<span style="color:#a6e22e">logger</span>.<span style="color:#a6e22e">Infof</span>(<span style="color:#e6db74">&#34;%x no leader at term %d; dropping index reading msg&#34;</span>, <span style="color:#a6e22e">r</span>.<span style="color:#a6e22e">id</span>, <span style="color:#a6e22e">r</span>.<span style="color:#a6e22e">Term</span>)
			<span style="color:#66d9ef">return</span> <span style="color:#66d9ef">nil</span>
		}
		<span style="color:#a6e22e">m</span>.<span style="color:#a6e22e">To</span> = <span style="color:#a6e22e">r</span>.<span style="color:#a6e22e">lead</span>
		<span style="color:#a6e22e">r</span>.<span style="color:#a6e22e">send</span>(<span style="color:#a6e22e">m</span>)
</code></pre></div><p>This means that a follower can send a <code>MsgReadIndex</code> message to perform the same kind of checks than a leader. This small features is in fact enabling <strong>follower-reads</strong> on ETCD ü§© That is why you can see <code>Range</code> requests from a <code>follower</code>.</p>
<h2 id="operational-tips">operational tips</h2>
<ul>
<li>If you are running etcd &lt;= 3.4, make sure <strong>logger=zap</strong> is set. Like this, you will be able to see some tracing logs, and I trully hope you will not witness this one:</li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-json" data-lang="json">{
  <span style="color:#f92672">&#34;level&#34;</span>: <span style="color:#e6db74">&#34;info&#34;</span>,
  <span style="color:#f92672">&#34;ts&#34;</span>: <span style="color:#e6db74">&#34;2020-08-12T08:24:56.181Z&#34;</span>,
  <span style="color:#f92672">&#34;caller&#34;</span>: <span style="color:#e6db74">&#34;traceutil/trace.go:145&#34;</span>,
  <span style="color:#f92672">&#34;msg&#34;</span>: <span style="color:#e6db74">&#34;trace[677217921] range&#34;</span>,
  <span style="color:#f92672">&#34;detail&#34;</span>: <span style="color:#e6db74">&#34;{range_begin:/...redacted...; range_end:; response_count:1; response_revision:2725080604; }&#34;</span>,
  <span style="color:#f92672">&#34;duration&#34;</span>: <span style="color:#e6db74">&#34;1.553047811s&#34;</span>,
  <span style="color:#f92672">&#34;start&#34;</span>: <span style="color:#e6db74">&#34;2020-08-12T08:24:54.628Z&#34;</span>,
  <span style="color:#f92672">&#34;end&#34;</span>: <span style="color:#e6db74">&#34;2020-08-12T08:24:56.181Z&#34;</span>,
  <span style="color:#f92672">&#34;steps&#34;</span>: [
    <span style="color:#e6db74">&#34;trace[677217921] &#39;agreement among raft nodes before linearized reading&#39;  (duration: 1.534322015s)&#34;</span> 
  ]
}
</code></pre></div><ul>
<li>there is <a href="https://github.com/etcd-io/etcd/issues/11884">a random performance issue on etcd 3.4</a></li>
<li>there is some metrics than you can watch for ReadIndex issues:
<ul>
<li><code>etcd_server_read_indexes_failed_total</code></li>
<li><code>etcd_server_slow_read_indexes_total</code></li>
</ul>
</li>
</ul>
<hr>
<p><strong>Thank you</strong> for reading my post! feel free to react to this article, I&rsquo;m also available on <a href="https://twitter.com/PierreZ">Twitter</a> if needed.</p>
]]></content>
        </item>
        
        <item>
            <title>Notes about Raft&#39;s paper</title>
            <link>https://pierrezemb.fr/posts/notes-about-raft/</link>
            <pubDate>Thu, 30 Jul 2020 07:24:27 +0100</pubDate>
            
            <guid>https://pierrezemb.fr/posts/notes-about-raft/</guid>
            <description>Notes About is a blogpost serie you will find a lot of links, videos, quotes, podcasts to click on about a specific topic. Today we will discover Raft&amp;rsquo;s paper called &amp;lsquo;In Search of an Understandable Consensus Algorithm&amp;rsquo;.
 As I&amp;rsquo;m digging into ETCD, I needed to refresh my memory about Raft. I started by reading the paper located here and I&amp;rsquo;m also playing with the amazing Raft labs made by PingCAP.</description>
            <content type="html"><![CDATA[<p><img src="/posts/notes-about-raft/images/raft.png" alt="raft_image"></p>
<p><a href="/tags/notesabout/">Notes About</a> is a blogpost serie  you will find a lot of <strong>links, videos, quotes, podcasts to click on</strong> about a specific topic. Today we will discover Raft&rsquo;s paper called &lsquo;In Search of an Understandable Consensus Algorithm&rsquo;.</p>
<hr>
<p>As I&rsquo;m digging into ETCD, I needed to refresh my memory about Raft. I started by reading the paper located <a href="https://raft.github.io/raft.pdf">here</a> and I&rsquo;m also playing with the amazing <a href="https://github.com/pingcap/talent-plan/tree/master/courses/dss/raft">Raft labs made by PingCAP</a>.</p>
<blockquote>
<p>These labs are derived from the <a href="http://nil.csail.mit.edu/6.824/2018/labs/lab-raft.html">lab2:raft</a> and <a href="http://nil.csail.mit.edu/6.824/2018/labs/lab-kvraft.html">lab3:kvraft</a> from the famous <a href="http://nil.csail.mit.edu/6.824/2018/index.html">MIT 6.824</a> course but rewritten in Rust.</p>
</blockquote>
<h2 id="abstract">Abstract</h2>
<blockquote>
<p>Raft is a consensus algorithm for managing a replicated log. It produces a result equivalent to (multi-)Paxos, andit is as efficient as Paxos, but its structure is differentfrom Paxos; this makes Raft more understandable thanPaxos and also provides a better foundation for build-ing practical systems.</p>
</blockquote>
<blockquote>
<p>Raft separates the key elements of consensus, such asleader election, log replication, and safety, and it enforcesa stronger degree of coherency to reduce the number ofstates that must be considered.</p>
</blockquote>
<h2 id="introduction">Introduction</h2>
<blockquote>
<p>Consensus algorithms allow a collection of machines to work as a coherent group that can survive the failures of some of its members.</p>
</blockquote>
<blockquote>
<p>Paxos has dominated the discussion of consensus algorithms over the last decade.</p>
</blockquote>
<blockquote>
<p>Unfortunately, Paxos is quite difficult to understand, inspite of numerous attempts to make it more approachable.Furthermore, its architecture requires complex changes to support practical systems. As a result, both systembuilders and students struggle with Paxos.</p>
</blockquote>
<blockquote>
<p>Our approach was unusual in that our primary goal was <strong>understandability</strong>.</p>
</blockquote>
<blockquote>
<p>We believe that Raft is superior to Paxos and other consensus algorithms, both for educational purposes and as a foundation for implementation.</p>
</blockquote>
<h2 id="replicated-state-machines">Replicated state machines</h2>
<p>The main idea is to compute identical copies of the same state (i.e <code>x:3, y:9</code>) in case of machines&rsquo;s failure. Most of the time, an ordered <code>wal</code> (write-ahead log) is used in the implementation, to hold the mutation (<code>x:4</code>). Keeping the replicated log consistent is the job of the consensus algorithm, here Raft.</p>
<p>Raft creates a true split between:</p>
<ul>
<li>the consensus module,</li>
<li>the wal,</li>
<li>the state machine.</li>
</ul>
<img src="/posts/notes-about-raft/images/fig_1.png" alt="fig1" class="center">
<h2 id="whats-wrong-with-paxos">What‚Äôs wrong with Paxos?</h2>
<p>The paper is listing the drawbacks of Paxos:</p>
<ul>
<li>difficult to understand, and <a href="https://www.microsoft.com/en-us/research/uploads/prod/2016/12/The-Part-Time-Parliament.pdf">I can&rsquo;t blame them</a></li>
<li>many details are missing from the paper to implement <code>Multi-Paxos</code> as the paper is mainly describing <code>single-decree Paxos</code></li>
</ul>
<blockquote>
<p>It is simpler and more efficient to design a system around a log, where new entries are appended sequentially in a constrained order.</p>
</blockquote>
<blockquote>
<p>As a result, practical systems bear little resemblance to Paxos. Each implementation begins with Paxos, discovers the difficulties in implementing it, and then develops a significantly different architecture. This is time-consuming and error-prone, and the difficulties of understanding Paxos exacerbate the problem. The following com-ment from the <a href="https://static.googleusercontent.com/media/research.google.com/en//archive/chubby-osdi06.pdf">Chubby</a> implementers is typical:</p>
</blockquote>
<blockquote>
<blockquote>
<p>There are significant gaps between the description of the Paxos algorithm and the needs of a real-world system
the final system will be based on an un-proven protocol [4].</p>
</blockquote>
</blockquote>
<h2 id="designing-for-understandability">Designing for understandability</h2>
<p>Beside all the others goals of Raft:</p>
<ul>
<li>a complete and practical foundation for system building,</li>
<li>must be safe under all conditions and available under typical operating conditions,</li>
<li>must be efficient for common operations,</li>
</ul>
<p><strong>understandability</strong> was the most difficult challenge:</p>
<blockquote>
<p>It must be possible for a large audience to understand the algorithm comfortably. In addition, it must be possible to develop intuitions about the algorithm, so that system builders can make the extensions that are inevitable in real-world implementations.</p>
</blockquote>
<blockquote>
<p>we divided problems into separate pieces that could be solved, explained, and understood relatively independently. For example, in Raft we separated leader election, log replication, safety, and membership changes.</p>
</blockquote>
<blockquote>
<p>Our second approach was to simplify the state spaceby reducing the number of states to consider, making thesystem more coherent and eliminating nondeterminism where possible.</p>
</blockquote>
<h2 id="the-raft-consensus-algorithm">The Raft consensus algorithm</h2>
<p>Raft is heavily relying on the <code>leader</code> pattern:</p>
<blockquote>
<p>Raft implements consensus by first electing a distinguished leader, then giving the leader complete responsibility for managing the replicated log.</p>
</blockquote>
<blockquote>
<p>The leader accepts log entries from clients, replicates them on other servers, and tells servers when it is safe to apply log entries to their state machines.</p>
</blockquote>
<p>Thanks to this pattern, Raft is splitting the consensus problem into 3:</p>
<ul>
<li>Leader election</li>
<li>Log replication</li>
<li>Safety</li>
</ul>
<h3 id="raft-basics">Raft basics</h3>
<p>Each server can be in one of the three states:</p>
<ul>
<li><strong>Leader</strong> handle all requests,</li>
<li><strong>Follower</strong> passive member, they issue no requests on their own but simply respond to requests from leaders and candidates,</li>
<li><strong>Candidate</strong> is used to elect a new leader.</li>
</ul>
<p>Leader is elected through <code>election</code>: Each term (interval of time of arbitrary length packed with an number) begins with an election, in which one or more candidates attempt to become leader. If a candidate wins the election, then it serves as leader for the rest of the term. In the case of a split vote, the term will end with no leader; a new term (with a new election) will begin.</p>
<blockquote>
<p>Terms act as a logical clock [14] in Raft.</p>
</blockquote>
<blockquote>
<p>Each server stores a current term number, which increases monotonically over time. Current terms are exchanged whenever servers communicate; if one server‚Äôs current term is smaller than the other‚Äôs, then it updates its current term to the larger value. If a candidate or leader discovers that its term is out of date, it immediately reverts to fol-lower state. If a server receives a request with a stale term number, it rejects the request.</p>
</blockquote>
<p><code>RPC</code> is used for communications:</p>
<ul>
<li><strong>RequestVote RPCs</strong> are initiated by candidates during elections,</li>
<li><strong>Append-Entries RPCs</strong> are initiated by leaders to replicate log en-tries and to provide a form of heartbeat.</li>
</ul>
<h3 id="leader-election">Leader election</h3>
<p>A good vizualization is available <a href="http://thesecretlivesofdata.com/raft/#election">here</a>.</p>
<p>The key-point of the election are the fact that:</p>
<ul>
<li>nodes vote for themselves,</li>
<li>the term number is used to recover from failure,</li>
<li>election timeouts are randomized.</li>
</ul>
<blockquote>
<p>To begin an election, a follower increments its current term and transitions to candidate state. It then votes for itself and issues RequestVote RPCs in parallel to each of the other servers in the cluster. A candidate continues in this state until one of three things happens:</p>
<ul>
<li>(a) it wins the election,</li>
<li>(b) another server establishes itself as leader,</li>
<li>(c) a period of time goes by with no winner.</li>
</ul>
</blockquote>
<blockquote>
<p>Raft uses randomized election timeouts to ensure that split votes are rare and that they are resolved quickly. To prevent split votes in the first place, election timeouts are chosen randomly from a fixed interval (e.g., 150‚Äì300ms).</p>
</blockquote>
<h3 id="log-replication">Log replication</h3>
<p>A good vizualization is available <a href="http://thesecretlivesofdata.com/raft/#replication">here</a>.</p>
<blockquote>
<p>Once a leader has been elected, it begins servicing client requests. Each client request contains a command to be executed by the replicated state machines. The leader appends the command to its log as a new entry, then issues AppendEntries RPCs in parallel to each of the other servers to replicate the entry. When the entry has been safely replicated (as described below), the leader applies the entry to its state machine and returns the result of that execution to the client.</p>
</blockquote>
<blockquote>
<p>The term numbers in log entries are used to detect inconsistencies between logs</p>
</blockquote>
<blockquote>
<p>The leader decides when it is safe to apply a log entry to the state machines; such an entry is called committed. Raft guarantees that committed entries are durable and will eventually be executed by all of the available state machines.</p>
</blockquote>
<p>Raft is implementing a lot of safety inside the log:</p>
<blockquote>
<p>When sending an AppendEntries RPC, the leader includes the index and term of the entry in its log that immediately precedes the new entries. If the follower does not find an entry in its log with the same index and term, then it refuses the new entries</p>
</blockquote>
<p>This is really interesting to be leader-failure proof. And for follower&rsquo;s failure:</p>
<blockquote>
<p>In Raft, the leader handles inconsistencies by forcing the followers‚Äô logs to duplicate its own.</p>
</blockquote>
<blockquote>
<p>To bring a follower‚Äôs log into consistency with its own,the leader must find the latest log entry where the two logs agree, delete any entries in the follower‚Äôs log after that point, and send the follower all of the leader‚Äôs entries after that point.</p>
</blockquote>
<h2 id="safety">Safety</h2>
<h3 id="leader-election-1">Leader election</h3>
<p>As Raft guarantees that all the committed entries are available on all followers, log entries only flow in one di-rection, from leaders to followers, and leaders never over-write existing entries in their logs.</p>
<blockquote>
<p>Raft uses the voting process to prevent a candidate from winning an election unless its log contains all committed entries. A candidate must contact a majority of the cluster in order to be elected, which means that every committed entry must be present in at least one of those servers.</p>
</blockquote>
<blockquote>
<p>Raft determines which of two logs is more up-to-date by comparing the index and term of the last entries in the logs. If the logs have last entries with different terms, then the log with the later term is more up-to-date. If the log send with the same term, then whichever log is longer is more up-to-date.</p>
</blockquote>
<h3 id="committing-entries-from-previous-terms">Committing entries from previous terms</h3>
<blockquote>
<p>Raft never commits log entries from previous terms by counting replicas. Only log entries from the leader‚Äôs current term are committed by counting replicas.</p>
</blockquote>
<p>This behavior avoids future leaders to attempt to finish replicating an entry where the leader crashes before committing an entry.</p>
<h3 id="follower-and-candidate-crashes">Follower and candidate crashes</h3>
<blockquote>
<p>If a follower or candidate crashes, then future RequestVote and AppendEntries RPCs sent to it will fail. Raft handles these failures by retrying indefinitely.</p>
</blockquote>
<h2 id="cluster-membership-changes">Cluster membership changes</h2>
<p>This section presents how to do cluster configuration(the set of servers participating in the consensus algorithm). Raft implements a two-phase approach:</p>
<blockquote>
<p>In Raft the cluster first switches to a transitional configuration we call joint consensus; once the joint consensus has been committed,the system then transitions to the new configuration. The joint consensus combines both the old and new configurations:</p>
<ul>
<li>Log entries are replicated to all servers in both con-figurations,</li>
<li>Any server from either configuration may serve asleader,</li>
<li>Agreement (for elections and entry commitment) requires separate majorities from both the old and new configurations.</li>
</ul>
</blockquote>
<h2 id="log-compaction">Log compaction</h2>
<p>As the WAL holds the commands, we need to compact it. Raft is using snapshots as describe here:</p>
<img src="/posts/notes-about-raft/images/fig_3.png" alt="fig3" class="center">
<blockquote>
<p>the leader must occasionally send snapshots to followers that lag behind.</p>
</blockquote>
<p>This is useful for slow follower or a new server joining the cluster.</p>
<blockquote>
<p>The leader uses a new RPC called InstallSnapshot to send snapshots to followers that are too far behind.</p>
</blockquote>
<h2 id="client-interaction">Client interaction</h2>
<blockquote>
<p>Clients of Raft send all of their requests to the leader. When a client first starts up, it connects to a randomly-chosen server. If the client‚Äôs first choice is not the leader,that server will reject the client‚Äôs request and supply information about the most recent leader it has heard from.</p>
</blockquote>
<hr>
<p><strong>Thank you</strong> for reading my post! Feel free to react to this article, I am also available on <a href="https://twitter.com/PierreZ">Twitter</a> if needed.</p>
]]></content>
        </item>
        
        <item>
            <title>Announcing Kafka-on-Pulsar: bring native Kafka protocol support to Apache Pulsar</title>
            <link>https://pierrezemb.fr/posts/announcing-kop/</link>
            <pubDate>Tue, 24 Mar 2020 10:24:27 +0100</pubDate>
            
            <guid>https://pierrezemb.fr/posts/announcing-kop/</guid>
            <description>This is a repost from OVHcloud&amp;rsquo;s official blogpost., please read it there to support my company. Thanks Horacio Gonzalez for the awesome drawings!
 This post has been published on both the StreamNative and OVHcloud blogs and was co-authored by Sijie Guo, Jia Zhai and Pierre Zemb. Thanks Horacio Gonzalez for the illustrations!
We are excited to announce that StreamNative and OVHcloud are open-sourcing &amp;ldquo;Kafka on Pulsar&amp;rdquo; (KoP). KoP brings the native Apache Kafka protocol support to Apache Pulsar by introducing a Kafka protocol handler on Pulsar brokers.</description>
            <content type="html"><![CDATA[<blockquote>
<p>This is a repost from <a href="https://www.ovh.com/blog/announcing-kafka-on-pulsar-bring-native-kafka-protocol-support-to-apache-pulsar/" title="Permalink to announcing KoP">OVHcloud&rsquo;s official blogpost.</a>, please read it there to support my company. Thanks <a href="https://twitter.com/LostInBrittany/">Horacio Gonzalez</a> for the awesome drawings!</p>
</blockquote>
<p>This post has been published on both the StreamNative and OVHcloud blogs and was co-authored by <a href="https://twitter.com/sijieg">Sijie Guo</a>, <a href="https://twitter.com/Jia_Zhai">Jia Zhai</a> and <a href="https://twitter.com/PierreZ">Pierre Zemb</a>. Thanks <a href="https://twitter.com/LostInBrittany">Horacio Gonzalez</a> for the illustrations!</p>
<p><img src="/posts/announcing-kop/images/kop-1.png" alt="hbase image"></p>
<p>We are excited to announce that StreamNative and OVHcloud are open-sourcing &ldquo;Kafka on Pulsar&rdquo; (KoP). KoP brings the native Apache Kafka protocol support to Apache Pulsar by introducing a Kafka protocol handler on Pulsar brokers. By adding the KoP protocol handler to your existing Pulsar cluster, you can now migrate your existing Kafka applications and services to Pulsar without modifying the code. This enables Kafka applications to leverage Pulsar&rsquo;s powerful features, such as:</p>
<ul>
<li>Streamlined operations with enterprise-grade multi-tenancy</li>
<li>Simplified operations with a rebalance-free architecture</li>
<li>Infinite event stream retention with Apache BookKeeper and tiered storage</li>
<li>Serverless event processing with Pulsar Functions</li>
</ul>
<h2 id="what-is-apache-pulsar">What is Apache Pulsar?</h2>
<p>Apache Pulsar is an event streaming platform designed from the ground up to be cloud-native- deploying a multi-layer and segment-centric architecture. The architecture separates serving and storage into different layers, making the system container-friendly. The cloud-native architecture provides scalability, availability and resiliency and enables companies to expand their offerings with real-time data-enabled solutions. Pulsar has gained wide adoption since it was open-sourced in 2016 and was designated an Apache Top-Level project in 2018.</p>
<h2 id="the-need-behind-kop">The need behind KoP</h2>
<p>Pulsar provides a unified messaging model for both queueing and streaming workloads. Pulsar implemented its own protobuf-based binary protocol to provide high performance and low latency. This choice of protobuf makes it convenient to implement Pulsar <a href="https://pulsar.apache.org/docs/en/client-libraries/">clients</a> and the project already supports Java, Go, Python and C++ languages alongside <a href="https://pulsar.apache.org/docs/en/client-libraries/#thirdparty-clients">thirdparty clients</a> provided by the community. However, existing applications written using other messaging protocols had to be rewritten to adopt Pulsar&rsquo;s new unified messaging protocol.</p>
<p>To address this, the Pulsar community developed applications to facilitate the migration to Pulsar from other messaging systems. For example, Pulsar provides a [Kafka wrapper](http://(<a href="https://pulsar.apache.org/docs/en/adaptors-kafka">https://pulsar.apache.org/docs/en/adaptors-kafka</a>) on Kafka Java API, which allows existing applications that already use Kafka Java client switching from Kafka to Pulsar <a href="https://www.youtube.com/watch?v=Cy9ev9nAZpI">without code change</a>. Pulsar also has a rich connector ecosystem, connecting Pulsar with other data systems. Yet, there was still a strong demand from those looking to switch from other Kafka applications to Pulsar.</p>
<h2 id="streamnative-and-ovhclouds-collaboration">StreamNative and OVHcloud&rsquo;s collaboration</h2>
<p>StreamNative was receiving a lot of inbound requests for help migrating from other messaging systems to Pulsar and recognized the need to support other messaging protocols (such as AMQP and Kafka) natively on Pulsar. StreamNative began working on introducing a general protocol handler framework in Pulsar that would allow developers using other messaging protocols to use Pulsar.</p>
<p>Internally, OVHcloud had been running Apache Kafka for years, but despite their experience operating multiple clusters with millions of messages per second on Kafka, there were painful operational challenges. For example, putting thousands of topics from thousands of users into a single cluster was difficult without multi-tenancy.</p>
<p>As a result, OVHcloud decided to shift and build the foundation of their topic-as-a-service product, called ioStream, on Pulsar instead of Kafka. Pulsar&rsquo;s multi-tenancy and the overall architecture with Apache Bookkeeper simplified operations compared to Kafka.</p>
<p>After spawning the first region, OVHcloud decided to implement it as a proof-of-concept proxy capable of transforming the Kafka protocol to Pulsar on the fly. During this process, OVHcloud discovered that StreamNative was working on bringing the Kafka protocol natively to Pulsar, and they joined forces to develop KoP.</p>
<p><img src="/posts/announcing-kop/images/kop-2.png" alt="hbase image"></p>
<p>KoP was developed to provide a streamlined and comprehensive solution leveraging Pulsar and BookKeeper&rsquo;s event stream storage infrastructure and Pulsar&rsquo;s pluggable protocol handler framework. KoP is implemented as a protocol handler plugin with protocol name &ldquo;kafka&rdquo;. It can be installed and configured to run as part of Pulsar brokers.</p>
<h2 id="the-distributed-log">The distributed log</h2>
<p>Both Pulsar and Kafka share a very similar data model around <strong>log</strong> for both pub/sub messaging and event streaming. For example, both are built on top of a distributed log. A key difference between these two systems is how they implement the distributed log. Kafka implements the distributed log in a partition-basis architecture, where a distributed log (a partition in Kafka) is designated to store in a set of brokers, while Pulsar deploys a <strong>segment</strong>-based architecture to implement its distributed log by leveraging Apache BookKeeper as its scale-out segment storage layer. Pulsar&rsquo;s <em>segment</em> based architecture provides benefits such as rebalance-free, instant scalability, and infinite event stream storage. You can learn more about the key differences between Pulsar and Kafka in <a href="https://www.splunk.com/en_us/blog/it/comparing-pulsar-and-kafka-how-a-segment-based-architecture-delivers-better-performance-scalability-and-resilience.html">this Splunk blog</a> and in <a href="http://bookkeeper.apache.org/distributedlog/technical-review/2016/09/19/kafka-vs-distributedlog.html">this blog from the Bookkeeper project</a>.</p>
<p>Since both of the systems are built on a similar data model, a distributed log, it is very simple to implement a Kafka-compatible protocol handler by leveraging Pulsar&rsquo;s distributed log storage and its pluggable protocol handler framework (introduced in the 2.5.0 release).</p>
<h2 id="implementations">Implementations</h2>
<p>The implementation is done by comparing the protocols between Pulsar and Kafka. We found that there are a lot of similarities between these two protocols. Both protocols are comprised of the following operations:</p>
<ul>
<li><strong>Topic Lookup</strong>: All the clients connect to any broker to lookup the metadata (i.e. the owner broker) of the topics. After fetching the metadata, the clients establish persistent TCP connections to the owner brokers.</li>
<li><strong>Produce</strong>: The clients talk to the <strong>owner</strong> broker of a topic partition to append the messages to a distributed log.</li>
<li><strong>Consume</strong>: The clients talk to the <strong>owner</strong> broker of a topic partition to read the messages from a distributed log.</li>
<li><strong>Offset</strong>: The messages produced to a topic partition are assigned with an offset. The offset in Pulsar is called MessageId. Consumers can use <strong>offsets</strong> to seek to a given position within the log to read messages.</li>
<li><strong>Consumption State</strong>: Both systems maintain the consumption state for consumers within a subscription (or a consumer group in Kafka). The consumption state is stored in __offsets topic in Kafka, while the consumption state is stored as cursors in Pulsar.</li>
</ul>
<p>As you can see, these are all the primitive operations provided by a scale-out distributed log storage such as Apache BookKeeper. The core capabilities of Pulsar are implemented on top of Apache BookKeeper. Thus it is pretty easy and straightforward to implement the Kafka concepts by using the existing components that Pulsar has developed on BookKeeper.<br>
The following figure illustrates how we add the Kafka protocol support within Pulsar. We are introducing a new <strong>Protocol Handler</strong>which implements the Kafka wire protocol by leveraging the existing components (such as topic discovery, the distributed log library ‚Äì ManagedLedger, cursors and etc) that Pulsar already has.</p>
<p><img src="/posts/announcing-kop/images/kop-3.png" alt="hbase image"></p>
<h3 id="topics">Topics</h3>
<p>In Kafka, all the topics are stored in one flat namespace. But in Pulsar, topics are organized in hierarchical multi-tenant namespaces. We introduce a setting <em>kafkaNamespace</em> in broker configuration to allow the administrator configuring to map Kafka topics to Pulsar topics.</p>
<p>In order to let Kafka users leverage the multi-tenancy feature of Apache Pulsar, a Kafka user can specify a Pulsar tenant and namespace as its SASL username when it uses SASL authentication mechanism to authenticate a Kafka client.</p>
<h3 id="message-id-and-offset">Message ID and offset</h3>
<p>In Kafka, each message is assigned with an offset once it is successfully produced to a topic partition. In Pulsar, each message is assigned with a <code>MessageID</code>. The message id consists of 3 components, <em>ledger-id</em>, <em>entry-id</em>, and <em>batch-index</em>. We are using the same approach in Pulsar-Kafka wrapper to convert a Pulsar MessageID to an offset and vice versa.</p>
<h3 id="messages">Messages</h3>
<p>Both a Kafka message and a Pulsar message have key, value, timestamp, and headers (note: this is called &lsquo;properties&rsquo; in Pulsar). We convert these fields automatically between Kafka messages and Pulsar messages.</p>
<h3 id="topic-lookup">Topic lookup</h3>
<p>We use the same topic lookup approach for the Kafka request handler as the Pulsar request handler. The request handler does topic discovery to lookup all the ownerships for the requested topic partitions and responds with the ownership information as part of Kafka TopicMetadata back to Kafka clients.</p>
<h3 id="produce-messages">Produce Messages</h3>
<p>When the Kafka request handler receives produced messages from a Kafka client, it converts Kafka messages to Pulsar messages by mapping the fields (i.e. key, value, timestamp and headers) one by one, and uses the ManagedLedger append API to append those converted Pulsar messages to BookKeeper. Converting Kafka messages to Pulsar messages allows existing Pulsar applications to consume messages produced by Kafka clients.</p>
<h3 id="consume-messages">Consume Messages</h3>
<p>When the Kafka request handler receives a consumer request from a Kafka client, it opens a non-durable cursor to read the entries starting from the requested offset. The Kafka request handler converts the Pulsar messages back to Kafka messages to allow existing Kafka applications to consume the messages produced by Pulsar clients.</p>
<h3 id="group-coordinator--offsets-management">Group coordinator &amp; offsets management</h3>
<p>The most challenging part is to implement the group coordinator and offsets management. Because Pulsar doesn&rsquo;t have a centralized group coordinator for assigning partitions to consumers of a consumer group and managing offsets for each consumer group. In Pulsar, the partition assignment is managed by broker on a per-partition basis, and the offset management is done by storing the acknowledgements in cursors by the owner broker of that partition.</p>
<p>It is difficult to align the Pulsar model with the Kafka model. Hence, for the sake of providing full compatibility with Kafka clients, we implemented the Kafka group coordinator by storing the coordinator group changes and offsets in a system topic called _public/kafka/_<em>offsets</em> in Pulsar.</p>
<p>This allows us to bridge the gap between Pulsar and Kafka and allows people to use existing Pulsar tools and policies to manage subscriptions and monitor Kafka consumers. We add a background thread in the implemented group coordinator to periodically sync offset updates from the system topic to Pulsar cursors. Hence a Kafka consumer group is effectively treated as a Pulsar subscription. All the existing Pulsar toolings can be used for managing Kafka consumer groups as well.</p>
<h2 id="bridge-two-popular-messaging-ecosystems">Bridge two popular messaging ecosystems</h2>
<p>At both companies, we value customer success. We believe that providing a native Kafka protocol on Apache Pulsar will reduce the barriers for people adopting Pulsar to achieve their business success. By integrating two popular event streaming ecosystems, KoP unlocks new use cases. Customers can leverage advantages from each ecosystem and build a truly unified event streaming platform with Apache Pulsar to accelerate the development of real-time applications and services.</p>
<p>With KoP, a log collector can continue collecting log data from its sources and producing messages to Apache Pulsar using existing Kafka integrations. The downstream applications can use Pulsar Functions to process the events arriving in the system to do serverless event streaming.</p>
<h2 id="try-it-out">Try it out</h2>
<p>KoP is open sourced under Apache License V2 in <a href="https://github.com/streamnative/kop">https://github.com/streamnative/kop</a>.</p>
<p>We are looking forward to your issues, and PRs. You can also <a href="https://apache-pulsar.herokuapp.com/">join #kop channel in Pulsar Slack</a> to discuss all things about Kafka-on-Pulsar.</p>
<p>StreamNative and OVHcloud are also hosting a webinar about KoP on March 31. If you are interested in learning more details about KoP,<a href="https://zoom.us/webinar/register/6515842602644/WN_l_i-3ekDSg6PwPFn7tqRvA">please sign up</a>. Looking forward to meeting you online.</p>
<p><img src="/posts/announcing-kop/images/kop-4.png" alt="hbase image"></p>
<h2 id="thanks">Thanks</h2>
<p>The KoP project was originally initiated by StreamNative. The OVHcloud team joined the project to collaborate on the development of the KoP project. Many thanks to Pierre Zemb and Steven Le Roux from OVHcloud for their contributions to this project!</p>
]]></content>
        </item>
        
        <item>
            <title>Contributing to Apache HBase: custom data balancing</title>
            <link>https://pierrezemb.fr/posts/hbase-custom-data-balancing/</link>
            <pubDate>Fri, 14 Feb 2020 10:24:27 +0100</pubDate>
            
            <guid>https://pierrezemb.fr/posts/hbase-custom-data-balancing/</guid>
            <description>This is a repost from OVHcloud&amp;rsquo;s official blogpost., please read it there to support my company. Thanks Horacio Gonzalez for the awesome drawings!
 In today&amp;rsquo;s blogpost, we&amp;rsquo;re going to take a look at our upstream contribution to Apache HBase&amp;rsquo;s stochastic load balancer, based on our experience of running HBase clusters to support OVHcloud&amp;rsquo;s monitoring.
The context Have you ever wondered how:
 we generate the graphs for your OVHcloud server or web hosting package?</description>
            <content type="html"><![CDATA[<blockquote>
<p>This is a repost from <a href="https://www.ovh.com/blog/contributing-to-apache-hbase-custom-data-balancing/" title="Permalink to Contributing to Apache HBase: custom data balancing">OVHcloud&rsquo;s official blogpost.</a>, please read it there to support my company. Thanks <a href="https://twitter.com/LostInBrittany/">Horacio Gonzalez</a> for the awesome drawings!</p>
</blockquote>
<p>In today&rsquo;s blogpost, we&rsquo;re going to take a look at our upstream
contribution to Apache HBase&rsquo;s stochastic load balancer, based on our
experience of running HBase clusters to support OVHcloud&rsquo;s monitoring.</p>
<p><img src="/posts/hbase-custom-data-balancing/images/hbase-ovh-1.jpeg" alt="hbase image"></p>
<h2 id="the-context">The context</h2>
<p>Have you ever wondered how:</p>
<ul>
<li>we generate the graphs for your OVHcloud server or web hosting package?</li>
<li>our internal teams monitor their own servers and applications?</li>
</ul>
<p><strong>All internal teams are constantly gathering telemetry and monitoring data</strong> and sending them to a <strong>dedicated team,</strong> who are responsible for <strong>handling all the metrics and logs generated by OVHcloud&rsquo;s infrastructure</strong>: the Observability team.</p>
<p>We tried a lot of different <strong>Time Series databases</strong>, and eventually chose <a href="https://warp10.io/">Warp10</a> to handle our workloads. <strong>Warp10</strong> can be integrated with the various <strong>big-data solutions</strong> provided by the <a href="https://www.apache.org/">Apache Foundation.</a> In our case, we use <a href="http://hbase.apache.org/">Apache HBase</a> as the long-term storage datastore for our metrics.</p>
<p><a href="http://hbase.apache.org/">Apache HBase</a>, a datastore built on top of <a href="http://hadoop.apache.org/">Apache Hadoop</a>, provides <strong>an elastic, distributed, key-ordered map.</strong> As such, one of the key features of Apache HBase for us is the ability to <strong>scan</strong>, i.e. retrieve a range of keys. Thanks to this feature, we can fetch <strong>thousands of datapoints in an optimised way</strong>.</p>
<p>We have our own dedicated clusters, the biggest of which has more than 270 nodes to spread our workloads:</p>
<ul>
<li>between 1.6 and 2 million writes per second, 24/7</li>
<li>between 4 and 6 million reads per second</li>
<li>around 300TB of telemetry, stored within Apache HBase</li>
</ul>
<p>As you can probably imagine, storing 300TB of data in 270 nodes comes with some challenges regarding repartition, as <strong>every</strong> <strong>bit is hot data, and should be accessible at any time</strong>. Let&rsquo;s dive in!</p>
<h2 id="how-does-balancing-work-in-apache-hbase">How does balancing work in Apache HBase?</h2>
<p>Before diving into the balancer, let&rsquo;s take a look at how it works. In Apache HBase, data is split into shards called <code>Regions</code>, and distributed through <code>RegionServers</code>. The number of regions will increase as the data is coming in, and regions will be split as a result. This is where the <code>Balancer</code> comes in. It will <strong>move regions</strong> to avoid hotspotting a single <code>RegionServer</code> and effectively distribute the load.</p>
<p><img src="/posts/hbase-custom-data-balancing/images/hbase-ovh-2.jpeg" alt="hbase image"></p>
<p>The actual implementation, called <a href="https://github.com/apache/hbase/blob/master/hbase-server/src/main/java/org/apache/hadoop/hbase/master/balancer/StochasticLoadBalancer.java">StochasticBalancer</a>, uses <strong>a cost-based approach:</strong></p>
<ol>
<li>It first computes the <strong>overall cost</strong> of the cluster, by looping through <code>cost functions</code>. Every cost function <strong>returns a number between 0 and 1 inclusive</strong>, where 0 is the lowest cost-best solution, and 1 is the highest possible cost and worst solution. Apache Hbase is coming with several cost functions, which are measuring things like region load, table load, data locality, number of regions per RegionServers&hellip; The computed costs are <strong>scaled by their respective coefficients, defined in the configuration</strong>.</li>
<li>Now that the initial cost is computed, we can try to <code>Mutate</code> our cluster. For this, the Balancer creates a random <code>nextAction</code>, which could be something like <strong>swapping two regions</strong>, or <strong>moving one region to another RegionServer</strong>. The action is <strong>applied</strong> <strong>virtually</strong> , and then the <strong>new cost is calculated</strong>. If the new cost is lower than our previous one, the action is stored. If not, it is skipped. This operation is repeated <code>thousands of times</code>, hence the <code>Stochastic</code>.</li>
<li>At the end, <strong>the list of valid actions is applied to the actual cluster.</strong></li>
</ol>
<h2 id="what-was-not-working-for-us">What was not working for us?</h2>
<p>We found out that <strong>for our specific use case</strong>, which involved:</p>
<ul>
<li>Single table</li>
<li>Dedicated Apache HBase and Apache Hadoop, <strong>tailored for our requirements</strong></li>
<li>Good key distribution</li>
</ul>
<p><strong>the number of regions per RegionServer was the real limit for us</strong>.</p>
<p>Even if the balancing strategy seems simple, <strong>we do think that being able to run an Apache HBase cluster on heterogeneous hardware is vital</strong>, especially in cloud environments, because you <strong>may not be able to buy the same server specs again in the future.</strong>
In our earlier example, our cluster grew from 80 to ~250 machines in
four years. Throughout that time, we bought new dedicated server
references, and even tested some special internal references.</p>
<p>We ended-up with differents groups of hardware: <strong>some servers can handle only 180 regions, whereas the biggest can handle more than 900</strong>. Because of this disparity, we had to disable the Load Balancer to avoid the <a href="https://github.com/apache/hbase/blob/master/hbase-server/src/main/java/org/apache/hadoop/hbase/master/balancer/StochasticLoadBalancer.java#L1194">RegionCountSkewCostFunction</a>, which would try to bring all RegionServers to the same number of regions.</p>
<p><img src="/posts/hbase-custom-data-balancing/images/hbase-ovh-3.jpeg" alt="hbase image"></p>
<p>Two years ago we developed some internal tools, which are responsible
for load balancing regions across RegionServers. The tooling worked
really good for our use case, simplifying the day-to-day operation of
our cluster.</p>
<p><strong>Open source is at the DNA of OVHcloud</strong>, and that means that we build our tools on open source software, but also that we <strong>contribute</strong>
and give it back to the community. When we talked around, we saw that
we weren&rsquo;t the only one concerned by the heterogenous cluster problem.
We decided to rewrite our tooling to make it more general, and to <strong>contribute</strong> it <strong>directly upstream</strong> to the HBase project <strong>.</strong></p>
<h2 id="our-contributions">Our contributions</h2>
<p>The first contribution was pretty simple, the cost function list was a <a href="https://github.com/apache/hbase/blob/8cb531f207b9f9f51ab1509655ae59701b66ac37/hbase-server/src/main/java/org/apache/hadoop/hbase/master/balancer/StochasticLoadBalancer.java#L199-L213">constant</a>. We <a href="https://github.com/apache/hbase/commit/836f26976e1ad8b35d778c563067ed0614c026e9">added the possibility to load custom cost functions</a>.</p>
<p>The second contribution was about <a href="https://github.com/apache/hbase/commit/42d535a57a75b58f585b48df9af9c966e6c7e46a">adding an optional costFunction to balance regions according to a capacity rule</a>.</p>
<h2 id="how-does-it-works">How does it works?</h2>
<p>The balancer will load a file containing lines of rules. <strong>A rule is composed of a regexp for hostname, and a limit.</strong> For example, we could have:</p>
<pre><code>rs[0-9] 200
rs1[0-9] 50
</code></pre><p>RegionServers with <strong>hostnames matching the first rules will have a limit of 200</strong>, and <strong>the others 50</strong>. If there&rsquo;s no match, a default is set.</p>
<p>Thanks to these rule, we have two key pieces of information:</p>
<ul>
<li>the <strong>max number of regions for this cluster</strong></li>
<li>the *<em>rules for each servers</em></li>
</ul>
<p>The <code>HeterogeneousRegionCountCostFunction</code> will try to <strong>balance regions, according to their capacity.</strong></p>
<p>Let&rsquo;s take an example&hellip; Imagine that we have 20 RS:</p>
<ul>
<li>10 RS, named <code>rs0</code> to <code>rs9</code>, loaded with 60 regions each, which can each handle 200 regions.</li>
<li>10 RS, named <code>rs10</code> to <code>rs19</code>, loaded with 60 regions each, which can each handle 50 regions.</li>
</ul>
<p>So, based on the following rules:</p>
<pre><code>rs[0-9] 200
rs1[0-9] 50
</code></pre><p>&hellip; we can see that the <strong>second group is overloaded</strong>, whereas the first group has plenty of space.</p>
<p>We know that we can handle a maximum of <strong>2,500 regions</strong> (200√ó10 + 50√ó10), and we have currently <strong>1,200 regions</strong> (60√ó20). As such, the <code>HeterogeneousRegionCountCostFunction</code> will understand that the cluster is <strong>full at 48.0%</strong> (1200/2500). Based on this information, we will then <strong>try to put all the RegionServers at ~48% of the load, according to the rules.</strong></p>
<p><img src="/posts/hbase-custom-data-balancing/images/hbase-ovh-4.jpeg" alt="hbase image"></p>
<h2 id="where-to-next">Where to next?</h2>
<p>Thanks to Apache HBase&rsquo;s contributors, our patches are now <strong>merged</strong> into the master branch. As soon as Apache HBase maintainers publish a new release, we will deploy and use it at scale. This <strong>will allow more automation on our side, and ease operations for the Observability Team.</strong></p>
<p>Contributing was an awesome journey. What I love most about open
source is the opportunity ability to contribute back, and build stronger
software. We <strong>had an opinion</strong> about how a particular issue should addressed, but <strong>the discussions with the community helped us to refine it</strong>. We spoke with e <strong>ngineers from other companies, who were struggling with Apache HBase&rsquo;s cloud deployments, just as we were</strong>, and thanks to those exchanges, <strong>our contribution became more and more relevant.</strong></p>
]]></content>
        </item>
        
        <item>
            <title>Notes about FoundationDB</title>
            <link>https://pierrezemb.fr/posts/notes-about-foundationdb/</link>
            <pubDate>Thu, 30 Jan 2020 10:24:27 +0100</pubDate>
            
            <guid>https://pierrezemb.fr/posts/notes-about-foundationdb/</guid>
            <description>Notes About is a blogpost serie you will find a lot of links, videos, quotes, podcasts to click on about a specific topic. Today we will discover FoundationDB.
 Overview of FoundationDB As stated in the official documentation:
 FoundationDB is a distributed database designed to handle large volumes of structured data across clusters of commodity servers. It organizes data as an ordered key-value store and employs ACID transactions for all operations.</description>
            <content type="html"><![CDATA[<p><img src="/posts/notes-about-foundationdb/images/fdb-white.jpg" alt="fdb image"></p>
<p><a href="/tags/notesabout/">Notes About</a> is a blogpost serie  you will find a lot of <strong>links, videos, quotes, podcasts to click on</strong> about a specific topic. Today we will discover FoundationDB.</p>
<hr>
<h2 id="overview-of-foundationdb">Overview of FoundationDB</h2>
<p>As stated in the <a href="https://apple.github.io/foundationdb/index.html">official documentation</a>:</p>
<blockquote>
<p>FoundationDB is a distributed database designed to handle large volumes of structured data across clusters of commodity servers. It organizes data as an ordered key-value store and employs ACID transactions for all operations. It is especially well-suited for read/write workloads but also has excellent performance for write-intensive workloads.</p>
</blockquote>
<p>It has strong key points:</p>
<ul>
<li>Multi-model data store</li>
<li>Easily scalable and fault tolerant</li>
<li>Industry-leading performance</li>
<li>Open source.</li>
</ul>
<p>From a database dialect, it provides:</p>
<ul>
<li><a href="https://jepsen.io/consistency/models/strict-serializable">strict serializability</a>(operations appear to have occurred in some order),</li>
<li><a href="https://cloud.google.com/spanner/docs/true-time-external-consistency">external consistency</a>(For any two transactions, T1 and T2, if T2 starts to commit after T1 finishes committing, then the timestamp for T2 is greater than the timestamp for T1).</li>
</ul>
<p><strong>And this is THE tweet that triggered a lot of curiosity on my side:</strong></p>
<blockquote class="twitter-tweet"><p lang="en" dir="ltr"><a href="https://twitter.com/obfuscurity?ref_src=twsrc%5Etfw">@obfuscurity</a> haven&#39;t tested foundation in part because their testing appears to be waaaay more rigorous than mine.</p>&mdash; Yukon Whorenelius (@aphyr) <a href="https://twitter.com/aphyr/status/405017101804396546?ref_src=twsrc%5Etfw">November 25, 2013</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<h2 id="the-story">The story</h2>
<p>FoundationDB started as a company in 2009, and then <a href="https://techcrunch.com/2015/03/24/apple-acquires-durable-database-company-foundationdb/">has been acquired in 2015 by Apple</a>. It <a href="https://news.ycombinator.com/item?id=9259986">was a bad public publicity for the database as the download were removed.</a></p>
<p>On April 19, 2018, Apple <a href="https://www.foundationdb.org/blog/foundationdb-is-open-source/">open sourced the software, releasing it under the Apache 2.0 license</a>.</p>
<h2 id="tooling-before-coding">Tooling before coding</h2>
<h3 id="flow">Flow</h3>
<p>From the <a href="https://apple.github.io/foundationdb/engineering.html">Engineering page</a>:</p>
<blockquote>
<p>FoundationDB began with ambitious goals for both high performance per node and scalability. We knew that to achieve these goals we would face serious engineering challenges that would require tool breakthroughs. We‚Äôd need efficient asynchronous communicating processes like in Erlang or the Async in .NET, but we‚Äôd also need the raw speed, I/O efficiency, and control of C++. To meet these challenges, we developed several new tools, the most important of which is <strong>Flow</strong>, a new programming language that brings actor-based concurrency to C++11.</p>
</blockquote>
<p>Flow is more of a <strong>stateful distributed system framework</strong> than an asynchronous library. It takes a number of highly opinionated stances on how the overall distributed system should be written, and isn‚Äôt trying to be a widely reusable building block.</p>
<blockquote>
<p>Flow adds about 10 keywords to C++11 and is technically a trans-compiler: the Flow compiler reads Flow code and compiles it down to raw C++11, which is then compiled to a native binary with a traditional toolchain.</p>
</blockquote>
<p>Flow was developed before FDB, as stated in this <a href="https://news.ycombinator.com/item?id=5319163">2013&rsquo;s post</a>:</p>
<blockquote>
<p>FoundationDB founder here. Flow sounds crazy. What hubris to think that you need a new programming language for your project? Three years later: Best decision we ever made.</p>
</blockquote>
<blockquote>
<p>We knew this was going to be a long project so we invested heavily in tools at the beginning. The first two weeks of FoundationDB were building this new programming language to give us the speed of C++ with high level tools for actor-model concurrency. But, the real magic is how Flow enables us to use our real code to do deterministic simulations of a cluster in a single thread. We have a white paper upcoming on this.</p>
</blockquote>
<blockquote>
<p>We&rsquo;ve had quite a bit of interest in Flow over the years and I&rsquo;ve given several talks on it at meetups/conferences. We&rsquo;ve always thought about open-sourcing it&hellip; It&rsquo;s not as elegant as some other actor-model languages like Scala or Erlang (see: C++) but it&rsquo;s nice and fast at run-time and really helps productivity vs. writing callbacks, etc.</p>
</blockquote>
<blockquote>
<p>(Fun fact: We&rsquo;ve only ever found two bugs in Flow. After the first, we decided that we never wanted a bug again in our programming language. So, we built a program in Python that generates random Flow code and independently-executes it to validate Flow&rsquo;s behavior. This fuzz tester found one more bug, and we&rsquo;ve never found another.)</p>
</blockquote>
<p>A very good overview of Flow is available <a href="https://apple.github.io/foundationdb/flow.html">here</a> and some details <a href="https://forums.foundationdb.org/t/why-was-flow-developed/1711/3">here</a>.</p>
<h3 id="simulation-driven-development">Simulation-Driven development</h3>
<p>One of Flow‚Äôs most important job is enabling <strong>Simulation</strong>:</p>
<blockquote>
<p>We wanted FoundationDB to survive failures of machines, networks, disks, clocks, racks, data centers, file systems, etc., so we created a simulation framework closely tied to Flow. By replacing physical interfaces with shims, replacing the main epoll-based run loop with a time-based simulation, and running multiple logical processes as concurrent Flow Actors, Simulation is able to conduct a deterministic simulation of an entire FoundationDB cluster within a single-thread! Even better, we are able to execute this simulation in a deterministic way, enabling us to reproduce problems and add instrumentation ex post facto. This incredible capability enabled us to build FoundationDB exclusively in simulation for the first 18 months and ensure exceptional fault tolerance long before it sent its first real network packet. For a database with as strong a contract as the FoundationDB, testing is crucial, and over the years we have run the equivalent of a trillion CPU-hours of simulated stress testing.</p>
</blockquote>
<p>A good overview of the simulation can be found <a href="https://apple.github.io/foundationdb/testing.html">here</a>. You can also have a look at this awesome talk!</p>

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/4fFDFbi3toc" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>

<p>Simulation has been made possible by combining:</p>
<ul>
<li>Single-threaded pseudo-concurrency,</li>
<li>Simulated implementation of all external communication,</li>
<li>determinism.</li>
</ul>
<p>Here&rsquo;s an example of a <a href="https://github.com/apple/foundationdb/blob/master/tests/slow/SwizzledCycleTest.txt">testfile</a>:</p>
<pre><code>testTitle=SwizzledCycleTest
    testName=Cycle
    transactionsPerSecond=5000.0
    testDuration=30.0
    expectedRate=0.01

    testName=RandomClogging
    testDuration=30.0
    swizzle = 1

    testName=Attrition
    machinesToKill=10
    machinesToLeave=3
    reboot=true
    testDuration=30.0

    testName=Attrition
    machinesToKill=10
    machinesToLeave=3
    reboot=true
    testDuration=30.0

    testName=ChangeConfig
    maxDelayBeforeChange=30.0
    coordinators=auto
</code></pre><p>The test is splitted into two parts:</p>
<ul>
<li>
<p><strong>The goal</strong>, for example doing transaction pointing to another with thousands of transactions per sec and there should be only 0.01% of success.</p>
</li>
<li>
<p><strong>What will be done to try to prevent the test to succeed</strong>. In this example it will <strong>at the same time</strong>:</p>
<ul>
<li>do random clogging. Which means that <strong>network connections will be stopped</strong> (preventing actors to send and receive packets). Swizzle flag means that a subset of network connections will be stopped and bring back in reverse order, üò≥</li>
<li>will <strong>poweroff/reboot machines</strong> (attritions) pseudo-randomly while keeping a minimal of three machines, ü§Ø</li>
<li><strong>change configuration</strong>, which means a coordination changes through multi-paxos for the whole cluster. üò±</li>
</ul>
</li>
</ul>
<p>Keep in mind that all these failures will appears <strong>at the same time!</strong> Do you think that your current <strong>datastore has gone through the same test on a daily basis?</strong> <a href="https://github.com/etcd-io/etcd/pull/11308">I think not</a>.</p>
<p>Applications written using the FoundationDB simulator have hierarchy: <code>DataCenter -&gt; Machine -&gt; Process -&gt; Interface</code>. <strong>Each of these can be killed/freezed/nuked</strong>. Even faulty admin commands fired by some DevOps are tested!</p>
<h3 id="known-limitations">Known limitations</h3>
<p>Limitations are well described in the <a href="https://apple.github.io/foundationdb/known-limitations.html">official documentation</a>.</p>
<h3 id="recap">Recap</h3>
<p>An awesome recap is available on the <a href="https://softwareengineeringdaily.com/2019/07/01/foundationdb-with-ryan-worl/">Software Engineering Daily podcast</a>:</p>
<blockquote>
<p>FoundationDB is tested in a very rigorous way using what&rsquo;s called <strong>a deterministic simulation</strong>. The reason they needed a new programming language to do this, is that to get a deterministic simulation, you have to make something that is deterministic. It&rsquo;s kind of obvious, but it&rsquo;s hard to do.</p>
</blockquote>
<blockquote>
<p>For example, if your process interacts with the network, or disks, or clocks, it&rsquo;s not deterministic. If you have multiple threads, not deterministic. So, they needed a way to write a concurrent program that could talk with networks and disks and that type of thing. They needed a way to write a concurrent program that does all of those things that you would think are non-deterministic in a deterministic way.</p>
</blockquote>
<blockquote>
<p>So, all FoundationDB processes, and FoundationDB, it&rsquo;s basically all written in Flow except a very small amount of it from the SQLite B-tree. The reason why that was useful is that when you use Flow, you get all of these higher level abstraction that let what you do what feels to you like asynchronous stuff, but under the hood, it&rsquo;s all implemented using callbacks in C++, which you can make deterministic by running it in a single thread. So, there&rsquo;s a scheduler that just calls these callbacks one after another and it&rsquo;s very crazy looking C++ code, like you wouldn&rsquo;t want to read it, but it&rsquo;s because of Flow they were able to implement that deterministic simulation.</p>
</blockquote>
<h2 id="the-architecture">The Architecture</h2>
<p>According to the <a href="https://apple.github.io/foundationdb/administration.html#fdbmonitor-and-fdbserver">fdbmonitor and fdbserver</a>:</p>
<blockquote>
<p>The core FoundationDB server process is <code>fdbserver</code>. Each <code>fdbserver</code> process uses up to one full CPU core, so a production FoundationDB cluster will usually run N such processes on an N-core system.</p>
</blockquote>
<blockquote>
<p>To make configuring, starting, stopping, and restarting fdbserver processes easy, FoundationDB also comes with a singleton daemon process, <code>fdbmonitor</code>, which is started automatically on boot. <code>fdbmonitor</code> reads the <code>foundationdb.conf</code> file and starts the configured set of fdbserver processes. It is also responsible for starting backup-agent.</p>
</blockquote>
<p>The whole architecture is designed to automatically:</p>
<ul>
<li>load-balanced data and traffic,</li>
<li>self-healing.</li>
</ul>
<h3 id="microservices">Microservices</h3>
<p>A typical FDB cluster is composed of different actors which are describe <a href="https://github.com/apple/foundationdb/blob/master/documentation/sphinx/source/kv-architecture.rst">here</a>.</p>
<p>The most important role in FDB is the <code>Coordinator</code>, it uses <code>Paxos</code> to manage membership on a quorum to do writes. The <code>Coordinator</code> is mostly only used to elect some peers and during recovery. You can view it as a Zookeeper-like stack.</p>
<p>The Coordinator starts by electing a <code>Cluster Controller</code>. It provides administratives informations about the cluster(I have 4 storage processes). Every process needs to register to the <code>Cluster Controller</code> and then it will assign roles to them. It is the one that will heart-beat all the processes.</p>
<p>Then a <code>Master</code> is elected. The <code>Master</code> process is reponsible for the <code>data distribution</code> algorithms. Fun fact, the mapping between keys and storage servers is stored within FDB, which is you can actually move data by running transactions like any other application. He is also the one providing <code>read versions</code> and <code>version number</code> internally. He is also acting as the <code>RateKeeper</code>.</p>
<p><code>The Proxies</code> are responsible for providing read versions, committing transactions, and tracking the storage servers responsible for each range of keys.</p>
<p><code>The Transaction Resolvers</code> are responsible determining conflicts between transactions. A transaction conflicts if it reads a key that has been written between the transaction‚Äôs read version and commit version. The resolver does this by holding the last 5 seconds of committed writes in memory, and comparing a new transaction‚Äôs reads against this set of commits.</p>
<p><img src="/posts/notes-about-foundationdb/images/architecture.png" alt="fdb image"></p>
<h3 id="read-and-write-path">Read and Write Path</h3>

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/EMwhsGsxfPU" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>

<h4 id="read-path">Read Path</h4>
<ol>
<li>Retrieve a consistend read version for the transaction</li>
<li>Do reads from a consistent MVCC snapshot at that read version on the storage node</li>
</ol>
<h4 id="write-path">Write Path</h4>
<ol>
<li>client is sending a bundle to the <code>proxy</code> containing:
<ul>
<li>read version for the transaction</li>
<li>every readen key</li>
<li>every mutation that you want to do</li>
</ul>
</li>
<li>The proxy will assign a <code>Commit version</code> to a batch of transactions. <code>Commit version</code> is generated by the <code>Master</code></li>
<li>Proxy is sending to the resolver. This will check if the data that you want to mutate has been changed between your <code>read Version</code> and your <code>Commit version</code>. They are sharded by key-range.</li>
<li>Transaction is made durable within the <code>Transaction Logs</code> by <code>fsync</code>ing the data. Before the data is even written to disk it is forwarded to the <code>storage servers</code> responsible for that mutation. Internally, <code>Transactions Logs</code> are creating <strong>a stream per <code>Storage Server</code></strong>. Once the <code>storage servers</code> have made the mutation durable, they pop it from the log. This generally happens roughly 6 seconds after the mutation was originally committed to the log.</li>
<li><code>Storage servers</code> are lazily updating data on disk from the <code>Transaction logs</code>. They are keeping new write in-memory.</li>
<li><code>Transaction Logs</code> is responding OK to the Proxy and then the proxy is replying OK to the client.</li>
</ol>
<p>You can find more diagrams about transactions <a href="https://forums.foundationdb.org/t/technical-overview-of-the-database/135/3">here</a>.</p>
<h3 id="recovery">Recovery</h3>
<p>Recovery processes are detailled at around 25min.</p>
<p>During failure of a process (Except storage servers), the systems will try to create a new <code>generation</code>, so new <code>Master</code>, <code>proxies</code>, <code>resolvers</code> and <code>transactions logs</code>. New master will get a read version from transactions logs, and commit with <code>Paxos</code> the fact that starting from <code>Read version</code>, the new generation is the one in charge.</p>
<p><code>Storage servers</code> are replicating data on failures.</p>
<h3 id="the-5-second-transaction-limit">The 5-second transaction limit</h3>
<p>FoundationDB currently does not support transactions running for over five seconds. More details around 16min but the <code>tl;dr</code> is:</p>
<ul>
<li>Storage servers are caching latest read in-memory,</li>
<li>Resolvers are caching the last 5 seconds transactions.</li>
</ul>
<h3 id="ratekeeper">Ratekeeper</h3>
<p>More details around 31min but the <code>tl;dr</code> is that when system is saturated, retrieving the <code>Read version</code> is slowed down.</p>
<h3 id="storage">Storage</h3>
<p>A lot of information are available in this talk:</p>

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/nlus1Z7TVTI" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>

<ul>
<li><code>memory</code> is optimized for small databases. Data is stored in memory and logged to disk. In this storage engine, all data must be resident in memory at all times, and all reads are satisfied from memory.</li>
<li><code>SSD</code> Storage Engine is based on SQLite B-Tree</li>
<li><code>Redwood</code> will be a new storage engine based on Versioned B+Tree</li>
</ul>
<h2 id="developer-experience">Developer experience</h2>
<p>FoundationDB‚Äôs keys are ordered, making <code>tuples</code> a particularly useful tool for data modeling. FoundationDB provides a <strong>tuple layer</strong> (available in each language binding) that encodes tuples into keys. This layer lets you store data using a tuple like <code>(state, county)</code> as a key. Later, you can perform reads using a prefix like <code>(state,)</code>. The layer works by preserving the natural ordering of the tuples.</p>
<p>Everything is wrapped into a transaction in FDB.</p>
<p>You can have a nice overview by reading the README of <a href="https://github.com/richardartoul/tsdb-layer/blob/master/README.md">tsdb-layer</a>, an experiment combining Time Series and FoundationDB: Millions of writes/s and 10x compression in under 2,000 lines of Go.</p>
<h2 id="fdb-one-more-things-layers">FDB One more things: Layers</h2>
<h3 id="concept-of-layers">Concept of layers</h3>

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/HLE8chgw6LI" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>

<p>FDB is resolving many distributed problems, but you still need things like <strong>security, multi-tenancy, query optimizations, schema, indexing</strong>.</p>
<hr>
<p><img src="/posts/notes-about-foundationdb/images/extract-layer-1.png" alt="fdb image"></p>
<hr>
<p>Layers are designed to develop features <strong>above FDB.</strong> The record-layer provided by Apple is a good starting point to build things above it, as it provides <strong>structured schema, indexes, and (async) query planner.</strong></p>
<hr>
<p><img src="/posts/notes-about-foundationdb/images/extract-layer-2.png" alt="fdb image"></p>
<hr>
<p>The record-layer provided by Apple is a good starting point to build things above it, as it provides <strong>structured schema, indexes, and (async) query planner.</strong></p>
<hr>
<p><img src="/posts/notes-about-foundationdb/images/extract-layer-3.png" alt="fdb image"></p>
<h3 id="apples-record-layer">Apple&rsquo;s Record Layer</h3>
<p>The paper is located <a href="https://arxiv.org/pdf/1901.04452.pdf">FoundationDB Record Layer:A Multi-Tenant Structured Datastore</a></p>

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/SvoUHHM9IKU" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>

<p>Record Layer was designed to solve CloudKit problem.</p>
<hr>
<p><img src="/posts/notes-about-foundationdb/images/record-extract-1.png" alt="fdb image"></p>
<hr>
<p>Record allow multi-tenancy with schema above FDB</p>
<hr>
<p><img src="/posts/notes-about-foundationdb/images/record-extract-2.png" alt="fdb image"></p>
<p><img src="/posts/notes-about-foundationdb/images/record-extract-3.png" alt="fdb image"></p>
<hr>
<p>Record Layers is providing stateless compute</p>
<hr>
<p><img src="/posts/notes-about-foundationdb/images/record-extract-4.png" alt="fdb image"></p>
<hr>
<p>And streaming queries!</p>
<hr>
<p><img src="/posts/notes-about-foundationdb/images/record-extract-5.png" alt="fdb image"></p>
<hr>
<h2 id="kubernetes-operators">Kubernetes Operators</h2>
<h3 id="overview-of-the-operator">Overview of the operator</h3>

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/A3U8M8pt3Ks" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>

<hr>
<p><img src="/posts/notes-about-foundationdb/images/operator-extract-1.png" alt="fdb image"></p>
<hr>
<p><img src="/posts/notes-about-foundationdb/images/operator-extract-2.png" alt="fdb image"></p>
<hr>
<p>Upgrade is done by <strong>bumping all processes at once</strong> üò±</p>
<hr>
<p><img src="/posts/notes-about-foundationdb/images/operator-extract-3.png" alt="fdb image"></p>
<hr>
<p><img src="/posts/notes-about-foundationdb/images/operator-extract-4.png" alt="fdb image"></p>
<h3 id="combining-chaos-mesh-and-the-operator">Combining chaos-mesh and the operator</h3>
<p>I played a bit with the operator by combining:</p>
<ul>
<li><a href="https://github.com/FoundationDB/fdb-kubernetes-operator">FoundationDB/fdb-kubernetes-operator</a></li>
<li><a href="https://github.com/pingcap/go-ycsb">pingcap/go-ycsb</a></li>
<li><a href="https://github.com/pingcap/chaos-mesh">pingcap/chaos-mesh</a></li>
<li><a href="https://github.com/PierreZ/fdb-prometheus-exporter/">PierreZ/fdb-prometheus-exporter</a></li>
</ul>
<p>The experiment is available <a href="https://github.com/PierreZ/fdb-k8s-chaos/">here</a>.</p>
<h2 id="roadmap">Roadmap</h2>
<p><a href="https://github.com/apple/foundationdb/wiki/FoundationDB-Release-7.0-Planning">FoundationDB Release 7.0 Planning</a></p>
<hr>
<p><strong>Thank you</strong> for reading my post! Feel free to react to this article, I am also available on <a href="https://twitter.com/PierreZ">Twitter</a> if needed.</p>
]]></content>
        </item>
        
        <item>
            <title>Diving into Kafka&#39;s Protocol</title>
            <link>https://pierrezemb.fr/posts/diving-into-kafka-protocol/</link>
            <pubDate>Sun, 08 Dec 2019 15:00:00 +0100</pubDate>
            
            <guid>https://pierrezemb.fr/posts/diving-into-kafka-protocol/</guid>
            <description>Diving Into is a blogpost serie where we are digging a specific part of of the project&amp;rsquo;s basecode. In this episode, we will digg into Kafka&amp;rsquo;s protocol.
 The protocol reference For the last few months, I worked a lot around Kafka&amp;rsquo;s protocols, first by creating a fully async Kafka to Pulsar Proxy in Rust, and now by contributing directly to KoP (Kafka On Pulsar). The full Kafka Protocol documentation is available here, but it does not offer a global view of what is happening for a classic Producer and Consumer exchange.</description>
            <content type="html"><![CDATA[<p><img src="/posts/diving-into-kafka-protocol/img/apache-kafka.png" alt="kafka image"></p>
<p><a href="/tags/diving-into/">Diving Into</a> is a blogpost serie where we are digging a specific part of of the project&rsquo;s basecode. In this episode, we will digg into Kafka&rsquo;s protocol.</p>
<hr>
<h1 id="the-protocol-reference">The protocol reference</h1>
<p>For the last few months, I worked a lot around Kafka&rsquo;s protocols, first by creating a fully async Kafka to Pulsar Proxy in Rust, and now by contributing directly to <a href="https://www.slideshare.net/streamnative/2-kafkaonpulsarjia">KoP (Kafka On Pulsar)</a>. The full Kafka Protocol documentation is available <a href="https://kafka.apache.org/protocol.html">here</a>, but it does not offer a global view of what is happening for a classic Producer and Consumer exchange. Let&rsquo;s dive in!</p>
<h2 id="common-handshake">Common handshake</h2>
<p>After a client established the TCP connection, there is a few common requests and responses that are almost always here.</p>
<p>The common handhake can be divided in three parts:</p>
<ul>
<li>Being able to understand each other. For this, we are using <strong><a href="https://kafka.apache.org/protocol.html#The_Messages_ApiVersions">API_VERSIONS</a></strong> to know which versions of which TCP frames can be uses,</li>
<li>Establish Auth using <strong>SASL</strong> if needed, thanks to <strong><a href="https://kafka.apache.org/protocol.html#The_Messages_SaslHandshake">SASL_HANDSHAKE</a></strong> and <strong><a href="https://kafka.apache.org/protocol.html#The_Messages_SaslAuthenticate">SASL_AUTHENTICATE</a></strong>,</li>
<li>Retrieve the topology of the cluster using <strong><a href="https://kafka.apache.org/protocol.html#The_Messages_Metadata">METADATA</a></strong>.</li>
</ul>
<blockquote>
<p>All exchange are based between a Kafka 2.0 cluster and client.</p>
</blockquote>
<blockquote>
<p>All the following diagrams are generated with <a href="https://mermaidjs.github.io/#/">MermaidJS</a>.</p>
</blockquote>
<div class="mermaid">
    
sequenceDiagram

    Note left of KafkaClient: I'm speaking Kafka <br/> 2.3,but can the <br/> broker understand <br/> me?

    KafkaClient ->>+ Broker0: API_VERSIONS request

    Note right of Broker0: I can handle theses <br/> structures in theses <br/>versions: ...
    Broker0 ->>- KafkaClient: 

    Note left of KafkaClient: Thanks!<br/> I see you can handle <br/> SASL, let's auth! <br/> can you handle <br/> SASL_PLAIN?
    KafkaClient ->>+ Broker0: SASL_HANDSHAKE request

    Note right of Broker0: Yes I can handle <br/> SASL_PLAIN <br/> among others
    Broker0 ->>- KafkaClient: 

    Note left of KafkaClient: Awesome, here's <br/> my credentials!
    KafkaClient ->>+ Broker0: SASL_AUTHENTICATE request

    Note right of Broker0: Checking...
    Note right of Broker0: You are <br/>authenticated!
    Broker0 ->>- KafkaClient: 

    Note left of KafkaClient: Cool! <br/> Can you give <br/> the cluster topology?<br/> I want to <br/> use 'my-topic'
    KafkaClient ->>+ Broker0: METADATA request

    Note right of Broker0: There is one topic <br/> with one partition<br/> called 'my-topic'<br/>The partition's leader <br/> is Broker0
    Broker0 ->>- KafkaClient: 

Note left of KafkaClient: That is you, I don't <br/> need to handshake <br/> again with <br/> another broker


</div>
<h2 id="producing">Producing</h2>
<p>The <strong><a href="https://kafka.apache.org/protocol.html#The_Messages_Produce">PRODUCE</a></strong> API is used to send message sets to the server. For efficiency it allows sending message sets intended for many topic partitions in a single request.</p>
<div class="mermaid">
    
sequenceDiagram

    Note over KafkaClient,Broker0: ...handshaking, see above...

    loop pull msg
        Note left of KafkaClient: I have a batch <br/> containing one <br/> message for the <br/> partition-0 <br/> of 'my-topic'
        KafkaClient ->>+ Broker0: PRODUCE request

        Note right of Broker0: Processing...<br/>
        Note right of Broker0: Done!
        Broker0 ->>- KafkaClient: 
        
        Note left of KafkaClient: Thanks
    end


</div>
<h2 id="consuming">Consuming</h2>
<p>Consuming is more complicated than producing. You can learn more in <a href="https://www.youtube.com/watch?v=maJulQ4ABNY">The Magical Group Coordination Protocol of Apache Kafka</a> By Gwen Shapira, Principal Data Architect @ Confluent and also in the <a href="https://cwiki.apache.org/confluence/display/KAFKA/Kafka+Client-side+Assignment+Proposal">Kafka Client-side Assignment Proposal</a>.</p>
<p>Consuming can be divided in three parts:</p>
<ul>
<li>coordinating the consumers to assign them partitions, using:
<ul>
<li><strong><a href="https://kafka.apache.org/protocol.html#The_Messages_FindCoordinator">FIND_COORDINATOR</a></strong>,</li>
<li><strong><a href="https://kafka.apache.org/protocol.html#The_Messages_JoinGroup">JOIN_GROUP</a></strong>,</li>
<li><strong><a href="https://kafka.apache.org/protocol.html#The_Messages_SyncGroup">SYNC_GROUP</a></strong>,</li>
</ul>
</li>
<li>then fetch messages using:
<ul>
<li><strong><a href="https://kafka.apache.org/protocol.html#The_Messages_OffsetFetch">OFFSET_FETCH</a></strong>,</li>
<li><strong><a href="https://kafka.apache.org/protocol.html#The_Messages_ListOffsets">LIST_OFFSETS</a></strong>,</li>
<li><strong><a href="https://kafka.apache.org/protocol.html#The_Messages_Fetch">FETCH</a></strong>,</li>
<li><strong><a href="https://kafka.apache.org/protocol.html#The_Messages_OffsetCommit">OFFSET_COMMIT</a></strong>,</li>
</ul>
</li>
<li>Send lifeproof to the coordinator using <strong><a href="https://kafka.apache.org/protocol.html#The_Messages_Heartbeat">HEARTBEAT</a></strong>.</li>
</ul>
<p>For the sake of the explanation, we have now another Broker1 which is holding the coordinator for topic &lsquo;my-topic&rsquo;. In real-life, it would be the same.</p>
<div class="mermaid">
    
sequenceDiagram

    Note over KafkaClient,Broker0: ...handshaking, see above...

    Note left of KafkaClient: Who is the <br/> coordinator for<br/> 'my-topic'?
    KafkaClient ->>+ Broker0: FIND_COORDINATOR request

    Note right of Broker0: It is Broker1!
    Broker0 ->>- KafkaClient: 

    Note left of KafkaClient: OK, let's connect<br/> to Broker1
    Note over KafkaClient,Broker1: ...handshaking, see above...

    Note left of KafkaClient: Hi, I want to join a <br/> consumption group <br/>for 'my-topic'
    KafkaClient ->>+ Broker1: JOIN_GROUP request

    Note right of Broker1: Welcome! I will be <br/> waiting a bit for any <br/>of your friends.
    Note right of Broker1: You are now leader. <br/>Your group contains <br/> only one member.<br/> You now  need to <br/> assign partitions to <br/> them. 
    Broker1 ->>- KafkaClient: 

    Note left of KafkaClient: Computing <br/>the assigment...
    Note left of KafkaClient: Done! I will be <br/> in charge of handling <br/> partition-0 of <br/>'my-topic'
    KafkaClient ->>+ Broker1: SYNC_GROUP request

    Note right of Broker1: Thanks, I will <br/>broadcast the <br/>assigmnents to <br/>everyone
    Broker1 ->>- KafkaClient: 

    Note left of KafkaClient: Can I get the <br/> committed offsets <br/> for partition-0<br/>for my consumer<br/>group?
    KafkaClient ->>+ Broker1: OFFSET_FETCH request

    Note right of Broker1: Found no <br/>committed offset<br/> for partition-0
    Broker1 ->>- KafkaClient: 

    Note left of KafkaClient: Thanks, I will now <br/>connect to Broker0

    Note over KafkaClient,Broker0: ...handshaking again...

    opt if new consumer-group
        Note left of KafkaClient: Can you give me<br/> the earliest position<br/> for partition-0?
        KafkaClient ->>+ Broker0: LIST_OFFSETS request
        
        Note right of Broker0: Here's the earliest <br/> position: ...
        Broker0 ->>- KafkaClient: 
    end 
    loop pull msg

        opt Consume
            Note left of KafkaClient: Can you give me<br/> some messages <br/> starting  at offset X?
            KafkaClient ->>+ Broker0: FETCH request

            Note right of Broker0: Here some records...
            Broker0 ->>- KafkaClient: 

            Note left of KafkaClient: Processing...
            Note left of KafkaClient: Can you commit <br/>offset X?
            KafkaClient ->>+ Broker1: OFFSET_COMMIT request

            Note right of Broker1: Committing...
            Note right of Broker1: Done!
            Broker1 ->>- KafkaClient: 
        end

        Note left of KafkaClient: I need to send <br/> some lifeness proof <br/> to the coordinator           
        opt Healthcheck
            Note left of KafkaClient: I am still alive!  
            KafkaClient ->>+ Broker1: HEARTBEAT request
            Note right of Broker1: I hear you
            Broker1 ->>- KafkaClient: 
        end
    end 

</div>
<hr>
<p><strong>Thank you</strong> for reading my post! Feel free to react to this article, I am also available on <a href="https://twitter.com/PierreZ">Twitter</a> if needed.</p>
]]></content>
        </item>
        
        <item>
            <title>Diving into Hbase&#39;s MemStore</title>
            <link>https://pierrezemb.fr/posts/diving-into-hbase-memstore/</link>
            <pubDate>Sun, 17 Nov 2019 10:24:27 +0100</pubDate>
            
            <guid>https://pierrezemb.fr/posts/diving-into-hbase-memstore/</guid>
            <description>Diving Into is a blogpost serie where we are digging a specific part of of the project&amp;rsquo;s basecode. In this episode, we will digg into the implementation behind Hbase&amp;rsquo;s MemStore.
 tl;dr: Hbase is using the ConcurrentSkipListMap.
What is the MemStore?  The memtable from the official BigTable paper is the equivalent of the MemStore in Hbase.
 As rows are sorted lexicographically in Hbase, when data comes in, you need to have some kind of a in-memory buffer to order those keys.</description>
            <content type="html"><![CDATA[<p><img src="/posts/hbase-data-model/images/hbase.jpg" alt="hbase image"></p>
<p><a href="/tags/diving-into/">Diving Into</a> is a blogpost serie where we are digging a specific part of of the project&rsquo;s basecode. In this episode, we will digg into the implementation behind Hbase&rsquo;s MemStore.</p>
<hr>
<p><code>tl;dr:</code> Hbase is using the <a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/ConcurrentSkipListMap.html">ConcurrentSkipListMap</a>.</p>
<h1 id="what-is-the-memstore">What is the MemStore?</h1>
<blockquote>
<p>The <code>memtable</code> from the official <a href="https://research.google.com/archive/bigtable-osdi06.pdf">BigTable paper</a> is the equivalent of the <code>MemStore</code> in Hbase.</p>
</blockquote>
<p>As rows are <strong>sorted lexicographically</strong> in Hbase, when data comes in, you need to have some kind of a <strong>in-memory buffer</strong> to order those keys. This is where the <code>MemStore</code> comes in. It absorbs the recent write (or put in Hbase semantics) operations. All the rest are immutable files called <code>HFile</code> stored in HDFS. There is one <code>MemStore</code> per <code>column family</code>.</p>
<p>Let&rsquo;s dig into how the MemStore internally works in Hbase 1.X.</p>
<h1 id="hbase-1">Hbase 1</h1>
<p>All extract of code for this section are taken from <a href="https://github.com/apache/hbase/tree/rel/1.4.9">rel/1.4.9</a> tag.</p>
<h2 id="in-memory-storage">in-memory storage</h2>
<p>The <a href="https://github.com/apache/hbase/blob/rel/1.4.9/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java#L35">MemStore interface</a> is giving us insight on how it is working internally.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-java" data-lang="java">  <span style="color:#75715e">/**
</span><span style="color:#75715e">   * Write an update
</span><span style="color:#75715e">   * @param cell
</span><span style="color:#75715e">   * @return approximate size of the passed cell.
</span><span style="color:#75715e">   */</span>
<span style="color:#66d9ef">long</span> <span style="color:#a6e22e">add</span><span style="color:#f92672">(</span><span style="color:#66d9ef">final</span> Cell cell<span style="color:#f92672">);</span>
</code></pre></div><p>&ndash; <a href="https://github.com/apache/hbase/blob/rel/1.4.9/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java#L68-L73">add function on the MemStore</a></p>
<p>The implementation is hold by <a href="https://github.com/apache/hbase/blob/rel/1.4.9/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/DefaultMemStore.java">DefaultMemStore</a>. <code>add</code> is wrapped by several functions, but in the end, we are arriving here:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-java" data-lang="java">  <span style="color:#66d9ef">private</span> <span style="color:#66d9ef">boolean</span> <span style="color:#a6e22e">addToCellSet</span><span style="color:#f92672">(</span>Cell e<span style="color:#f92672">)</span> <span style="color:#f92672">{</span>
    <span style="color:#66d9ef">boolean</span> b <span style="color:#f92672">=</span> <span style="color:#66d9ef">this</span><span style="color:#f92672">.</span><span style="color:#a6e22e">activeSection</span><span style="color:#f92672">.</span><span style="color:#a6e22e">getCellSkipListSet</span><span style="color:#f92672">().</span><span style="color:#a6e22e">add</span><span style="color:#f92672">(</span>e<span style="color:#f92672">);</span>
</code></pre></div><p>&ndash; <a href="https://github.com/apache/hbase/blob/rel/1.4.9/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/DefaultMemStore.java#L202-L213">addToCellSet on the DefaultMemStore</a></p>
<p><a href="https://github.com/apache/hbase/blob/rel/1.4.9/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CellSkipListSet.java#L33-L48">CellSkipListSet class</a> is built on top of <a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/ConcurrentSkipListMap.html">ConcurrentSkipListMap</a>, which provide nice features:</p>
<ul>
<li>concurrency</li>
<li>sorted elements</li>
</ul>
<h2 id="flush-on-hdfs">Flush on HDFS</h2>
<p>As we seen above, the <code>MemStore</code> is supporting all the puts. When asked to flush, the current memstore is <strong>moved to snapshot and is cleared</strong>. Flushed file are called (<a href="https://github.com/apache/hbase/blob/rel/2.1.2/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java">HFiles</a>) and they are similar to <code>SSTables</code> introduced by the official <a href="https://research.google.com/archive/bigtable-osdi06.pdf">BigTable paper</a>. HFiles are flushed on the Hadoop Distributed File System called <code>HDFS</code>.</p>
<blockquote>
<p>If you want deeper insight about SSTables, I recommend reading <a href="https://github.com/facebook/rocksdb/wiki/Rocksdb-BlockBasedTable-Format">Table Format from the awesome RocksDB wiki</a></p>
</blockquote>
<h2 id="compaction">Compaction</h2>
<p>Compaction are only run on HFiles. It means that <strong>if hot data is continuously updated, we are overusing memory due to duplicate entries per row per MemStore</strong>. Accordion tends to solve this problem through <em>in-memory compactions</em>. Let&rsquo;s have a look to Hbase 2.X!</p>
<h1 id="hbase-2">Hbase 2</h1>
<h2 id="storing-data">storing data</h2>
<p><strong>All extract of code starting from here are taken from <a href="https://github.com/apache/hbase/tree/rel/2.1.2">rel/2.1.2</a> tag.</strong></p>
<p>Does <code>MemStore</code> interface changed?</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-java" data-lang="java">  <span style="color:#75715e">/**
</span><span style="color:#75715e">   * Write an update
</span><span style="color:#75715e">   * @param cell
</span><span style="color:#75715e">   * @param memstoreSizing The delta in memstore size will be passed back via this.
</span><span style="color:#75715e">   *        This will include both data size and heap overhead delta.
</span><span style="color:#75715e">   */</span>
  <span style="color:#66d9ef">void</span> <span style="color:#a6e22e">add</span><span style="color:#f92672">(</span><span style="color:#66d9ef">final</span> Cell cell<span style="color:#f92672">,</span> MemStoreSizing memstoreSizing<span style="color:#f92672">);</span>
</code></pre></div><p>&ndash; <a href="https://github.com/apache/hbase/blob/rel/2.1.2/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java#L67-L73">add function in MemStore interface</a></p>
<p>The signature changed a bit, to include passing a object instead of returning a long. Moving on.</p>
<p>The new structure implementing MemStore is called <a href="https://github.com/apache/hbase/blob/rel/2.1.2/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/AbstractMemStore.java#L42">AbstractMemStore</a>. Again, we have some layers, where AbstractMemStore is writing to a <code>MutableSegment</code>, which itsef is wrapping <code>Segment</code>. If you dig far enough, you will find that data are stored into the <a href="https://github.com/apache/hbase/blob/rel/2.1.2/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CellSet.java#L35-L51">CellSet class</a> which is also things built on top of <strong>ConcurrentSkipListMap</strong>!</p>
<h2 id="in-memory-compactions">in-memory Compactions</h2>
<p>Hbase 2.0 introduces a big change to the original memstore called Accordion which is a codename for in-memory compactions. An awesome blogpost is available here: <a href="https://blogs.apache.org/hbase/entry/accordion-hbase-breathes-with-in">Accordion: HBase Breathes with In-Memory Compaction</a> and the <a href="https://issues.apache.org/jira/secure/attachment/12709471/HBaseIn-MemoryMemstoreCompactionDesignDocument.pdf">document design</a> is also available.</p>
<hr>
<p><strong>Thank you</strong> for reading my post! feel free to react to this article, I&rsquo;m also available on <a href="https://twitter.com/PierreZ">Twitter</a> if needed.</p>
]]></content>
        </item>
        
        <item>
            <title>What can be gleaned about GFS successor codenamed Colossus?</title>
            <link>https://pierrezemb.fr/posts/colossus-google/</link>
            <pubDate>Sun, 04 Aug 2019 15:07:11 +0200</pubDate>
            
            <guid>https://pierrezemb.fr/posts/colossus-google/</guid>
            <description>In the last few months, there has been numerous blogposts about the end of the Hadoop-era. It is true that:
 Health of Hadoop-based companies are publicly bad Hadoop has a bad publicity with headlines like &amp;lsquo;What does the death of Hadoop mean for big data?&#39;  Hadoop, as a distributed-system, is hard to operate, but can be essential for some type of workload. As Hadoop is based on GFS, we can wonder how GFS evolved inside Google.</description>
            <content type="html"><![CDATA[
    <img src="/posts/colossus-google/hadoop-logo.jpg"  alt="Hello Friend"  class="center"  style="border-radius: 8px;"  />


<p>In the last few months, there has been numerous blogposts about the end of the Hadoop-era. It is true that:</p>
<ul>
<li><a href="https://www.theregister.co.uk/2019/06/06/cloudera_ceo_quits_customers_delay_purchase_orders_due_to_roadmap_uncertainty_after_hortonworks_merger/">Health of Hadoop-based companies are publicly bad</a></li>
<li>Hadoop has a bad publicity with headlines like <a href="https://techwireasia.com/2019/07/what-does-the-death-of-hadoop-mean-for-big-data/">&lsquo;What does the death of Hadoop mean for big data?'</a></li>
</ul>
<p>Hadoop, as a distributed-system, <strong>is hard to operate, but can be essential for some type of workload</strong>. As Hadoop is based on GFS, we can wonder how GFS evolved inside Google.</p>
<h2 id="hadoops-story">Hadoop&rsquo;s story</h2>
<p>Hadoop is based on a Google&rsquo;s paper called <a href="https://static.googleusercontent.com/media/research.google.com/en//archive/gfs-sosp2003.pdf">The Google File System</a> published in 2003. There are some key-elements on this paper:</p>
<ul>
<li>It was designed to be deployed with <a href="https://ai.google/research/pubs/pub43438">Borg</a>,</li>
<li>to &ldquo;<a href="https://queue.acm.org/detail.cfm?id=1594206">simplify the overall design problem</a>&rdquo;, they:
<ul>
<li>implemented a single master architecture</li>
<li>dropped the idea of a full POSIX-compliant file system</li>
</ul>
</li>
<li>Metadatas are stored in RAM in the master,</li>
<li>Datas are stored within chunkservers,</li>
<li>There is no YARN or Map/Reduce or any kind of compute capabilities.</li>
</ul>
<h2 id="is-hadoop-still-revelant">Is Hadoop still revelant?</h2>
<p>Google with GFS and the rest of the world with Hadoop hit some issues:</p>
<ul>
<li>One (Metadata) machine is not large enough for large FS,</li>
<li>Single bottleneck for metadata operations,</li>
<li>Not appropriate for latency sensitive applications,</li>
<li>Fault tolerant not HA,</li>
<li>Unpredictable performance,</li>
<li>Replication&rsquo;s cost,</li>
<li>HDFS Write-path pipelining,</li>
<li>fixed-size of blocks,</li>
<li>cost of operations,</li>
<li>&hellip;</li>
</ul>
<p>Despite all the issues, Hadoop is still relevant for some usecases, such as Map/Reduce, or if you need Hbase as a main datastore. There is stories available online about the scalability of Hadoop:</p>
<ul>
<li><a href="https://blog.twitter.com/engineering/en_us/topics/infrastructure/2017/the-infrastructure-behind-twitter-scale.html">Twitter has multiple clusters storing over 500 PB (2017)</a></li>
<li>whereas Google prefered to <a href="https://cloud.google.com/files/storage_architecture_and_challenges.pdf">&ldquo;Scaled to approximately 50M files, 10P&rdquo; to avoid &ldquo;added management overhead&rdquo; brought by the scaling.</a></li>
</ul>
<p>Nowadays, Hadoop is mostly used for Business Intelligence or to create a datalake, but at first, GFS was designed to provide a distributed file-system on top of commodity servers.</p>
<p>Google&rsquo;s developers were/are deploying applications into &ldquo;containers&rdquo;, meaning that <strong>any process could be spawned somewhere into the cloud</strong>. Developers are used to work with the file-system abstraction, which provide a layer of durability and security. To mimic that process, they developed GFS, so that <strong>processes don&rsquo;t need to worry about replication</strong> (like Bigtable/HBase).</p>
<p>This is a promise that, I think, was forgotten. In a world where Kubernetes <em>seems</em> to be the standard, <strong>the need of a global distributed file-system is now higher than before</strong>. By providing a &ldquo;file-system&rdquo; abstraction for applications deployed in Kubernetes, we may be solving many problems Kubernetes-adopters are hitting, such as:</p>
<ul>
<li>How can I retrieve that particular file for my applications deployed on the other side of the Kubernetes cluster?</li>
<li>Should I be moving that persistent volume over my slow network?</li>
<li>What is happening when <a href="https://github.com/dgraph-io/dgraph/issues/2698">Kubernetes killed an alpha pod in the middle of retrieving snapshot</a>?</li>
</ul>
<h2 id="well-lets-put-hadoop-in-kubernetes">Well, let&rsquo;s put Hadoop in Kubernetes!</h2>
<p>Putting a distributed systems inside Kubernetes is currently a unpleasant experience because of the current tooling:</p>
<ul>
<li>Helm is not helping me expressing my needs as a distributed-system operator. Even worse, the official <a href="https://github.com/helm/charts/tree/master/stable/hadoop">Helm chart for Hadoop is limited to YARN and Map/Reduce and &ldquo;Data should be read from cloud based datastores such as Google Cloud Storage, S3 or Swift.&quot;</a></li>
<li>Kubernetes Operators has no access to key-metrics, so they cannot watch over your applications correctly. It is only providing a &ldquo;day-zero to day-two&rdquo; good experience,</li>
<li>Google seems to <a href="https://news.ycombinator.com/item?id=16971959">not be using the Operators design internally</a>.</li>
<li><a href="https://www.ibm.com/cloud/blog/new-builders/database-deep-dives-couchdb">CouchDB developers</a> are saying that:
<ul>
<li>&ldquo;For certain workloads, the technology isn‚Äôt quite there yet&rdquo;</li>
<li>&ldquo;In certain scenarios that are getting smaller and smaller, both Kubernetes and Docker get in the way of that. At that point, CouchDB gets slow, or you get timeout errors, that you can‚Äôt explain.&rdquo;</li>
</ul>
</li>
</ul>
<h2 id="how-gfs-evolved-within-google">How GFS evolved within Google</h2>
<p>As GFS&rsquo;s paper was published in 2003, we can ask ourselves if GFS has evolved. And it did! The sad part is that there is only a few informations about this project codenamed <code>Colossus</code>. There is no papers, and not a lot informations available, here&rsquo;s what can be found online:</p>
<ul>
<li>
<p>From <a href="https://cloud.google.com/files/storage_architecture_and_challenges.pdf">Storage Architecture and Challenges(2010)</a>:</p>
<ul>
<li>They moved from full-replication to <a href="https://en.wikipedia.org/wiki/Reed%E2%80%93Solomon_error_correction">Reed-Salomon</a>. This feature is acually in <a href="https://hadoop.apache.org/docs/r3.0.0/hadoop-project-dist/hadoop-hdfs/HDFSErasureCoding.html">Hadoop 3</a>,</li>
<li>replication is handled by the client, instead of the pipelining,</li>
<li>the metadata layer is automatically sharded. We can find more informations about that in the next ressource!</li>
</ul>
</li>
<li>
<p>From <a href="http://www.pdsw.org/pdsw-discs17/slides/PDSW-DISCS-Google-Keynote.pdf">Cluster-Level Storage @ Google(2017)</a>:</p>
<ul>
<li>GFS master replaced by Colossus</li>
<li>GFS chunkserver replaced by D</li>
<li>Colossus rebalances old, cold data</li>
<li>distributes newly written data evenly across disks</li>
<li>Metadatas are stored into BigTable. each Bigtable row corresponds to a single file.</li>
</ul>
</li>
</ul>
<p>The &ldquo;all in RAM&rdquo; GFS master design was a severe single-point-of-failure, so getting rid of it was a priority. They didn&rsquo;t had a lof of options for a scalable and rock-solid datastore <strong>beside BigTable</strong>. When you think about it, a key/value datastore is a great replacement for a distributed file-system master:</p>
<ul>
<li>automatic sharding of regions,</li>
<li>scan capabilities for files in the same &ldquo;directory&rdquo;,</li>
<li>lexical ordering,</li>
<li>&hellip;</li>
</ul>
<p>The funny part is that they now need a Colossus for Colossus. The only things saving them is that storing the metametametadata (the metadata of the metadata of the metadata) can be hold in Chubby.</p>
<ul>
<li>
<p>From <a href="https://queue.acm.org/detail.cfm?id=1594206">GFS: Evolution on Fast-forward(2009)</a></p>
<ul>
<li>they moved to chunks of 1MB of files, as the limitations of the master disappeared. This is also allowing Colossus to support latency sensitive applications,</li>
</ul>
</li>
<li>
<p>From <a href="https://github.com/cockroachdb/cockroach/issues/243#issuecomment-91575792">a Github comment on Colossus</a>:</p>
<ul>
<li>File reconstruction from Reed-Salomnon was performed on both client-side and server-side</li>
<li>on-the-fly recovery of data is greatly enhanced by this data layout(Reed Salomon)</li>
</ul>
</li>
<li>
<p>From a <a href="https://news.ycombinator.com/item?id=20135927">Hacker News comment</a>:</p>
<ul>
<li>Colossus and D are two separate things.</li>
</ul>
</li>
</ul>
<p>What is that &ldquo;D&rdquo;?</p>
<ul>
<li>
<p>From <a href="https://landing.google.com/sre/sre-book/chapters/production-environment/"> The Production Environment at Google, from the Viewpoint of an SRE</a>:</p>
<ul>
<li>D stands for <em>Disk</em>,</li>
<li>D is a fileserver running on almost all machines in a cluster.</li>
</ul>
</li>
<li>
<p>From <a href="https://medium.com/@jerub/the-production-environment-at-google-8a1aaece3767">The Production Environment at Google</a>:</p>
<ul>
<li>D is more of a block server than a file server</li>
<li>It provides nothing apart from checksums.</li>
</ul>
</li>
</ul>
<h2 id="is-there-an-open-source-effort-to-create-a-colossus-like-dfs">Is there an open-source effort to create a Colossus-like DFS?</h2>
<p>I did not found any point towards a open-source version of Colossus, beside some work made for <a href="https://github.com/baidu/bfs">The Baidu File System</a> in which the Nameserver is implemented as a raft group.</p>
<p>There is <a href="https://www.slideshare.net/HadoopSummit/scaling-hdfs-to-manage-billions-of-files-with-distributed-storage-schemes">some work to add colossus&rsquo;s features in Hadoop</a> but based on the bad publicity Hadoop has now, I don&rsquo;t think there will be a lot of money to power those efforts.</p>
<p>I do think that rewriting an distributed file-system based on Colossus would be a huge benefit for the community:</p>
<ul>
<li>Reimplement D may be easy, my current question is <strong>how far can we use modern FS such as OpenZFS</strong> to facilitate the work? FS capabilities such as <a href="https://github.com/zfsonlinux/zfs/wiki/Checksums">OpenZFS checksums</a> seems pretty interesting.</li>
<li>To resolve the distributed master issue, we could use <a href="https://tikv.org/">Tikv</a> as a building block to provide an &ldquo;BigTable experience&rdquo; without the need of a distributed file-system underneath.</li>
</ul>
<p>But remember:</p>
<blockquote>
<p>Like crypto, Do not roll your own DFS!</p>
</blockquote>
<hr>
<p><strong>Thank you</strong> for reading my post! Feel free to react to this article, I am also available on <a href="https://twitter.com/PierreZ">Twitter</a> if needed.</p>
]]></content>
        </item>
        
        <item>
            <title>Playing with TTL in HBase</title>
            <link>https://pierrezemb.fr/posts/ttl-hbase/</link>
            <pubDate>Mon, 27 May 2019 22:07:11 +0200</pubDate>
            
            <guid>https://pierrezemb.fr/posts/ttl-hbase/</guid>
            <description>Among all features provided by HBase, there is one that is pretty handy to deal with your data&amp;rsquo;s lifecyle: the fact that every cell version can have Time to Live or TTL. Let&amp;rsquo;s dive into the feature!
Time To Live (TTL) Let&amp;rsquo;s read the doc first!
 ColumnFamilies can set a TTL length in seconds, and HBase will automatically delete rows once the expiration time is reached.
 HBase Book: Time To Live (TTL)</description>
            <content type="html"><![CDATA[<header class="row text-center header">
   <img src="/posts/hbase-data-model/images/hbase.jpg" alt="HBase Image" class="text-center"> 
</header>
<p>Among all features provided by HBase, there is one that is pretty handy to deal with your data&rsquo;s lifecyle: the fact that every cell version can have <strong>Time to Live</strong> or TTL. Let&rsquo;s dive into the feature!</p>
<h1 id="time-to-live-ttl">Time To Live (TTL)</h1>
<p>Let&rsquo;s read the doc first!</p>
<blockquote>
<p>ColumnFamilies can set a TTL length in seconds, and <strong>HBase will automatically delete rows once the expiration time is reached</strong>.</p>
</blockquote>
<p><a href="https://hbase.apache.org/book.html#ttl">HBase Book: Time To Live (TTL)</a></p>
<p>Let&rsquo;s play with it! You can easily start an standalone HBase by following <a href="https://hbase.apache.org/book.html#quickstart">the HBase Book</a>. Once your standalone cluster is started, we can get started:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">./bin/hbase shell

hbase<span style="color:#f92672">(</span>main<span style="color:#f92672">)</span>:001:0&gt; create <span style="color:#e6db74">&#39;test_table&#39;</span>, <span style="color:#f92672">{</span><span style="color:#e6db74">&#39;NAME&#39;</span> <span style="color:#f92672">=</span>&gt; <span style="color:#e6db74">&#39;cf1&#39;</span>,<span style="color:#e6db74">&#39;TTL&#39;</span> <span style="color:#f92672">=</span>&gt; 30<span style="color:#f92672">}</span> <span style="color:#75715e"># 30 sec</span>
</code></pre></div><p>Now that our test_table is created, we can <code>put</code> some data on it:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">hbase<span style="color:#f92672">(</span>main<span style="color:#f92672">)</span>:002:0&gt; put <span style="color:#e6db74">&#39;test_table&#39;</span>,<span style="color:#e6db74">&#39;row123&#39;</span>,<span style="color:#e6db74">&#39;cf1:desc&#39;</span>, <span style="color:#e6db74">&#39;TTL Demo&#39;</span>
</code></pre></div><p>And you can <code>get</code> it with:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">hbase<span style="color:#f92672">(</span>main<span style="color:#f92672">)</span>:003:0&gt; get <span style="color:#e6db74">&#39;test_table&#39;</span>,<span style="color:#e6db74">&#39;row123&#39;</span>,<span style="color:#e6db74">&#39;cf1:desc&#39;</span>
COLUMN                             CELL
 cf1:desc                          timestamp<span style="color:#f92672">=</span>1558366581134, value<span style="color:#f92672">=</span>TTL Demo
<span style="color:#ae81ff">1</span> row<span style="color:#f92672">(</span>s<span style="color:#f92672">)</span> in 0.0080 seconds
</code></pre></div><p>Here&rsquo;s our row! But if you wait a bit, it will <strong>disappear</strong> thanks to the TTL:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">hbase<span style="color:#f92672">(</span>main<span style="color:#f92672">)</span>:004:0&gt; get <span style="color:#e6db74">&#39;test_table&#39;</span>,<span style="color:#e6db74">&#39;row123&#39;</span>,<span style="color:#e6db74">&#39;cf1:desc&#39;</span>
COLUMN                             CELL
<span style="color:#ae81ff">0</span> row<span style="color:#f92672">(</span>s<span style="color:#f92672">)</span> in 0.0220 seconds
</code></pre></div><p>It has been filtered from the result, but the data is still here.  You can trigger a <strong>raw</strong> scan to check:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">hbase<span style="color:#f92672">(</span>main<span style="color:#f92672">)</span>:002:0&gt; scan <span style="color:#e6db74">&#39;test_table&#39;</span>, <span style="color:#f92672">{</span>RAW <span style="color:#f92672">=</span>&gt; true<span style="color:#f92672">}</span>
ROW                                COLUMN+CELL
 row123                            column<span style="color:#f92672">=</span>cf1:desc, timestamp<span style="color:#f92672">=</span>1558366581134, value<span style="color:#f92672">=</span>TTL Demo
<span style="color:#ae81ff">1</span> row<span style="color:#f92672">(</span>s<span style="color:#f92672">)</span> in 0.3280 seconds
</code></pre></div><p>It will be removed only when a <strong>major-compaction</strong> will occur. As we are playing, we can:</p>
<ul>
<li>force the memstore to be <strong>flushed as HFiles</strong></li>
<li>force the <strong>compaction</strong>:</li>
</ul>
<div class="bs-callout bs-callout-info">
You may have heard about <b><a target="_blank" href="https://blogs.apache.org/hbase/entry/accordion-hbase-breathes-with-in">Accordion</a></b>, the new feature in HBase 2. If you are playing with HBase 2, you can enable it by following <a target="_blank" href="https://hbase.apache.org/book.html#inmemory_compaction">this link</a> and run <b>compactions directly in the MemStores.</b>
</div>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">hbase<span style="color:#f92672">(</span>main<span style="color:#f92672">)</span>:014:0&gt; flush <span style="color:#e6db74">&#39;test_table&#39;</span>
Took 0.4456 seconds    
hbase<span style="color:#f92672">(</span>main<span style="color:#f92672">)</span>:015:0&gt; compact <span style="color:#e6db74">&#39;test_table&#39;</span>
Took 0.0468 seconds
<span style="color:#75715e"># wait a bit</span>
hbase<span style="color:#f92672">(</span>main<span style="color:#f92672">)</span>:016:0&gt; scan <span style="color:#e6db74">&#39;test_table&#39;</span>, <span style="color:#f92672">{</span>RAW <span style="color:#f92672">=</span>&gt; true<span style="color:#f92672">}</span>
ROW                            COLUMN+CELL
<span style="color:#ae81ff">0</span> row<span style="color:#f92672">(</span>s<span style="color:#f92672">)</span>
Took 0.0060 seconds
</code></pre></div><h1 id="how-does-it-works">How does it works?</h1>
<p>As always, the truth is held by the documentation:</p>
<blockquote>
<p>A {row, column, version} tuple exactly specifies a cell in HBase. It‚Äôs possible to have an unbounded number of cells where the row and column are the same but the cell address differs only in its version dimension.</p>
</blockquote>
<blockquote>
<p>While rows and column keys are expressed as bytes, <strong>the version is specified using a long integer</strong>. Typically <strong>this long contains time instances</strong> such as those returned by java.util.Date.getTime() or <strong>System.currentTimeMillis()</strong>,</p>
</blockquote>
<p><a href="https://hbase.apache.org/book.html#versions">HBase Book: Versions</a></p>
<p>You may have seen it during our scan earlier, there is a <strong>timestamp associated</strong> with the version of the cell:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">hbase<span style="color:#f92672">(</span>main<span style="color:#f92672">)</span>:003:0&gt; get <span style="color:#e6db74">&#39;test_table&#39;</span>,<span style="color:#e6db74">&#39;row123&#39;</span>,<span style="color:#e6db74">&#39;cf1:desc&#39;</span>
COLUMN                             CELL
 cf1:desc                          timestamp<span style="color:#f92672">=</span>1558366581134, value<span style="color:#f92672">=</span>TTL Demo
 <span style="color:#75715e">#                           here  ^^^^^^^^^^^^^^^^^^^^^^^ </span>
</code></pre></div><p>Hbase used the <code>System.currentTimeMillis()</code> at ingest time to add it. During scanner and compaction, as time went by, <strong>there was more than TTL seconds between the cell version and now, so the row was discarded</strong>.</p>
<p>Now the real question is: <strong>can you set it by yourself and be real Time-Lord</strong> (of HBase)?</p>
<p>The reponse is <em>yes!</em> There is also a bit of a warning a bit <a href="https://hbase.apache.org/book.html#_explicit_version_example">below:</a></p>
<blockquote>
<p><em>Caution:</em> the version timestamp is used internally by HBase for things like <strong>time-to-live calculations</strong>. It‚Äôs usually best to avoid setting this timestamp yourself. Prefer using a separate timestamp attribute of the row, or have the timestamp as a part of the row key, or both.</p>
</blockquote>
<p>Let&rsquo;s try it:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">date +%s -d <span style="color:#e6db74">&#34;+2 min&#34;</span>
<span style="color:#ae81ff">1558472441</span>  <span style="color:#75715e"># don&#39;t forget to add 3 zeroes as the time need to be in millisecond!</span>

./bin/hbase shell
hbase<span style="color:#f92672">(</span>main<span style="color:#f92672">)</span>:001:0&gt; put <span style="color:#e6db74">&#39;test_table&#39;</span>,<span style="color:#e6db74">&#39;row1234&#39;</span>,<span style="color:#e6db74">&#39;cf1:desc&#39;</span>, <span style="color:#e6db74">&#39;timestamp Demo&#39;</span>, <span style="color:#ae81ff">1558472441000</span>  
hbase<span style="color:#f92672">(</span>main<span style="color:#f92672">)</span>:044:0&gt; scan <span style="color:#e6db74">&#39;test_table&#39;</span>
ROW                            COLUMN+CELL
 row1234                       column<span style="color:#f92672">=</span>cf1:desc, timestamp<span style="color:#f92672">=</span>1558473315, value<span style="color:#f92672">=</span>timestamp Demo
<span style="color:#ae81ff">1</span> row<span style="color:#f92672">(</span>s<span style="color:#f92672">)</span>
Took 0.0031 seconds
</code></pre></div><p>Notice that we are using a timestamp at the end of the <code>put</code> method? This will <strong>add the desired timestamp to the version</strong>. Which means that <strong>your application can control when your version will be removed, even with a TTL on your column-qualifier.</strong> You just need to compute a timestamp like this:</p>
<blockquote>
<p><code>ts = now - ttlCF + desiredTTL</code>.</p>
</blockquote>
<hr>
<p><strong>Thank you</strong> for reading my post! Feel free to react to this article, I am also available on <a href="https://twitter.com/PierreZ">Twitter</a> if needed.</p>
]]></content>
        </item>
        
        <item>
            <title>Handling OVH&#39;s alerts with Apache Flink</title>
            <link>https://pierrezemb.fr/posts/ovh-alerts-flink/</link>
            <pubDate>Sun, 03 Feb 2019 15:37:27 +0100</pubDate>
            
            <guid>https://pierrezemb.fr/posts/ovh-alerts-flink/</guid>
            <description>This is a repost from OVH&amp;rsquo;s official blogpost.. Thanks Horacio Gonzalez for the awesome drawings!
Handling OVH&amp;rsquo;s alerts with Apache Flink OVH relies extensively on metrics to effectively monitor its entire stack. Whether they are low-level or business centric, they allow teams to gain insight into how our services are operating on a daily basis. The need to store millions of datapoints per second has produced the need to create a dedicated team to build a operate a product to handle that load: **Metrics Data Platform.</description>
            <content type="html"><![CDATA[<p>This is a repost from <a href="https://www.ovh.com/fr/blog/handling-ovhs-alerts-with-apache-flink/" title="Permalink to Handling OVH's alerts with Apache Flink">OVH&rsquo;s official blogpost.</a>. Thanks <a href="https://twitter.com/LostInBrittany/">Horacio Gonzalez</a> for the awesome drawings!</p>
<h1 id="handling-ovhs-alerts-with-apache-flink">Handling OVH&rsquo;s alerts with Apache Flink</h1>
<p><img src="https://www.ovh.com/fr/blog/wp-content/uploads/2019/01/001-1.png?x70472" alt="OVH & Apache Flink"></p>
<p>OVH relies extensively on <strong>metrics</strong> to effectively monitor its entire stack. Whether they are <strong>low-level</strong> or <strong>business</strong> centric, they allow teams to gain <strong>insight</strong> into how our services are operating on a daily basis. The need to store <strong>millions of datapoints per second</strong> has produced the need to create a dedicated team to build a operate a product to handle that load: <a href="https://www.ovh.com/fr/data-platforms/metrics/">**Metrics Data Platform</a>.** By relying on <a href="https://hbase.apache.org/">**Apache Hbase</a>, <a href="https://kafka.apache.org/">Apache Kafka</a>** and <a href="https://www.warp10.io/"><strong>Warp 10</strong></a>, we succeeded in creating a fully distributed platform that is handling all our metrics‚Ä¶ and yours!</p>
<p>After building the platform to deal with all those metrics, our next challenge was to build one of the most needed feature for Metrics: the <strong>Alerting.</strong></p>
<h2 id="meet-omni-our-alerting-layer">Meet OMNI, our alerting layer</h2>
<p>OMNI is our code name for a <strong>fully distributed</strong>, <strong>as-code</strong>, <strong>alerting</strong> system that we developed on top of Metrics. It is split into components:</p>
<ul>
<li><strong>The management part</strong>, taking your alerts definitions defined in a Git repository, and represent them as continuous queries,</li>
<li><strong>The query executor</strong>, scheduling your queries in a distributed way.</li>
</ul>
<p>The query executor is pushing the query results into Kafka, ready to be handled! We now need to perform all the tasks that an alerting system does:</p>
<ul>
<li>Handling alerts <strong>deduplication</strong> and <strong>grouping</strong>, to avoid <a href="https://en.wikipedia.org/wiki/Alarm_fatigue">alert fatigue. </a></li>
<li>Handling <strong>escalation</strong> steps, **acknowledgement **or <strong>snooze</strong>.</li>
<li><strong>Notify</strong> the end user, through differents <strong>channels</strong>: SMS, mail, Push notifications, ‚Ä¶</li>
</ul>
<p>To handle that, we looked at open-source projects, such as <a href="https://github.com/prometheus/alertmanager">Prometheus AlertManager,</a> <a href="https://engineering.linkedin.com/blog/2017/06/open-sourcing-iris-and-oncall">LinkedIn Iris,</a> we discovered the <em>hidden</em> truth:</p>
<blockquote>
<p>Handling alerts as streams of data,<br>
moving from operators to another.</p>
</blockquote>
<p>We embraced it, and decided to leverage <a href="https://flink.apache.org/">Apache Flink</a> to create <strong>Beacon</strong>. In the next section we are going to describe the architecture of Beacon, and how we built and operate it.</p>
<p>If you want some more information on Apache Flink, we suggest to read the introduction article on the official website: <a href="https://flink.apache.org/flink-architecture.html">What is Apache Flink?</a></p>
<h2 id="beacon-architecture"><strong>Beacon architecture</strong></h2>
<p>At his core, Beacon is reading events from <strong>Kafka</strong>. Everything is represented as a <strong>message</strong>, from alerts to aggregations rules, snooze orders and so on. The pipeline is divided into two branches:</p>
<ul>
<li>One that is running the <strong>aggregations</strong>, and triggering notifications based on customer&rsquo;s rules.</li>
<li>One that is handling the <strong>escalation steps</strong>.</li>
</ul>
<p>Then everything is merged to <strong>generate</strong> <strong>a</strong> <strong>notification</strong>, that is going to be forward to the right person. A notification message is pushed into Kafka, that will be consumed by another component called <strong>beacon-notifier.</strong></p>

    <img src="https://www.ovh.com/fr/blog/wp-content/uploads/2019/01/002.png?x70472"  alt="Hello Friend"  class="center"  style="background: white"  />


<h2 id="handling-states">Handling States</h2>
<p>If you are new to streaming architecture, I recommend reading <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.7/concepts/programming-model.html">Dataflow Programming Model</a> from Flink official documentation.</p>

    <img src="https://www.ovh.com/fr/blog/wp-content/uploads/2019/01/003.png?x70472"  alt="Hello Friend"  class="center"  style="background: white"  />


<p>Everything is merged into a dataStream, <strong>partitionned</strong> (<a href="https://medium.com/r/?url=https%3A%2F%2Fci.apache.org%2Fprojects%2Fflink%2Fflink-docs-release-1.7%2Fdev%2Fstream%2Fstate%2Fstate.html%23keyed-state">keyed by </a>in Flink API) by users. Here&rsquo;s an example:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-java" data-lang="java">    <span style="color:#66d9ef">final</span> DataStream<span style="color:#f92672">&gt;</span> alertStream <span style="color:#f92672">=</span>
    
      <span style="color:#75715e">// Partitioning Stream per AlertIdentifier
</span><span style="color:#75715e"></span>      cleanedAlertsStream<span style="color:#f92672">.</span><span style="color:#a6e22e">keyBy</span><span style="color:#f92672">(</span>0<span style="color:#f92672">)</span>
      <span style="color:#75715e">// Applying a Map Operation which is setting since when an alert is triggered
</span><span style="color:#75715e"></span>      <span style="color:#f92672">.</span><span style="color:#a6e22e">map</span><span style="color:#f92672">(</span><span style="color:#66d9ef">new</span> SetSinceOnSelector<span style="color:#f92672">())</span>
      <span style="color:#f92672">.</span><span style="color:#a6e22e">name</span><span style="color:#f92672">(</span><span style="color:#e6db74">&#34;setting-since-on-selector&#34;</span><span style="color:#f92672">).</span><span style="color:#a6e22e">uid</span><span style="color:#f92672">(</span><span style="color:#e6db74">&#34;setting-since-on-selector&#34;</span><span style="color:#f92672">)</span>
    
      <span style="color:#75715e">// Partitioning again Stream per AlertIdentifier
</span><span style="color:#75715e"></span>      <span style="color:#f92672">.</span><span style="color:#a6e22e">keyBy</span><span style="color:#f92672">(</span>0<span style="color:#f92672">)</span>
      <span style="color:#75715e">// Applying another Map Operation which is setting State and Trend
</span><span style="color:#75715e"></span>      <span style="color:#f92672">.</span><span style="color:#a6e22e">map</span><span style="color:#f92672">(</span><span style="color:#66d9ef">new</span> SetStateAndTrend<span style="color:#f92672">())</span>
      <span style="color:#f92672">.</span><span style="color:#a6e22e">name</span><span style="color:#f92672">(</span><span style="color:#e6db74">&#34;setting-state&#34;</span><span style="color:#f92672">).</span><span style="color:#a6e22e">uid</span><span style="color:#f92672">(</span><span style="color:#e6db74">&#34;setting-state&#34;</span><span style="color:#f92672">);</span>
</code></pre></div><p>In the example above, we are chaining two keyed operations:</p>
<ul>
<li><strong>SetSinceOnSelector</strong>, which is setting <strong>since</strong> when the alert is triggered</li>
<li><strong>SetStateAndTrend</strong>, which is setting the <strong>state</strong>(ONGOING, RECOVERY or OK) and the <strong>trend</strong>(do we have more or less metrics in errors).</li>
</ul>
<p>Each of this class is under 120 lines of codes because Flink is <strong>handling all the difficulties</strong>. Most of the pipeline are <strong>only composed</strong> of <strong>classic transformations</strong> such as <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.7/dev/stream/operators/">Map, FlatMap, Reduce</a>, including their <a href="https://ci.apache.org/projects/flink/flink-docs-stable/dev/api_concepts.html#rich-functions">Rich</a> and <a href="https://ci.apache.org/projects/flink/flink-docs-stable/dev/stream/state/state.html#using-managed-keyed-state">Keyed</a> version. We have a few <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.7/dev/stream/operators/process_function.html">Process Functions</a>, which are <strong>very handy</strong> to develop, for example, the escalation timer.</p>
<h2 id="integration-tests">Integration tests</h2>
<p>As the number of classes was growing, we needed to test our pipeline. Because it is only wired to Kafka, we wrapped consumer and producer to create what we call **scenari: **a series of integration tests running different scenarios.</p>
<h2 id="queryable-state">Queryable state</h2>
<p>One killer feature of Apache Flink is the <strong>capabilities of <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.7/dev/stream/state/queryable_state.html">**<strong>querying the internal state</strong></a></strong> of an operator**. Even if it is a beta feature, it allows us the get the current state of the different parts of the job:</p>
<ul>
<li>at which escalation steps are we on</li>
<li>is it snoozed or <em>ack</em>-ed</li>
<li>Which alert is ongoing</li>
<li>and so on.</li>
</ul>
<p><img src="https://www.ovh.com/fr/blog/wp-content/uploads/2019/01/004-1.png?x70472" alt="Queryable state overview">Queryable state overview</p>
<p>Thanks to this, we easily developed an <strong>API</strong> over the queryable state, that is powering our <strong>alerting view</strong> in <a href="https://studio.metrics.ovh.net/">Metrics Studio,</a> our codename for the Web UI of the Metrics Data Platform.</p>
<h3 id="apache-flink-deployment">Apache Flink deployment</h3>
<p>We deployed the latest version of Flink (<strong>1.7.1</strong> at the time of writing) directly on bare metal servers with a dedicated Zookeeper&rsquo;s cluster using Ansible. Operating Flink has been a really nice surprise for us, with <strong>clear documentation and configuration</strong>, and an <strong>impressive resilience</strong>. We are capable of <strong>rebooting</strong> the whole Flink cluster, and the job is <strong>restarting at his last saved state</strong>, like nothing happened.</p>
<p>We are using <strong>RockDB</strong> as a state backend, backed by OpenStack **Swift storage **provided by OVH Public Cloud.</p>
<p>For monitoring, we are relying on <a href="https://ci.apache.org/projects/flink/flink-docs-stable/monitoring/metrics.html#prometheus-orgapacheflinkmetricsprometheusprometheusreporter">Prometheus Exporter</a> with <a href="https://github.com/ovh/beamium">Beamium</a> to gain <strong>observability</strong> over job&rsquo;s health.</p>
<h3 id="in-short-we-love-apache-flink">In short, we love Apache Flink!</h3>
<p>If you are used to work with stream related software, you may have realized that we did not used any rocket science or tricks. We may be relying on basics streaming features offered by Apache Flink, but they allowed us to tackle many business and scalability problems with ease.</p>
<p><img src="https://www.ovh.com/fr/blog/wp-content/uploads/2019/01/0F28C7F7-9701-4C19-BAFB-E40439FA1C77.png?x70472" alt="Apache Flink"></p>
<p>As such, we highly recommend that any developers should have a look to Apache Flink. I encourage you to go through <a href="https://medium.com/r/?url=https%3A%2F%2Ftraining.da-platform.com%2F">Apache Flink Training</a>, written by Data Artisans. Furthermore, the community has put a lot of effort to easily deploy Apache Flink to Kubernetes, so you can easily try Flink using our Managed Kubernetes!</p>
]]></content>
        </item>
        
        <item>
            <title>What are ACID transactions?</title>
            <link>https://pierrezemb.fr/posts/acid-transactions/</link>
            <pubDate>Sun, 03 Feb 2019 15:37:27 +0100</pubDate>
            
            <guid>https://pierrezemb.fr/posts/acid-transactions/</guid>
            <description>Transaction? &amp;quot;Programming should be about transforming data&amp;quot;  &amp;mdash; Programming Elixir 1.3 by Dave Thomas
 As developers, we are interacting oftenly with data, whenever handling it from an API or a messaging consumer. To store it, we started to create softwares called relational database management system or RDBMS. Thanks to them, we, as developers, can develop applications pretty easily, without the need to implement our own storage solution. Interacting with mySQL or PostgreSQL have now become a commodity.</description>
            <content type="html"><![CDATA[<h1 id="transaction">Transaction?</h1>
<pre><code>&quot;Programming should be about transforming data&quot;
</code></pre>
<p>&mdash; Programming Elixir 1.3 by Dave Thomas</p>
<hr>
<p>As developers, we are interacting oftenly with data, whenever handling it from an API or a messaging consumer. To store it, we started to create softwares called <strong>relational database management system</strong> or <a href="https://en.wikipedia.org/wiki/Relational_database_management_system">RDBMS</a>. Thanks to them, we, as developers, can develop applications pretty easily, <strong>without the need to implement our own storage solution</strong>. Interacting with <a href="https://www.mysql.com/">mySQL</a> or <a href="https://www.postgresql.org/">PostgreSQL</a> have now become a <strong>commodity</strong>. Handling a database is not that easy though, because anything can happen, from failures to concurrency isssues:</p>
<ul>
<li>How can we interact with <strong>datastores that can fail?</strong></li>
<li>What is happening if two users are  <strong>updating a value at the same time?</strong></li>
</ul>
<p>As a database user, we are using <code>transactions</code> to answer these questions. As a developer, a transaction is a <strong>single unit of logic or work</strong>, sometimes made up of multiple operations. It is mainly an <strong>abstraction</strong> that we are using to <strong>hide underlying problems</strong>, such as concurrency or hardware faults.</p>
<p><code>ACID</code> appears in a paper published in 1983 called <a href="https://sites.fas.harvard.edu/~cs265/papers/haerder-1983.pdf">&ldquo;Principles of transaction-oriented database recovery&rdquo;</a> written by <em>Theo Haerder</em> and <em>Andreas Reuter</em>. This paper introduce a terminology of properties for a transaction:</p>
<blockquote>
<p><strong>A</strong>tomic, <strong>C</strong>onsistency, <strong>I</strong>solation, <strong>D</strong>urability</p>
</blockquote>
<h2 id="atomic">Atomic</h2>
<p>Atomic, as you may have guessed, <code>atomic</code> represents something that <strong>cannot be splitted</strong>. In the database transaction world, it means for example that if a transaction with several writes is <strong>started and failed</strong> at some point, <strong>none of the write will be committed</strong>. As stated by many, the word <code>atomic</code> could be reword as <code>abortability</code>.</p>
<hr>
<h2 id="consistency">Consistency</h2>
<p>You will hear about <code>consistency</code> a lot of this serie. Unfortunately, this word can be used in a lot of context. In the ACID definition, it refers to the fact that a transaction will <strong>bring the database from one valid state to another.</strong></p>
<hr>
<h2 id="isolation">Isolation</h2>
<p>Think back to your database. Were you the only user on it? I don&rsquo;t think so. Maybe they were concurrent transactions at the same time, beside yours. <strong>Isolation while keeping good performance is the most difficult item on the list.</strong> There&rsquo;s a lot of litterature and papers about it, and we will only scratch the surface. There is different transaction isolation levels, depending on the number of guarantees provided.</p>
<h3 id="isolation-by-the-theory">Isolation by the theory</h3>
<p>The SQL standard defines four isolation levels: <code>Serializable</code>, <code>Repeatable Read</code>, <code>Read Commited</code> and <code>Read Uncommited</code>. The strongest isolation is <code>Serializable</code> where transaction are <strong>not runned in parallel</strong>. As you may have guessed, it is also the slowest. <strong>Weaker isolation level are trading speed against anomalies</strong> that can be sum-up like this:</p>
<table>
<thead>
<tr>
<th>Isolation level</th>
<th><a href="https://en.wikipedia.org/wiki/Isolation_(database_systems)#Dirty_reads">dirty reads</a></th>
<th><a href="https://en.wikipedia.org/wiki/Isolation_%28database_systems%29#Non-repeatable_reads">Non-repeatable reads</a></th>
<th><a href="https://en.wikipedia.org/wiki/Isolation_(database_systems)#Phantom_reads">Phantom reads</a></th>
<th>Performance</th>
</tr>
</thead>
<tbody>
<tr>
<td>Serializable</td>
<td>üòé</td>
<td>üòé</td>
<td>üòé</td>
<td>üëç</td>
</tr>
<tr>
<td>Repeatable Read</td>
<td>üòé</td>
<td>üòé</td>
<td>üò±</td>
<td>üëçüëç</td>
</tr>
<tr>
<td>Read Commited</td>
<td>üòé</td>
<td>üò±</td>
<td>üò±</td>
<td>üëçüëçüëç</td>
</tr>
<tr>
<td>Read uncommited</td>
<td>üò±</td>
<td>üò±</td>
<td>üò±</td>
<td>üëçüëçüëçüëç</td>
</tr>
</tbody>
</table>
<blockquote>
<p>I encourage you to click on all the links within the table to <strong>see everything that could go wrong in a weak database!</strong></p>
</blockquote>
<h3 id="isolation-in-real-databases">Isolation in Real Databases</h3>
<p>Now that we saw some theory, let&rsquo;s have a look on a particular well-known database: PostgreSQL. What kind of isolation PostgreSQL is offering?</p>
<blockquote>
<p>PostgreSQL provides a rich set of tools for developers to manage concurrent access to data. Internally, data consistency is maintained by using a multiversion model (<strong>Multiversion Concurrency Control, MVCC</strong>).</p>
</blockquote>
<p>&mdash; <a href="https://www.postgresql.org/docs/current/mvcc-intro.html">Concurrency Control introduction</a></p>
<p>Wait what? What is MVCC? Well, turns out that after the SQL standards came another type of Isolation: <strong>Snapshot Isolation</strong>. Instead of locking that row for reading when somebody starts working on it, it ensures that <strong>any transaction will see a version of the data that is corresponding to the start of the query</strong>. As it is providing a good balance between <strong>performance and consistency</strong>, it became <a href="https://en.wikipedia.org/wiki/List_of_databases_using_MVCC">a standard used by the industry</a>.</p>
<hr>
<h2 id="durability">Durability</h2>
<p><code>Durability</code> ensure that your database is a <strong>safe place</strong> where data can be stored without fear of losing it. If a transaction has commited successfully, any written data will not be forgotten.</p>
<h1 id="thats-it">That&rsquo;s it?</h1>
<p><strong>All these properties may seems obvious to you</strong> but each of the item is involving a lot of engineering and researchs. And this is only valid for a single machine, <strong>the distributed transaction field</strong> is even more complicated, but we will get to it in another blogpost!</p>
<hr>
<p><strong>Thank you</strong> for reading my post! Feel free to react to this article, I am also available on <a href="https://twitter.com/PierreZ">Twitter</a> if needed.</p>
]]></content>
        </item>
        
        <item>
            <title>Hbase Data Model</title>
            <link>https://pierrezemb.fr/posts/hbase-data-model/</link>
            <pubDate>Sun, 27 Jan 2019 20:24:27 +0100</pubDate>
            
            <guid>https://pierrezemb.fr/posts/hbase-data-model/</guid>
            <description>HBase?  Apache HBase‚Ñ¢ is a type of &amp;ldquo;NoSQL&amp;rdquo; database. &amp;ldquo;NoSQL&amp;rdquo; is a general term meaning that the database isn‚Äôt an RDBMS which supports SQL as its primary access language. Technically speaking, HBase is really more a &amp;ldquo;Data Store&amp;rdquo; than &amp;ldquo;Data Base&amp;rdquo; because it lacks many of the features you find in an RDBMS, such as typed columns, secondary indexes, triggers, and advanced query languages, etc.
 &amp;ndash; Hbase architecture overview</description>
            <content type="html"><![CDATA[<h1 id="hbase">HBase?</h1>
<p><img src="/posts/hbase-data-model/images/hbase.jpg" alt="hbase image"></p>
<blockquote>
<p><a href="https://hbase.apache.org/">Apache HBase‚Ñ¢</a> is a type of &ldquo;NoSQL&rdquo; database. &ldquo;NoSQL&rdquo; is a general term meaning that the database isn‚Äôt an RDBMS which supports SQL as its primary access language. Technically speaking, HBase is really more a &ldquo;Data Store&rdquo; than &ldquo;Data Base&rdquo; because it lacks many of the features you find in an RDBMS, such as typed columns, secondary indexes, triggers, and advanced query languages, etc.</p>
</blockquote>
<p>&ndash; <a href="https://hbase.apache.org/book.html#arch.overview.nosql">Hbase architecture overview</a></p>
<h1 id="hbase-data-model">Hbase data model</h1>
<p>The data model is simple: it&rsquo;s like a multi-dimensional map:</p>
<ul>
<li>Elements are stored as <strong>rows</strong> in a <strong>table</strong>.</li>
<li>Each table has only <strong>one index, the row key</strong>. There are no secondary indices.</li>
<li>Rows are <strong>sorted lexicographically by row key</strong>.</li>
<li>A range of rows is called a <strong>region</strong>. It is similar to a shard.</li>
<li>A row in HBase consists of a <strong>row key</strong> and <strong>one or more columns</strong>, which are holding the cells.</li>
<li>Values are stored into what we call a <strong>cell</strong> and are versioned with a timestamp.</li>
<li>A column is divided between a <strong>Column Family</strong> and a <strong>Column Qualifier</strong>. Long story short, a Column Family is kind of like a column in classic SQL, and a qualifier is a sub-structure inside a Colum family. A column Family is <strong>static</strong>, you need to create it during table creation, whereas Column Qualifiers can be created on the fly.</li>
</ul>
<p>Not as easy as you thought? Here&rsquo;s an example! Let&rsquo;s say that we&rsquo;re trying to <strong>save the whole internet</strong>. To do this, we need to store the content of each pages, and versioned it. We can use <strong>the page address as the row key</strong> and store the contents in a <strong>column called &ldquo;Contents&rdquo;</strong>. Nowadays, website <strong>contents can be anything</strong>, from a HTML file to a binary such as a PDF. To handle that, we can create as many <strong>qualifiers</strong> as we want, such as &ldquo;content:html&rdquo; or &ldquo;content:video&rdquo;.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-json" data-lang="json">{
  <span style="color:#f92672">&#34;fr.pierrezemb.www&#34;</span>: {          <span style="color:#960050;background-color:#1e0010">//</span> <span style="color:#960050;background-color:#1e0010">Row</span> <span style="color:#960050;background-color:#1e0010">key</span>
    <span style="color:#f92672">&#34;contents&#34;</span>: {                 <span style="color:#960050;background-color:#1e0010">//</span> <span style="color:#960050;background-color:#1e0010">Column</span> <span style="color:#960050;background-color:#1e0010">family</span>
      <span style="color:#f92672">&#34;content:html&#34;</span>: {	          <span style="color:#960050;background-color:#1e0010">//</span> <span style="color:#960050;background-color:#1e0010">Column</span> <span style="color:#960050;background-color:#1e0010">qualifier</span>
        <span style="color:#f92672">&#34;2017-01-01&#34;</span>:             <span style="color:#960050;background-color:#1e0010">//</span> <span style="color:#960050;background-color:#1e0010">A</span> <span style="color:#960050;background-color:#1e0010">timestamp</span>
          <span style="color:#e6db74">&#34;&lt;html&gt;...&#34;</span>,            <span style="color:#960050;background-color:#1e0010">//</span> <span style="color:#960050;background-color:#1e0010">The</span> <span style="color:#960050;background-color:#1e0010">actual</span> <span style="color:#960050;background-color:#1e0010">value</span>
        <span style="color:#f92672">&#34;2016-01-01&#34;</span>:             <span style="color:#960050;background-color:#1e0010">//</span> <span style="color:#960050;background-color:#1e0010">Another</span> <span style="color:#960050;background-color:#1e0010">timestamp</span>
          <span style="color:#e6db74">&#34;&lt;html&gt;...&#34;</span>             <span style="color:#960050;background-color:#1e0010">//</span> <span style="color:#960050;background-color:#1e0010">Another</span> <span style="color:#960050;background-color:#1e0010">cell</span>
      },
      <span style="color:#f92672">&#34;content:pdf&#34;</span>: {            <span style="color:#960050;background-color:#1e0010">//</span> <span style="color:#960050;background-color:#1e0010">Another</span> <span style="color:#960050;background-color:#1e0010">Column</span> <span style="color:#960050;background-color:#1e0010">qualifier</span>
        <span style="color:#f92672">&#34;2015-01-01&#34;</span>: 
          <span style="color:#e6db74">&#34;&lt;pdf&gt;...&#34;</span>  <span style="color:#960050;background-color:#1e0010">//</span> <span style="color:#960050;background-color:#1e0010">my</span> <span style="color:#960050;background-color:#1e0010">website</span> <span style="color:#960050;background-color:#1e0010">may</span> <span style="color:#960050;background-color:#1e0010">only</span> <span style="color:#960050;background-color:#1e0010">contained</span> <span style="color:#960050;background-color:#1e0010">a</span> <span style="color:#960050;background-color:#1e0010">pdf</span> <span style="color:#960050;background-color:#1e0010">in</span> <span style="color:#ae81ff">2015</span>
      }
    }
  }
}
</code></pre></div><h1 id="key-design">Key design</h1>
<p>Hbase is most efficient at queries when we&rsquo;re getting a <strong>single row key</strong>, or during <strong>row range</strong>, ie. getting a block of contiguous data because keys are <strong>sorted lexicographically by row key</strong>. For example, my website <code>fr.pierrezemb.www</code> and <code>org.pierrezemb.www</code> would not be &ldquo;near&rdquo;.</p>
<p>As such, the <strong>key design</strong> is really important:</p>
<ul>
<li>If your data are too spread, you will have poor performance.</li>
<li>If your data are too much collocate, you will also have poor performance.</li>
</ul>
<p>As stated by the official <a href="https://hbase.apache.org/book.html#rowkey.design">documentation</a>:</p>
<blockquote>
<p>Hotspotting occurs when a <strong>large amount of client traffic is directed at one node, or only a few nodes, of a cluster</strong>. This traffic may represent reads, writes, or other operations. The traffic overwhelms the single machine responsible for hosting that region, causing performance degradation and potentially leading to region unavailability.</p>
</blockquote>
<p>As you may have guessed, this is why we are using the <strong>reverse address name</strong> in my example, because <code>www</code> is too generic, we would have hotspot the poor region holding data for <code>www</code>.</p>
<p>If you are curious about Hbase schema, you should have a look on <a href="https://cloud.google.com/bigtable/docs/schema-design">Designing Your BigTable Schema</a>, as BigTable is kind of the proprietary version of Hbase.</p>
<h1 id="be-warned">Be warned</h1>
<p>I have been working with Hbase for the past three years, <strong>including operation and on-call duty.</strong> It is a really nice data store, but it diverges from classical RDBMS. Here&rsquo;s some warnings extracted from the well-written documentation:</p>
<blockquote>
<p>HBase is really more a &ldquo;Data Store&rdquo; than &ldquo;Data Base&rdquo; because it lacks many of the features you find in an RDBMS, such as typed columns, secondary indexes, triggers, and advanced query languages, etc. However, HBase has many features which supports both linear and modular scaling.</p>
</blockquote>
<p>&ndash; <a href="https://hbase.apache.org/book.html#arch.overview.nosql">NoSQL?</a></p>
<blockquote>
<p>If you have hundreds of millions or billions of rows, then HBase is a good candidate. If you only have a few thousand/million rows, then using a traditional RDBMS might be a better choice due to the fact that all of your data might wind up on a single node (or two) and the rest of the cluster may be sitting idle.</p>
</blockquote>
<p>&ndash; <a href="https://hbase.apache.org/book.html#arch.overview.when">When Should I Use HBase?</a></p>
<hr>
<p><strong>Thank you</strong> for reading my post! Feel free to react to this article, I am also available on <a href="https://twitter.com/PierreZ">Twitter</a> if needed.</p>
]]></content>
        </item>
        
        <item>
            <title>Introducing HelloExoWorld: The quest to discover exoplanets with Warp10 and Tensorflow</title>
            <link>https://pierrezemb.fr/posts/introducing-helloexoworld-the-quest-to-discover-exoplanets-with-warp10-and-tensorflow/</link>
            <pubDate>Wed, 11 Oct 2017 10:23:11 +0000</pubDate>
            
            <guid>https://pierrezemb.fr/posts/introducing-helloexoworld-the-quest-to-discover-exoplanets-with-warp10-and-tensorflow/</guid>
            <description>update 2019: this is a repost on my own blog. original article can be read on medium.
 Artist‚Äôs impression of the super-Earth exoplanet LHS 1140b By ESO/spaceengine.org‚Ää‚Äî‚ÄäCC BY 4.0
My passion for programming was kind of late, I typed my first line of code at my engineering school. It then became a passion, something I‚Äôm willing to do at work, on my free-time, at night or the week-end.</description>
            <content type="html"><![CDATA[<p><strong>update 2019:</strong> this is a repost on my own blog. original article can be read on <a href="https://medium.com/helloexoworld/introducing-helloexoworld-the-quest-to-discover-exoplanets-with-warp10-and-tensorflow-e50f6e669915">medium</a>.</p>
<hr>
<p><img src="/posts/introducing-helloexoworld-the-quest-to-discover-exoplanets-with-warp10-and-tensorflow/images/1.jpeg" alt="image">
<em>Artist‚Äôs impression of the super-Earth exoplanet LHS 1140b By <a href="https://www.eso.org/public/images/eso1712a/">ESO/spaceengine.org</a>‚Ää‚Äî‚Ää<a href="http://creativecommons.org/licenses/by/4.0">CC BY 4.0</a></em></p>
<p>My passion for programming was kind of late, I typed my first line of code at my engineering school. It then became a <strong>passion</strong>, something I‚Äôm willing to do at work, on my free-time, at night or the week-end. But before discovering C and other languages, I had another passion: <strong>astronomy</strong>. Every summer, I was participating at the <a href="https://www.afastronomie.fr/les-nuits-des-etoiles"><strong>Nuit des Etoiles</strong></a>, a <strong>global french event</strong> organized by numerous clubs of astronomers offering several hundreds (between 300 and 500 depending on the year) of free animation sites for the general public.</p>
<p><img src="/posts/introducing-helloexoworld-the-quest-to-discover-exoplanets-with-warp10-and-tensorflow/images/2.png" alt="image">
<em>As you can see below, I was <strong>kind of young at the time</strong>!</em></p>
<p>But the sad truth is that I didn‚Äôt do any astronomy during my studies. But now, <strong>I want to get back to it and look at the sky again</strong>. There were two obstacles:</p>
<ul>
<li>The price of equipments</li>
<li>The local weather</li>
</ul>
<p><strong>I was looking for something that would unit my two passions: computer and astronomy</strong>. So I started googling:</p>
<p><img src="/posts/introducing-helloexoworld-the-quest-to-discover-exoplanets-with-warp10-and-tensorflow/images/3.png" alt="image"></p>
<p>I found a lot of amazing projects using Raspberry pis, but I didn‚Äôt find something that would <strong>motivate me</strong> over the time. So I started typing over keywords, more work-related, such as <strong><em>time series</em></strong> or <strong><em>analytics</em></strong>. I found many papers related to astrophysics, but there was two keywords that were coming back: <strong>exoplanet detection</strong>.</p>
<h3 id="what-is-an-exoplanet-and-how-to-detect-it">What is an exoplanet and how to detect it?</h3>
<p>Let‚Äôs quote our good old friend <a href="https://en.wikipedia.org/wiki/Exoplanet"><strong>Wikipedia</strong></a>:</p>
<blockquote>
<p><em>An exoplanet or extrasolar planet is a planet outside of our solar system that orbits a star.</em></p>
</blockquote>
<p>do you know how many exoplanets that have been discovered? <a href="https://exoplanetarchive.ipac.caltech.edu/"><strong>3,529 confirmed planets</strong> as of 10/09/2017</a>. I was amazed by the number of them. I started digging into the <a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets"><strong>detection methods</strong></a>. Turns out there is one method heavily used, called <strong>the transit method</strong>. It‚Äôs like a eclipse: when the exoplanet is passing in front of the star, the photometry is varying during the transit, as shown below:</p>
<p><img src="/posts/introducing-helloexoworld-the-quest-to-discover-exoplanets-with-warp10-and-tensorflow/images/4.gif" alt="image"></p>
<p>animation illustrating how a dip in the observed brightness of a star may indicate the presence of an exoplanet. <strong><em>Credits: NASA‚Äôs Goddard Space Flight Center</em></strong></p>
<p>To recap, exoplanet detection using the transit method are in reality a <strong>time series analysis problem</strong>. As I‚Äôm starting to be familiar with that type of analytics thanks to my current work at OVH in <a href="https://www.ovh.com/fr/data-platforms/metrics/"><strong>Metrics Data Platform</strong></a>, I wanted to give it a try.</p>
<h3 id="keplerk2-mission">Kepler/K2 mission</h3>
<p><img src="/posts/introducing-helloexoworld-the-quest-to-discover-exoplanets-with-warp10-and-tensorflow/images/5.jpeg" alt="image"></p>
<p><em>Image Credit: NASA Ames/W. Stenzel</em></p>
<p>Kepler is a <strong>space observatory</strong> launched by NASA in March 2009 to <strong>discover Earth-sized planets orbiting other stars</strong>. <a href="https://www.nasa.gov/feature/ames/nasas-k2-mission-the-kepler-space-telescopes-second-chance-to-shine">The loss of a second of the four reaction wheels during May 2013</a> put an end to the original mission. Fortunately, scientists decided to create an <strong>entirely community-driven mission</strong> called K2, to <strong>reuse the Kepler spacecraft and its assets</strong>. But furthermore, the community is also encouraged to exploit the mission‚Äôs unique <strong>open</strong> data archive. Every image taken by the satellite can be <strong>downloaded and analyzed by anyone</strong>.</p>
<p>More information about the telescope itself can be found <a href="https://keplerscience.arc.nasa.gov/the-kepler-space-telescope.html"><strong>here</strong></a>.</p>
<h3 id="where-im-going">Where I‚Äôm going</h3>
<p>The goal of my project is to see if <strong>I can contribute to the exoplanets search</strong> using new tools such as <a href="http://www.warp10.io"><strong>Warp10</strong></a> and <a href="https://tensorflow.org/"><strong>TensorFlow</strong></a>. Using <strong>Deep Learning to search for anomalies could be much more effective</strong> than writing WarpScript, because it is the <strong>neural network's job to learn</strong> by itself <strong>how</strong> to detect the exoplanets.</p>
<p>As I‚Äôm currently following <a href="https://www.coursera.org/learn/neural-networks-deep-learning"><strong>Andrew Ng courses about Deep Learning</strong></a>, it is also a great opportunity for me to play with <strong>Tensorflow</strong> in a personal project. The project can be divided into several steps:</p>
<ul>
<li><strong>Import</strong> the data</li>
<li><strong>Analyze</strong> the data using WarpScript</li>
<li><strong>Build</strong> a neural network to search for exoplanets</li>
</ul>
<p>Let's see how the import was done!</p>
<h3 id="importing-kepler-and-k2-dataset">Importing Kepler and K2 dataset</h3>
<h4 id="step-0-find-the-data">Step 0: Find the data</h4>
<p>As mentioned previously, data are available from The Mikulski Archive for Space Telescopes or <a href="https://archive.stsci.edu/">MAST</a>. It‚Äôs a <strong>NASA funded project</strong> to support and provide the astronomical community with a variety of astronomical data archives. Both Kepler and K2 dataset are <strong>available</strong> through <strong>campaigns</strong>. Each campaign has a collection of tar files, which are containing the FITS files associated. A <a href="https://en.wikipedia.org/wiki/FITS"><strong>FITS</strong></a> file is an <strong>open format</strong> for images which is also <strong>containing scientific data</strong>.</p>
<p><img src="/posts/introducing-helloexoworld-the-quest-to-discover-exoplanets-with-warp10-and-tensorflow/images/6.png" alt="image"></p>
<p><em>FITS file representation.</em> <a href="https://keplerscience.arc.nasa.gov/k2-observing.html"><em>Image Credit: KEPLER &amp; K2 Science Center</em></a></p>
<h4 id="step-1-etl-extract-transform-and-load-into-warp10">Step 1: ETL (Extract, Transform and Load) into Warp10</h4>
<p>To speed-up acquisition, I developed <a href="https://github.com/PierreZ/kepler-lens"><strong>kepler-lens</strong></a> to <strong>automatically</strong> <strong>download Kepler/K2 datasets and extract the needed time series</strong> into a CSV format. <strong>Kepler-lens</strong> is using two awesome libraries:</p>
<ul>
<li><a href="https://github.com/KeplerGO/PyKE"><strong>pyKe</strong></a> to export the data from the <a href="https://en.wikipedia.org/wiki/FITS"><strong>FITS</strong></a> files to CSV (<a href="https://github.com/KeplerGO/PyKE/pull/69"><strong>#PR69</strong></a> and <a href="https://github.com/KeplerGO/PyKE/pull/76"><strong>#PR76</strong></a>  have been merged).</li>
<li><a href="https://github.com/dfm/kplr"><strong>kplr</strong></a> is used to <strong>tag</strong> the dataset. With it, I can easily <strong>find stars</strong> with <strong>confirmed</strong> exoplanets or <strong>candidates</strong>.</li>
</ul>
<p>Then <a href="https://github.com/PierreZ/kepler2warp10"><strong>Kepler2Warp10</strong></a> is used to <strong>push the CSV files generated by kepler-lens to Warp10</strong>.</p>
<p>To ease importation, an <a href="https://github.com/PierreZ/kepler2warp10-ansible"><strong>Ansible role</strong></a>  has been made, to spread the work across multiples small <strong>virtual machines</strong>.</p>
<p>Principles of transaction-oriented database recovery</p>
<blockquote class="twitter-tweet"><p lang="en" dir="ltr">The import of @NASAKepler  dataset has been spread on 16 machines, just because I can üòé <a href="https://t.co/qa49tAgdzz">pic.twitter.com/qa49tAgdzz</a></p>&mdash; Pierre Zemb (@PierreZ) <a href="https://twitter.com/PierreZ/status/908784580450295808?ref_src=twsrc%5Etfw">September 15, 2017</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<ul>
<li><strong>550k distincts stars</strong></li>
<li>around <strong>50k datapoints per star</strong></li>
</ul>
<p>That's around <strong>27,5 billions of measures</strong> (300GB of LevelDB files), imported on a <strong>standalone</strong> instance. The Warp10 instance is <strong>self-hosted</strong> on a dedicated <a href="https://www.kimsufi.com/"><strong>Kimsufi</strong></a> server at OVH. Here‚Äôs the full specifications for the curious ones:</p>
<p><img src="/posts/introducing-helloexoworld-the-quest-to-discover-exoplanets-with-warp10-and-tensorflow/images/7.png" alt="image"></p>
<p>Now that the data are <strong>available</strong>, we are ready to <strong>dive into the dataset</strong> and <strong>look for exoplanets</strong>! Let's use WarpScript</p>
<p>!### Let's see a transit using WarpScript</p>
<p><img src="/posts/introducing-helloexoworld-the-quest-to-discover-exoplanets-with-warp10-and-tensorflow/images/8.png" alt="image"></p>
<p>WarpScript logo</p>
<p>For those who don‚Äôt know WarpScript, I recommend reading my previous blogpost ‚Äú<a href="https://medium.com/@PierreZ/engage-maximum-warp-speed-in-time-series-analysis-with-warpscript-c97a9f4a0016"><strong>Engage maximum warp speed in time series analysis with WarpScript</strong></a>‚Äù.</p>
<p>Let‚Äôs first plot the data! We are going to take a well-known star called <a href="https://en.wikipedia.org/wiki/Kepler-11"><strong>Kepler-11</strong></a>. It has (at least) 6 confirmed exoplanets. Let's write our first WarpScript:</p>
<p>The <a href="http://www.warp10.io/reference/functions/function_FETCH">FETCH</a> function retrieves <strong>raw datapoints</strong> from Warp10. Let‚Äôs plot the result of our script:</p>
<p><img src="/posts/introducing-helloexoworld-the-quest-to-discover-exoplanets-with-warp10-and-tensorflow/images/9.png" alt="image"></p>
<p>Mmmmh, the straight lines are representing <strong>empties period with no datapoints</strong>; they correspond to <strong>different observations</strong>. <strong>Let's divide the data</strong> and generate <strong>one time series per observation</strong> using <a href="http://www.warp10.io/reference/functions/function_TIMESPLIT/">TIMESPLIT</a>:</p>
<p>To ease the display, 0 GET is used to <strong>get only the first observation</strong>. Let's see the result:</p>
<p><img src="/posts/introducing-helloexoworld-the-quest-to-discover-exoplanets-with-warp10-and-tensorflow/images/10.png" alt="image"></p>
<p>Much better. Do you see the dropouts? <strong>Those are transiting exoplanets!</strong> Now we‚Äôll need to <strong>write a WarpScript to automatically detect transits.</strong> But that was enough for today, so we‚Äôll cover this **in the next blogpost!**Thank you for reading! Feel free to <strong>comment</strong> and to <strong>subscribe</strong> to the <a href="https://twitter.com/helloexoworld">twitter account</a>!</p>
<p><img src="/posts/introducing-helloexoworld-the-quest-to-discover-exoplanets-with-warp10-and-tensorflow/images/11.jpeg" alt="image"></p>
<p><strong>Artist‚Äôs impression of the ultracool dwarf star TRAPPIST-1 from close to one of its planets</strong>. Image Credit: By <a href="http://www.eso.org/public/images/eso1615b/">ESO/M. Kornmesser</a>‚Ää‚Äî‚Ää<a href="https://creativecommons.org/licenses/by-sa/4.0">CC BY-SA 4.0</a></p>
]]></content>
        </item>
        
        <item>
            <title>Engage maximum warp speed in time series analysis with WarpScript</title>
            <link>https://pierrezemb.fr/posts/engage-maximum-warp-speed-in-time-series-analysis-with-warpscript/</link>
            <pubDate>Sun, 08 Oct 2017 20:43:05 +0000</pubDate>
            
            <guid>https://pierrezemb.fr/posts/engage-maximum-warp-speed-in-time-series-analysis-with-warpscript/</guid>
            <description>update 2019: this is a repost on my own blog. original article can be read on medium.
 We, at Metrics Data Platform, are working everyday with Warp10 Platform, an open source Time Series database. You may not know it because it‚Äôs not as famous as Prometheus or InfluxDB but Warp10 is the most powerful and generic solution to store and analyze sensor data. It‚Äôs the core of Metrics, and many internal teams from OVH are using Metrics Data Platform to monitor their infrastructure.</description>
            <content type="html"><![CDATA[<p><strong>update 2019:</strong> this is a repost on my own blog. original article can be read on <a href="https://medium.com/@PierreZ/engage-maximum-warp-speed-in-time-series-analysis-with-warpscript-c97a9f4a0016">medium</a>.</p>
<hr>
<p><img src="/posts/engage-maximum-warp-speed-in-time-series-analysis-with-warpscript/images/1.png" alt="image"></p>
<p>We, at <a href="https://www.ovh.com/fr/data-platforms/metrics/">Metrics Data Platform</a>, are working everyday with <a href="http://www.warp10.io/">Warp10 Platform</a>, an open source Time Series database. You may not know it because it‚Äôs not as famous as <a href="https://prometheus.io/">Prometheus</a> or <a href="https://docs.influxdata.com/influxdb/">InfluxDB</a> but Warp10 is the most <strong>powerful and generic solution</strong> to store and analyze sensor data. It‚Äôs the <strong>core</strong> of Metrics, and many internal teams from OVH are using <a href="https://www.ovh.com/fr/data-platforms/metrics/">Metrics Data Platform</a> to monitor their infrastructure. As a result, we are handling a pretty nice traffic 24/7/365, as you can see below:</p>
<p><img src="/posts/engage-maximum-warp-speed-in-time-series-analysis-with-warpscript/images/6.png" alt="image"></p>
<p>Not only Warp10 allows us to reach an unbelievable scalability but it also comes with his own language called <strong>WarpScript</strong>, to manipulate and perform heavy time series analysis. Before digging into the need of a new language, let‚Äôs talk a bit about the need of time series analysis.### What is a time serie ?</p>
<p><strong>A time serie, or sensor data, is simply a sequence of measurements over time</strong>. The definition is quite generic, because many things can be represented as a time serie:</p>
<ul>
<li>the evolution of the stock exchange or a bank account</li>
<li>the number of calls on a webserver</li>
<li>the fuel consumption of a car</li>
<li>the time to insert a value into a database</li>
<li>the time a customer is taking to register on your website</li>
<li>the heart rate of a person measured through a smartwatch</li>
</ul>
<p>From an historical point of view, time series appeared shortly after the creation of the Web, to <strong>help engineers monitor the networks</strong>. It quickly expands to also monitors servers. With the right monitoring system, you can have <strong>insights</strong> and <strong>KPIs</strong> about your service:</p>
<p><strong>Analysis of long-term trend</strong></p>
<ul>
<li>How fast is my database growing?</li>
<li>At what speed my number of active user accounts grows?</li>
</ul>
<p><strong>The comparison over time</strong></p>
<ul>
<li>My queries run faster with the new version of my library? Is my site slower than last week?</li>
</ul>
<p><strong>Alerts</strong></p>
<ul>
<li>Trigger alerts based on advanced queries</li>
</ul>
<p><strong>Displaying data through dashboards</strong></p>
<ul>
<li>Dashboards help answer basic questions on the service, and in particular the 4 indispensable metrics: <strong>latency, traffic, errors and service saturation</strong></li>
</ul>
<p><strong>The possibility of designing retrospective</strong></p>
<ul>
<li>Our latency is doubling, what‚Äôs going on?### Time series are complicated to handle</li>
</ul>
<p>Storage, retrieval and analysis of time series cannot be done through standard relational databases. Generally, highly scalable databases are used to support volumetry. For example, the <strong>300,000 Airbus A380 sensors on board can generate an average of 16 TB of data per flight</strong>. On a smaller scale, <strong>a single sensor that measures every second generates 31.5 million values per year</strong>. Handling time series at scale is difficult, because you‚Äôre running into advanced distributed systems issues, such as:</p>
<ul>
<li><strong>ingestion scalability</strong>, i.e. how to absorb all the datapoints 24‚ÅÑ7</li>
<li><strong>query scalability</strong>, i.e. how to query in a raisonnable amount of time</li>
<li><strong>delete capability</strong>, i.e. how to handle deletes without stopping ingestion and query</li>
</ul>
<p>Frustration with existing open source monitoring tools like <strong>Nagios</strong> and <strong>Ganglia</strong> is why the giants created their own tools‚Ää‚Äî‚Ää<strong>Google has Borgmon</strong> and <strong>Facebook has</strong> <a href="http://www.vldb.org/pvldb/vol8/p1816-teller.pdf"><strong>Gorilla</strong></a>, just to name two. They are closed sources but the idea of treating time-series data as a data source for generating alerts is now accessible to everyone, thanks to the <strong>former Googlers who decided to rewrite Borgmon</strong> outside Google.### Why another time series database?</p>
<p>Now the time series ecosystem is bigger than ever, here‚Äôs a short list of what you can find to handle time series data:</p>
<ul>
<li>InfluxDB.</li>
<li>Prometheus.</li>
<li>Riak TS.</li>
<li>OpenTSDB.</li>
</ul>
<p>Then there‚Äôs <strong>Warp10</strong>. The difference is quite simple, Warp10 is <strong>a platform</strong> whereas all the time series listed above are <strong>stores</strong>. This is game changing, for multiples reasons.</p>
<h4 id="security-first-design">Security-first design</h4>
<p>Security is mandatory for data access and sharing job‚Äôs results, but in most of the above databases, security access is not handled by default. With Warp10, security is handled with crypto tokens similar to <a href="https://research.google.com/pubs/pub41892.html">Macaroons</a>.</p>
<h4 id="high-level-analysis-capabilities">High level analysis capabilities</h4>
<p>Using classical time series database, <strong>high level analysis must be done elsewhere</strong>, with R, Spark, Flink, Python, or whatever languages or frameworks that you want to use. Using Warp10, you can just <strong>submit your script</strong> and <em>voil√†</em>!</p>
<h4 id="server-side-calculation">Server-side calculation</h4>
<p>Algorithms are resource heavy. Whatever they‚Äôre using CPU, ram, disk and network, you‚Äôll hit <strong>limitations</strong> on your personal computer. Can you really aggregate and analyze one year of data from thousands of sensors on your laptop? Maybe, but what if you‚Äôre submitting the job from a mobile? To be <strong>scalable</strong>, analysis must be done <strong>server-side</strong>.### Meet WarpScript</p>
<p><img src="/posts/engage-maximum-warp-speed-in-time-series-analysis-with-warpscript/images/2.png" alt="image"></p>
<p>Warp10 folks created WarpScript, an <strong>extensible</strong> <a href="https://en.wikipedia.org/wiki/Stack-oriented_programming_language"><strong>stack oriented programming language</strong></a> which offers more than <strong>800 functions</strong> and <strong>several high level frameworks</strong> to ease and speed your data analysis. Simply <strong>create scripts</strong> containing your data analysis code and <strong>submit them to the platform</strong>, they will <strong>execute close to where the data resides</strong> and you will get the result of that analysis as a <strong>JSON object</strong> that you can <strong>integrate into your application</strong>.</p>
<p>Yes, you‚Äôll be able to run that <strong>awesome query that is fetching millions of datapoints</strong> and only get the result. You need all the data, or just the timestamp of a weird datapoint? <strong>The result of the script is simply what‚Äôs left on the stack</strong>.</p>
<h4 id="dataflow-language">Dataflow language</h4>
<p>WarpScript is really easy to code, <strong>because of the stack design</strong>. You‚Äôll be <strong>pushing elements into the stack and consume them</strong>. Coding became logical. First you need to <strong>fetch</strong> your points, then <strong>applying some downsampling</strong> and then <strong>aggregate</strong>. These 3 steps are translated into <strong>3 lines of WarpScript</strong>:</p>
<ul>
<li><strong>FETCH</strong> will push the needed Geo Time Series into the stack</li>
<li><strong>BUCKETIZE</strong> will take the Geo Time Series from the stack, apply some downsampling, and push the result into the stack</li>
<li><strong>REDUCE</strong> will take the Geo Time Series from the stack, aggregate them, and push them back into the stack</li>
</ul>
<p>Debugguing as never be that easy, just use the keyword <strong>STOP</strong> to see the stack at any moment.</p>
<h4 id="rich-programming-capabilities">Rich programming capabilities</h4>
<p>WarpScript is coming with more than <strong>800 functions</strong>, ready to use. Things like <strong>Patterns and outliers detections, rolling average, FFT, IDWT</strong> are built-in.</p>
<h4 id="geo-fencing-capabilities">Geo-Fencing capabilities</h4>
<p>Both <strong>space</strong> (location) and <strong>time</strong> are considered <strong>first class citizens</strong>. Complex searches like ‚Äú<strong>find all the sensors active during last Monday in the perimeter delimited by this geo-fencing polygon</strong>‚Äù can be done without involving expensive joins between separate time series for the same source.</p>
<h4 id="unified-language">Unified Language</h4>
<p>WarpScript can be used in <strong>batch</strong> mode, or in <strong>real-time</strong>, because you need both of them in the real world.</p>
<h3 id="geez-give-me-an-example">Geez, give me an example!</h3>
<p>Here‚Äôs an example of a simple but advanced query:</p>
<pre><code>// Fetching all values  
[ $token ‚Äòtemperature‚Äô {} NOW 1 h ] FETCH // Get max value for each minute  
[ SWAP bucketizer.max	0 1 m 0 ] BUCKETIZE // Round to nearest long  
[ SWAP mapper.round 0 0 0 ] MAP // reduce the data by keeping the max, grouping by 'buildingID'  
[ SWAP [ 'buildingID' ] reducer.max ] REDUCE
</code></pre><p>Have you guessed the goal? The result will <strong>display the temperature from now to 1 hour of the hottest room per buildingID</strong>.</p>
<h3 id="what-about-a-more-complex-example">What about a more complex example?</h3>
<p>You‚Äôre still here? Good, let‚Äôs have a more complex example. Let‚Äôs say that I want to do some patterns recognition. Let‚Äôs take an example. Here‚Äôs a cosinus with an increasing amplitude:</p>
<p><img src="/posts/engage-maximum-warp-speed-in-time-series-analysis-with-warpscript/images/3.png" alt="image"></p>
<p>I want to <strong>detect the green part</strong> of the time series, because I know that my service is crashing when I have that kind of load. With WarpScript, it‚Äôs only a <strong>2 functions calls</strong>:</p>
<ul>
<li><strong>PATTERNS</strong> is generating a list of motifs.</li>
<li><strong>PATTERNDETECTION</strong> is running the list of motifs on all the time series you have.</li>
</ul>
<p>Here‚Äôs the code</p>
<pre><code>// defining some variables  
32 'windowSize' STORE  
8 'patternLength' STORE  
16 'quantizationScale' STORE  

// Generate patterns   
$pattern.to.detect 0 GET   
$windowSize $patternLength $quantizationScale PATTERNS  
VALUES 'patterns' STORE  

// Running the patterns through a list of GTS (Geo Time Series)  
$list.of.gts $patterns   
$windowSize $patternLength $quantizationScale  PATTERNDETECTION
</code></pre><p>Here‚Äôs the result:</p>
<p><img src="/posts/engage-maximum-warp-speed-in-time-series-analysis-with-warpscript/images/4.png" alt="image"></p>
<p>As you can see, <strong>PATTERNDETECTION</strong> is working even with the increasing amplitude! You can discover this example by yourself by using <a href="https://home.cityzendata.net/quantum/preview/#/plot/TkVXR1RTICdjb3MnIFJFTkFNRQoxIDEwODAKPCUgRFVQICdpJyBTVE9SRSBEVVAgMiAqIFBJICogMzYwIC8gQ09TICRpICogTmFOIE5hTiBOYU4gNCBST0xMIEFERFZBTFVFICU+IEZPUgoKWyBTV0FQIGJ1Y2tldGl6ZXIubGFzdCAxMDgwIDEgMCBdIEJVQ0tFVElaRSAnY29zJyBTVE9SRQoKTkVXR1RTICdwYXR0ZXJuLnRvLmRldGVjdCcgUkVOQU1FCjIwMCAzNzAKPCUgIERVUCAnaScgU1RPUkUgRFVQIDIgKiBQSSAqIDM2MCAvIENPUyAkaSAqIE5hTiBOYU4gTmFOIDQgUk9MTCBBRERWQUxVRSAlPiBGT1IKClsgU1dBUCBidWNrZXRpemVyLmxhc3QgMjE2MCAxIDAgXSBCVUNLRVRJWkUgJ3BhdHRlcm4udG8uZGV0ZWN0JyBTVE9SRQoKLy8gQ3JlYXRlIFBhdHRlcm4KMzIgJ3dpbmRvd1NpemUnIFNUT1JFCjggJ3BhdHRlcm5MZW5ndGgnIFNUT1JFCjE2ICdxdWFudGl6YXRpb25TY2FsZScgU1RPUkUKCiRwYXR0ZXJuLnRvLmRldGVjdCAwIEdFVCAkd2luZG93U2l6ZSAkcGF0dGVybkxlbmd0aCAkcXVhbnRpemF0aW9uU2NhbGUgUEFUVEVSTlMgVkFMVUVTICdwYXR0ZXJucycgU1RPUkUKCiRjb3MgJHBhdHRlcm5zICR3aW5kb3dTaXplICRwYXR0ZXJuTGVuZ3RoICRxdWFudGl6YXRpb25TY2FsZSAgUEFUVEVSTkRFVEVDVElPTiAnY29zLmRldGVjdGlvbicgUkVOQU1FICdjb3MuZGV0ZWN0aW9uJyBTVE9SRQoKJGNvcy5kZXRlY3Rpb24KLy8gTGV0J3MgY3JlYXRlIGEgZ3RzIGZvciBlYWNoIHRyaXAKMTAgICAgICAgLy8gIFF1aWV0IHBlcmlvZAo1ICAgICAgICAgLy8gTWluIG51bWJlciBvZiB2YWx1ZXMKJ3N1YlBhdHRlcm4nICAvLyBMYWJlbApUSU1FU1BMSVQKCiRjb3M=/eyJ1cmwiOiJodHRwczovL3dhcnAuY2l0eXplbmRhdGEubmV0L2FwaS92MCIsImhlYWRlck5hbWUiOiJYLUNpdHl6ZW5EYXRhIn0=">Quantum</a>, the official web-based IDE for WarpScript. <strong>You need to switch X-axis scale to Timestamp in order to see the courbe</strong>.Thanks for reading, here‚Äôs a nice list of additionnals informations about the time series subject and Warp10:</p>
<ul>
<li><a href="https://www.ovh.com/fr/data-platforms/metrics/">Metrics Data Platform</a>, our product</li>
<li><a href="http://warp10.io/">Warp10 official documentation</a></li>
<li><a href="http://tour.warp10.io/">Warp10 tour</a>, similar to ‚ÄúThe Go Tour‚Äù</li>
<li><a href="https://www.youtube.com/watch?v=mNkfBR9KofY">Presentation of the Warp 10 Time Series Platform at the 42 US school in Fremont</a></li>
<li><a href="https://groups.google.com/forum/#!forum/warp10-users">Warp10 Google Groups</a></li>
</ul>
]]></content>
        </item>
        
        <item>
            <title>Event-driven architecture 101</title>
            <link>https://pierrezemb.fr/posts/eventdriven-architecture-101/</link>
            <pubDate>Fri, 13 May 2016 17:19:23 +0000</pubDate>
            
            <guid>https://pierrezemb.fr/posts/eventdriven-architecture-101/</guid>
            <description>update 2019: this is a repost on my own blog. original article can be read on medium.
 Do your own cover on http://dev.to/rly
I‚Äôm still a student, so my point of view could be far from reality, be gentle ;)
**tl;dr: Queue messaging are cool. Use them at the core of your architecture.**I‚Äôm currently playing a lot around Kafka and Flink at work. I also discovered Vert.x at my local JUG.</description>
            <content type="html"><![CDATA[<p><strong>update 2019:</strong> this is a repost on my own blog. original article can be read on <a href="https://medium.com/@PierreZ/event-driven-architecture-101-d8e13cc4c656">medium</a>.</p>
<hr>
<p><img src="/posts/eventdriven-architecture-101/images/1.png" alt="image"></p>
<p>Do your own cover on <a href="http://dev.to/rly">http://dev.to/rly</a></p>
<p><em>I‚Äôm still a student, so my point of view could be far from reality, be gentle ;)</em></p>
<p>**<em>tl;dr: Queue messaging are cool. Use them at the core of your architecture.</em>**I‚Äôm currently playing a lot around <a href="https://kafka.apache.org/">Kafka</a> and <a href="https://flink.apache.org/">Flink</a> at work. I also discovered <a href="http://vertx.io/">Vert.x</a> at my local JUG. All three have a common word: <strong>events</strong>. Event-driven architecture is not something that I learned at school, and I think that‚Äôs a shame. It‚Äôs really powerful and useful, especially in a world where we speak more and more about ‚Äúserverless‚Äù and ‚Äúmicro services‚Äù stuff. So here‚Äôs my attempt to make a big sum-up.</p>
<h1 id="the-unix-philosophy">the Unix philosophy</h1>
<p><img src="/posts/eventdriven-architecture-101/images/2.gif" alt="image"></p>
<p>I‚Äôm a huge fan of GNU/Linux. I just love my terminal. It‚Äôs been difficult at the beginning, but now, I consider myself fluent with it. My favorite feature ? <strong>Pipes or |</strong>. For those who don‚Äôt know, it‚Äôs the ability to pass the result of the command to another command. For example, to count how many files you have in a folder, you‚Äôll find yourself doing something like this:</p>
<ul>
<li><strong>list files</strong> in a folder</li>
<li>From this list, <strong>manipulate/filter</strong> it. One line must correspond to one file, things like folder are omitted</li>
<li>And then <strong>count</strong> the line!</li>
</ul>
<p>In the UNIX world, it should give you something like ‚Äú<strong><em>ls -l | grep ^- | wc -l‚Äù.</em></strong> it might feels like chinese. For me, it‚Äôs just feels logical. <strong>3 operations mapped into 3 commands.</strong> You declare a set a commands that, in the end, give you the result. It‚Äôs simple and also very fast (in fact, you can find funny articles like this one: <a href="http://aadrake.com/command-line-tools-can-be-235x-faster-than-your-hadoop-cluster.html">Command-line tools can be 235x faster than your Hadoop cluster</a>). This is only possible thanks to the <strong>UNIX philosophy</strong>, greatly describe by Doug McIlroy, Elliot Pinson and Berk Tague in 1978:</p>
<blockquote>
<p>Make each program do one thing well. To do a new job, build afresh rather than complicate old programs by adding new ‚Äúfeatures‚Äù.&gt; Expect the output of every program to become the input to another, as yet unknown, program.</p>
</blockquote>
<p>Why should I care? It‚Äôs 2016, not 1978! Well‚Ä¶</p>
<h1 id="back-in-2016">Back in 2016</h1>
<p><img src="/posts/eventdriven-architecture-101/images/3.gif" alt="image"></p>
<p>Cloud changed everything in terms of software engineering. <strong>We can now deploy applications without thinking about the underlying server</strong>. How cool is that? Let‚Äôs take some steps back. Now that you can easily deploy a huge application, what can be accomplished? Well, if I can deploy one app with ease, <strong>Why should I deploy only one huge app ?</strong> why can‚Äôt I deploy multiples applications instead of one? <strong>Let‚Äôs call theses applications micro services</strong> because we are in 2016.</p>
<p><img src="/posts/eventdriven-architecture-101/images/4.png" alt="image"></p>
<p>OK, so now I‚Äôm applying the first rule of the UNIX Philosophy, because I have multiples programs that are doing one job each. But about the second rule? <strong>How can they communicate? How can we simulate UNIX pipes?</strong> Before answering, let‚Äôs answer to another question first: <strong>What do we really need to send through our network?</strong> Don‚Äôt forget the  <a href="https://en.wikipedia.org/wiki/Fallacies_of_distributed_computing"><strong>Fallacies of distributed computing</strong></a><strong>‚Ä¶</strong></p>
<p>Let‚Äôs take an example. We are a new startup, and we are building our plateform. We‚Äôll certainly need to handle our customers. Let‚Äôs say that for each new customer, <strong>we need to make two actions</strong>: add it to our database, and then to our mailing-list. <strong>A simple and classical way would be to just call two functions</strong> (whether on the same applications or not), and then say to the customer: ‚ÄúYou‚Äôre successfully registered‚Äù. Like this:</p>
<p><img src="/posts/eventdriven-architecture-101/images/5.png" alt="image"></p>
<p>Classic approach</p>
<p>Is there another approach? Let‚Äôs use an <strong>event-based architecture</strong>:</p>
<h1 id="lets-talk-events"><strong>Let‚Äôs talk events</strong></h1>
<p>Let‚Äôs ask Google, what‚Äôs an event?</p>
<blockquote>
<p>a thing that happens, especially one of importance.</p>
</blockquote>
<p>Well, handling a new customer is a thing that happens (hopefully). For this, we‚Äôll be using a <strong>Queue messaging system or Broker</strong>. It‚Äôs a <strong>middleware</strong> that will <strong>receive events, and making them available for another application or groups of applications.</strong></p>
<p><img src="/posts/eventdriven-architecture-101/images/6.gif" alt="image"></p>
<p>Queue messaging architecture with 2 producers and 4 consumers</p>
<p>So let‚Äôs rethink our architecture. Pay attention to the words: our Register page will <strong>produce</strong> an event that will contains all the information about our client. This event will be <strong>queued</strong>, waiting to be <strong>consumed</strong> by the associated micro services.</p>
<p><img src="/posts/eventdriven-architecture-101/images/7.png" alt="image"></p>
<p>Simple event-driven architecture</p>
<p>We didn‚Äôt changed much, but we enable many things over here:</p>
<ul>
<li><strong>Simplicity</strong>. Remember, the first rule ! ‚ÄúMake each program do one thing well‚Äù. Like this, your <strong>code base for each app will be simple</strong> <strong>as hell</strong>, and you‚Äôll be able to easily replace your software if needed.</li>
<li><strong>Modularity</strong>. You need to add another action to the event, for example CreateProfile ? Easy, <strong>just plug another app on the same queue</strong>. You need to test a new version of your program? Easy, <strong>just plug it on the same queue</strong>.</li>
<li><strong>Scalability</strong>. One of your micro services is taking too much time? <strong>Just start a new instance of it</strong>. Huge traffic? Add new instances. With this approach, you can start really small and become giant.</li>
<li><strong>Big-data friendly.</strong> This type of architecture is often used to handle a lot of data. With plateform like <a href="http://flink.apache.org">Apache Flink</a>, you can do some <strong>stream processing directly</strong>. <a href="https://ci.apache.org/projects/flink/flink-docs-master/apis/streaming/index.html#example-program">Look how easy it is</a>.</li>
<li><strong>Polyglotism.</strong> Most messaging system are offering libraries for many languages.<strong>Like this, you can use whatever language you want</strong> . But be aware, <em>With great power comes great responsibility</em>.</li>
</ul>
<h1 id="what-about-serverless"><strong>What about serverless?</strong></h1>
<p>Serverless is the ‚Äúnew‚Äù buzz word. Ignited by Amazon with their product <a href="https://aws.amazon.com/lambda/">AWS Lambda</a> and quickly followed by <a href="https://cloud.google.com/functions/docs">Google</a>, <a href="https://azure.microsoft.com/en-us/services/functions/">Microsoft</a>, <a href="https://new-console.ng.bluemix.net/openwhisk/">IBM</a> and <a href="https://www.iron.io/introducing-aws-lambda-support">Iron.io</a>, the goal is to <strong>offer to developers a new way of building apps</strong>. Instead of writing apps, <strong>you‚Äôll just write a function that will respond to an event</strong>. In fact, you‚Äôll be paying only for the time it‚Äôs running. It‚Äôs a interesting point-of-view, because you‚Äôll be <strong>deploying an architecture built only using events</strong>. I must admit that I didn‚Äôt try it yet, but I think i<strong>t‚Äôs a great idea to force developers to split their apps and really think about events,</strong> but you could just build the same thing with any cloud provider.</p>
<h1 id="additional-links-and-talks-about-this-topic">Additional links and talks about this topic</h1>
<ul>
<li><a href="http://www.confluent.io/blog/apache-kafka-samza-and-the-unix-philosophy-of-distributed-data">Apache Kafka, Samza, and the Unix Philosophy of Distributed Data</a> by <a href="https://medium.com/u/13be457aed12">Martin Kleppmann</a></li>
<li><a href="http://blog.cloudera.com/blog/2014/09/apache-kafka-for-beginners/">Apache Kafka for Beginners</a> by Cloudera Engineering Blog</li>
<li><a href="https://www.voxxed.com/blog/2016/04/introduction-apache-kafka/">Introduction to Apache Kafka</a> by Guglielmo Iozza</li>
<li>[Apache Flink Training] (<a href="http://dataartisans.github.io/flink-training/)by">http://dataartisans.github.io/flink-training/)by</a> data-artisans</li>
<li>Meetup LeboncoinTech‚Ää‚Äî‚ÄäAMQP 101 by <a href="https://medium.com/u/58ea5a89aaae">Quentin ADAM</a> (French sorry)</li>
<li>vert.x 3‚Ää‚Äî‚Ääbe reactive on the JVM but not only in Java by Clement Escoffier/Paulo Lopes DEVOXX 2015</li>
</ul>
<p>Please, Feel free to react to this article, you can reach me on <a href="https://twitter.com/PierreZ">Twitter</a>, or have a look on my <a href="https://pierrezemb.fr">website</a>.</p>
]]></content>
        </item>
        
        <item>
            <title>Let‚Äôs talk about containers</title>
            <link>https://pierrezemb.fr/posts/lets-talk-about-containers/</link>
            <pubDate>Mon, 04 Jan 2016 18:52:19 +0000</pubDate>
            
            <guid>https://pierrezemb.fr/posts/lets-talk-about-containers/</guid>
            <description>update 2019: this is a repost on my own blog. original article can be read on medium.
 English is not my first language, so the whole story may have some mistakes‚Ä¶ corrections and fixes will be greatly appreciated. I‚Äôm also still a student, so my point of view could be far from ‚Äúproduction ready‚Äù, be gentle ;-)
In the last two years, there‚Äôs been a technology that became really hype.</description>
            <content type="html"><![CDATA[<p><strong>update 2019:</strong> this is a repost on my own blog. original article can be read on <a href="https://medium.com/@pierrez/let-s-talk-about-containers-1f11ee68c470">medium</a>.</p>
<hr>
<p><em>English is not my first language, so the whole story may have some mistakes‚Ä¶ corrections and fixes will be greatly appreciated. I‚Äôm also still a student, so my point of view could be far from ‚Äúproduction ready‚Äù, be gentle ;-)</em></p>
<p>In the last two years, there‚Äôs been a technology that became really hype. It was the graal for easy deployments, easy applications management. Let‚Äôs talk about containers.</p>
<h3 id="write-once-run-everywhere">‚ÄúWrite once, run everywhere‚Äù</h3>
<p><img src="/posts/lets-talk-about-containers/images/1.jpeg" alt="image"></p>
<p>When I first heard about containers, I was working as a part-time internship for a french bank as a developer in a Ops team. I was working around <a href="https://hadoop.apache.org/">Hadoop</a> and monitoring systems, and I was wondering ‚ÄúHow should I properly deploy my work?‚Äù. It was a java app, running into the official Java version provided by my company. <strong>I couldn‚Äôt just give it to my colleagues</strong> <strong>and leave them do some vaudou stuff because they are the Ops team</strong>. I remembered saying to myself ‚Äùfortunately, all the features that I need are in this official java version, I don‚Äôt need the latest JRE. I just need to bundle everything into a jar and done‚Äù. But what if it wasn‚Äôt? What if I had to explain to my colleagues that I need the new JRE for a really small app written by an intern? Or I needed another non-standard library during runtime?</p>
<p>The important thing here at the time was that, at any time, <strong>I could deploy it on another server that had Java, because everything is bundled into that big fat jar file</strong>. After all, ‚Äú<strong>write once, run everywhere</strong>‚Äù was the slogan created by Sun Microsystems to illustrate the cross-platform benefits of the Java language. That is a real commodity, and this is the first thing that strike me with Docker.</p>
<h3 id="docker-hype">Docker hype</h3>
<p>I will always remember my chat with my colleagues about it. I was like this:</p>
<p><img src="/posts/lets-talk-about-containers/images/2.jpeg" alt="image"></p>
<h2 id="and-they-were-more-like">And they were more like:</h2>
<p><img src="/posts/lets-talk-about-containers/images/3.jpeg" alt="image"></p>
<p>Ops knew about containers since the dawn of time, so why such hype now? I think that ‚Äúwrite once, run everywhere‚Äù is the true slogan of Docker, because you can run docker containers in any environments that has Docker. <strong>You want to try the latest datastore/SaaS app that you found on Hacker News or Reddit? There‚Äôs a Dockerfile for that</strong>. And that is super cool. So everyone started to get interested in Docker, myself included. But the real benefit is that many huge companies like Google admits that containers are the way they are deploying apps. <strong>They don‚Äôt care what type of applications they are deploying or where it‚Äôs running, it‚Äôs just running somewhere.</strong> That‚Äôs all that matters. By unifying the packages, you can automatize and deliver whatever you want somewhere. Do you really care if it‚Äôs on a specific machine? No you don‚Äôt. That‚Äôs a powerful way to think infrastructure more like a bunch of compute or storage power, and not individual machines.</p>
<h3 id="lets-create-a-container">Let‚Äôs create a container!</h3>
<p>That‚Äôs not a secret: I love <a href="https://golang.org/">Go</a>. It‚Äôs in my opinion a very nice programming language <a href="https://medium.com/@PierreZ/why-you-really-should-give-golang-a-try-6b577092d725">that you should really try</a>. So let‚Äôs say that I‚Äôm creating a go app, and then ship it with Docker. So I‚Äôll use the officiel Docker image right? <strong>Then I end up with a 700MB container to ship a 10MB app</strong>‚Ä¶ I thought that containers were supposed to be small‚Ä¶ Why? because it‚Äôs based on a full OS, with go compiler and so on. To run a single binary, there‚Äôs no need to have the whole Go compiler stack.</p>
<p>That was really bothering me. At this point, if the container is holding everything, why not use a VM? Why do we need to bundle Ubuntu into the container? From a outside point-of-view, running a container in interactive mode is much like a virtual machines right? <strong>At the time of writing, Docker‚Äôs official image for Ubuntu was pulled more than 36,000,000 time</strong>. That‚Äôs huge! And disturbing. Do you really need for example ‚Äúls, chmod, chown, sudo‚Äù into a container?</p>
<p>There is another huge impact on having a full distribution on a container: Security. <strong>You now have to watch not only for CVEs (Common Vulnerabilities and Exposures) on the packages in your host distribution, but also in your container</strong>! After all, based on this <a href="https://docs.google.com/presentation/d/1toUKgqLyy1b-pZlDgxONLduiLmt2yaLR0GliBB7b3L0/pub?start=false&amp;loop=false#slide=id.ge614ec624_2_70">presentation</a>, 66.6% of analyzed images on Quay.io are vulnerable to <a href="https://community.qualys.com/blogs/laws-of-vulnerabilities/2015/01/27/the-ghost-vulnerability">Ghost</a>, and 80% to <a href="http://heartbleed.com/">Heartbleed</a>. That is quite scary‚Ä¶ So adding this nightmare doesn‚Äôt seems the solution.</p>
<h3 id="so-what-should-i-put-into-my-container">So what should I put into my container?</h3>
<p>I looked a lot around the internet, I saw things like <a href="https://github.com/gliderlabs/docker-alpine">docker-alpine</a> or [baseimage-docker] (<a href="https://github.com/phusion/baseimage-docker)which">https://github.com/phusion/baseimage-docker)which</a> are cool, but in fact, the answer was on Docker‚Äôs website‚Ä¶ Here‚Äôs the [official sentence] (<a href="https://www.docker.com/what-docker)that">https://www.docker.com/what-docker)that</a> explains the difference between containers and virtual machines:</p>
<blockquote>
<p>‚ÄúContainers include the application and all of its dependencies, but share the kernel with other containers.‚Äù</p>
</blockquote>
<p>This specific sentence triggers something in my head. When you execute a program on your UNIX system, the system creates a special environment for that program. This environment contains everything needed for the system to run the program as if no other program were running on the system. It‚Äôs exactly the same! <strong>So a container should be abstract not as a Virtual machines, but as a UNIX process!</strong></p>
<ul>
<li>application + dependencies represent the image</li>
<li>Runtime environment like token/password will be passed through env vars for example</li>
</ul>
<h3 id="static-compilation">Static compilation</h3>
<p><img src="/posts/lets-talk-about-containers/images/4.png" alt="image"></p>
<p>Meet Go</p>
<p>Here‚Äôs an interesting fact: Go, the open-source programming language pushed by Google <strong>supports statically apps</strong>, what a coincidence! That means that this statically app will be directly talking to the kernel. <strong>Our Docker image can be empty</strong>, except for the binary and needed files like configuration. There‚Äôs a strange image on Docker that you might have seen, which is called ‚Äúscratch‚Äù:</p>
<blockquote>
<p>You can use Docker‚Äôs reserved, minimal image, scratch, as a starting point for building containers. Using the scratch ‚Äúimage‚Äù signals to the build process that you want the next command in the Dockerfile to be the first filesystem layer in your image. While scratch appears in Docker‚Äôs repository on the hub, you can‚Äôt pull it, run it, or tag any image with the name scratch. Instead, you can refer to it in your Dockerfile.</p>
</blockquote>
<p>That means that our Dockerfile now looks like this:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-docker" data-lang="docker"><span style="color:#66d9ef">FROM</span><span style="color:#e6db74"> scratch  </span><span style="color:#960050;background-color:#1e0010">
</span><span style="color:#960050;background-color:#1e0010"></span><span style="color:#66d9ef">ADD</span> hello /  <span style="color:#960050;background-color:#1e0010">
</span><span style="color:#960050;background-color:#1e0010"></span><span style="color:#66d9ef">CMD</span> [<span style="color:#960050;background-color:#1e0010">/hello</span>]<span style="color:#960050;background-color:#1e0010">
</span></code></pre></div><p>So now, I have finally (I think) the right abstraction for a container! <strong>We have a container containing only our app</strong>. Can we go even further? The most interesting thing that I learned from (quickly) reading <a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43438.pdf"><em>Large-scale cluster management at Google with Borg</em></a> is this:</p>
<blockquote>
<p>Borg programs are statically linked to reduce dependencies on their runtime environment, and structured as packages of binaries and data files, whose installation is orchestrated by Borg.</p>
</blockquote>
<p>Here‚Äôs the (final) answer! By trully coming back to the UNIX process point-of-view, we can abstract containers as Unix processes. Bu we still need to handle them. So <strong>the role of Docker would be more like a Operating System builder</strong> (nice name found by <a href="https://medium.com/u/58ea5a89aaae">Quentin ADAM</a>).As a conclusion, I think that Docker true success was to show developers that they can sandbox their apps easily, and now it‚Äôs our work to build better software, and learning new design patterns.Please, Feel free to react to this article, you can reach me on <a href="https://twitter.com/PierreZ">Twitter</a>, Or visite my <a href="https://pierrezemb.fr">website</a>.</p>
]]></content>
        </item>
        
    </channel>
</rss>
