<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>Kafka - Category - Pierre Zemb</title>
        <link>https://pierrezemb.fr/categories/kafka/</link>
        <description>Kafka - Category - Pierre Zemb</description>
        <generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Sun, 08 Dec 2019 15:00:00 &#43;0100</lastBuildDate><atom:link href="https://pierrezemb.fr/categories/kafka/" rel="self" type="application/rss+xml" /><item>
    <title>Diving into Kafka&#39;s Protocol</title>
    <link>https://pierrezemb.fr/posts/diving-into-kafka-protocol/</link>
    <pubDate>Sun, 08 Dec 2019 15:00:00 &#43;0100</pubDate>
    <author>Pierre Zemb</author>
    <guid>https://pierrezemb.fr/posts/diving-into-kafka-protocol/</guid>
    <description><![CDATA[Diving Into is a blogpost serie where we are digging a specific part of of the project&rsquo;s basecode. In this episode, we will digg into Kafka&rsquo;s protocol.
The protocol reference For the last few months, I worked a lot around Kafka&rsquo;s protocols, first by creating a fully async Kafka to Pulsar Proxy in Rust, and now by contributing directly to KoP (Kafka On Pulsar). The full Kafka Protocol documentation is available here, but it does not offer a global view of what is happening for a classic Producer and Consumer exchange.]]></description>
</item>
</channel>
</rss>
