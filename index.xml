<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>website</title>
    <link>https://pierrezemb.fr/</link>
    <description>Recent content on website</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-US</language>
    <lastBuildDate>Sun, 04 Aug 2019 15:07:11 +0200</lastBuildDate>
    
        <atom:link href="https://pierrezemb.fr/index.xml" rel="self" type="application/rss+xml" />
    
    
    
    <item>
      <title>What can be gleaned about GFS successor codenamed Colossus?</title>
      <link>https://pierrezemb.fr/posts/colossus-google/</link>
      <pubDate>Sun, 04 Aug 2019 15:07:11 +0200</pubDate>
      
      <guid>https://pierrezemb.fr/posts/colossus-google/</guid>
      <description>In the last few months, there has been numerous blogposts about the end of the Hadoop-era. It is true that:
 Health of Hadoop-based companies are publicly bad Hadoop has a bad publicity with headlines like &amp;lsquo;What does the death of Hadoop mean for big data?&amp;rsquo;  Hadoop, as a distributed-system, is hard to operate, but can be essential for some type of workload. As Hadoop is based on GFS, we can wonder how GFS evolved inside Google.</description>
    </item>
    
    
    
    <item>
      <title>Playing with TTL in HBase</title>
      <link>https://pierrezemb.fr/posts/ttl-hbase/</link>
      <pubDate>Mon, 27 May 2019 22:07:11 +0200</pubDate>
      
      <guid>https://pierrezemb.fr/posts/ttl-hbase/</guid>
      <description>Among all features provided by HBase, there is one that is pretty handy to deal with your data&amp;rsquo;s lifecyle: the fact that every cell version can have Time to Live or TTL. Let&amp;rsquo;s dive into the feature!
Time To Live (TTL) Let&amp;rsquo;s read the doc first!
 ColumnFamilies can set a TTL length in seconds, and HBase will automatically delete rows once the expiration time is reached.
 HBase Book: Time To Live (TTL)</description>
    </item>
    
    
    
    <item>
      <title>Monitoring OVH: 300k servers, 27 DCs and one metrics platform</title>
      <link>https://pierrezemb.fr/talks/one-monitoring-platform/</link>
      <pubDate>Sun, 19 May 2019 17:24:34 +0200</pubDate>
      
      <guid>https://pierrezemb.fr/talks/one-monitoring-platform/</guid>
      <description>Abstract What to do when you must monitor the whole infrastructure of the biggest European hosting and cloud provider? How to choose a tool when the most used ones fail to scale to your needs? How to build an Metrics platform to unify, conciliate and replace years of fragmented legacy partial solutions?
In this talk we will relate our experience building and maintaining OVH Metrics, the platform used to monitor all OVH infrastructure.</description>
    </item>
    
    
    
    <item>
      <title>Operate JVM at Scale</title>
      <link>https://pierrezemb.fr/talks/handling-jvm-scale/</link>
      <pubDate>Mon, 06 May 2019 22:18:13 +0200</pubDate>
      
      <guid>https://pierrezemb.fr/talks/handling-jvm-scale/</guid>
      <description>Abstract OVH has 27 data centers, more than 300 000 servers and 1.3 million customers. We operate one of the world’s largest cloud infrastructures on a daily basis, running millions of applications. Those softwares manage millions of transactions every second. To monitor such an architecture, OVH has chosen to build a unified monitoring platform: OVH Metrics Data Platform. Such a platform uses complex distributed systems to operate, based mainly on open source tools running on the JVM (Apache Kafka, Apache HBase, Warp 10, …).</description>
    </item>
    
    
    
    <item>
      <title>Handling alerts at OVH-Scale with Apache Flink</title>
      <link>https://pierrezemb.fr/talks/ovh-alerts-flink/</link>
      <pubDate>Thu, 18 Apr 2019 22:22:36 +0100</pubDate>
      
      <guid>https://pierrezemb.fr/talks/ovh-alerts-flink/</guid>
      <description>Abstract OVH relies heavily on metrics to effectively monitor its entire infrastructure. Offering a low-level vision and business, these allow teams to better operate the daily operation of our services. After managing more than 300 TB of telemetry, we started working on an alerting solution over this huge datalake. For that, we decided to use Apache Flink to manage all these large scale alerts. Today, this project manages the alerting of flagship OVH products such as Public Cloud Instances and Kubernetes.</description>
    </item>
    
    
    
    
    
    <item>
      <title>What we learned as DevOps @OVH</title>
      <link>https://pierrezemb.fr/talks/devops-ovh/</link>
      <pubDate>Wed, 06 Mar 2019 22:22:36 +0100</pubDate>
      
      <guid>https://pierrezemb.fr/talks/devops-ovh/</guid>
      <description>Abstract Have you been wondered what is like to be working at the largest European Cloud Provider as a DevOps ? Despite both working on differents teams and products, we have a lot in common, such as good practices, organizations, technologies and even our good mood ! Time to lift the curtain! We will share with you perspectives from two DevOps: one working on OVH managed Kubernetes product and one working on Metrics, OVH distributed monitoring platform.</description>
    </item>
    
    
    
    <item>
      <title>Handling OVH&#39;s alerts with Apache Flink</title>
      <link>https://pierrezemb.fr/posts/ovh-alerts-flink/</link>
      <pubDate>Sun, 03 Feb 2019 15:37:27 +0100</pubDate>
      
      <guid>https://pierrezemb.fr/posts/ovh-alerts-flink/</guid>
      <description>This is a repost from OVH&amp;rsquo;s official blogpost.. Thanks Horacio Gonzalez for the awesome drawings!
Handling OVH&amp;rsquo;s alerts with Apache Flink OVH relies extensively on metrics to effectively monitor its entire stack. Whether they are low-level or business centric, they allow teams to gain insight into how our services are operating on a daily basis. The need to store millions of datapoints per second has produced the need to create a dedicated team to build a operate a product to handle that load: **Metrics Data Platform.</description>
    </item>
    
    
    
    <item>
      <title>What are ACID transactions?</title>
      <link>https://pierrezemb.fr/posts/acid-transactions/</link>
      <pubDate>Sun, 03 Feb 2019 15:37:27 +0100</pubDate>
      
      <guid>https://pierrezemb.fr/posts/acid-transactions/</guid>
      <description>Transaction? &amp;quot;Programming should be about transforming data&amp;quot;  &amp;mdash; Programming Elixir 1.3 by Dave Thomas
As developers, we are interacting oftenly with data, whenever handling it from an API or a messaging consumer. To store it, we started to create softwares called relational database management system or RDBMS. Thanks to them, we, as developers, can develop applications pretty easily, without the need to implement our own storage solution. Interacting with mySQL or PostgreSQL have now become a commodity.</description>
    </item>
    
    
    
    <item>
      <title>Hbase Data Model</title>
      <link>https://pierrezemb.fr/posts/hbase-data-model/</link>
      <pubDate>Sun, 27 Jan 2019 20:24:27 +0100</pubDate>
      
      <guid>https://pierrezemb.fr/posts/hbase-data-model/</guid>
      <description>HBase?  Apache HBase™ is a type of &amp;ldquo;NoSQL&amp;rdquo; database. &amp;ldquo;NoSQL&amp;rdquo; is a general term meaning that the database isn’t an RDBMS which supports SQL as its primary access language. Technically speaking, HBase is really more a &amp;ldquo;Data Store&amp;rdquo; than &amp;ldquo;Data Base&amp;rdquo; because it lacks many of the features you find in an RDBMS, such as typed columns, secondary indexes, triggers, and advanced query languages, etc.
 &amp;ndash; Hbase architecture overview</description>
    </item>
    
    
    
    <item>
      <title>Rediscover the known data universe with NASA dataset</title>
      <link>https://pierrezemb.fr/talks/nasa-datasets/</link>
      <pubDate>Sat, 15 Dec 2018 19:11:11 +0100</pubDate>
      
      <guid>https://pierrezemb.fr/talks/nasa-datasets/</guid>
      <description>Abstract For many years humanity has been exploring the skies, dreaming of interstellar voyages and new planetary colonies. And you, do you want to go 3h with us to discover the universe?
It turns out that NASA has a great public dataset, especially one that is used to search for exoplanets, that is, planets outside our solar system.
During this Hands-on, we will guide you through the different stages of rediscovering exoplanets using Warp10, an open-source time series processing platform.</description>
    </item>
    
    
    
    <item>
      <title>About me</title>
      <link>https://pierrezemb.fr/about/</link>
      <pubDate>Sat, 15 Dec 2018 18:34:45 +0100</pubDate>
      
      <guid>https://pierrezemb.fr/about/</guid>
      <description>$ whoami I&amp;rsquo;m an Infrastructure Engineer at OVH.
I have a passion for distributed systems problems, specifically when it comes with scalability and performance issues.
I&amp;rsquo;m developing software using Go, Rust and Java, as well as performing on-call duty on more than 600 servers, including several Hadoop clusters.
Work I&amp;rsquo;m currently working on Metrics Data Platform. We are using Warp10 with friendly Apache softwares such as Hbase, Hadoop, Zookeeper, Kafka and Flink to handle all OVH&amp;rsquo;s metrics-based monitoring, which represent around 432 billions of measurements per day.</description>
    </item>
    
    
    
    <item>
      <title>One day into the Time Series&#39;s world</title>
      <link>https://pierrezemb.fr/talks/one-day-timeseries/</link>
      <pubDate>Sun, 11 Nov 2018 22:22:36 +0100</pubDate>
      
      <guid>https://pierrezemb.fr/talks/one-day-timeseries/</guid>
      <description> Abstract This is a one-day course I&amp;rsquo;m giving at my former engineering school ISEN Brest.
Schedule  Introduction to Time Series Time Series in real life Code instrumentation Lab: searching for exoplanets  Ressources  slides  </description>
    </item>
    
    
    
    <item>
      <title>Metrics Experience beyond protocols</title>
      <link>https://pierrezemb.fr/talks/metrics-experience/</link>
      <pubDate>Sat, 16 Dec 2017 15:38:52 +0100</pubDate>
      
      <guid>https://pierrezemb.fr/talks/metrics-experience/</guid>
      <description> Occurences  Paris Open Source Summit, 2017  Ressources The slides are available here.
Photos and Tweets Let&amp;#39;s discover @OvhMetrics experience with @PierreZ at #OSSPARIS17 pic.twitter.com/Xz1tRTNcFW
&amp;mdash; Collignon Rémi (@miton1810) December 7, 2017  </description>
    </item>
    
    
    
    <item>
      <title>Introducing HelloExoWorld: The quest to discover exoplanets with Warp10 and Tensorflow</title>
      <link>https://pierrezemb.fr/posts/introducing-helloexoworld-the-quest-to-discover-exoplanets-with-warp10-and-tensorflow/</link>
      <pubDate>Wed, 11 Oct 2017 10:23:11 +0000</pubDate>
      
      <guid>https://pierrezemb.fr/posts/introducing-helloexoworld-the-quest-to-discover-exoplanets-with-warp10-and-tensorflow/</guid>
      <description>update 2019: this is a repost on my own blog. original article can be read on medium.
Artist’s impression of the super-Earth exoplanet LHS 1140b By ESO/spaceengine.org — CC BY 4.0
My passion for programming was kind of late, I typed my first line of code at my engineering school. It then became a passion, something I’m willing to do at work, on my free-time, at night or the week-end.</description>
    </item>
    
    
    
    <item>
      <title>Engage maximum warp speed in time series analysis with WarpScript</title>
      <link>https://pierrezemb.fr/posts/engage-maximum-warp-speed-in-time-series-analysis-with-warpscript/</link>
      <pubDate>Sun, 08 Oct 2017 20:43:05 +0000</pubDate>
      
      <guid>https://pierrezemb.fr/posts/engage-maximum-warp-speed-in-time-series-analysis-with-warpscript/</guid>
      <description>update 2019: this is a repost on my own blog. original article can be read on medium.
We, at Metrics Data Platform, are working everyday with Warp10 Platform, an open source Time Series database. You may not know it because it’s not as famous as Prometheus or InfluxDB but Warp10 is the most powerful and generic solution to store and analyze sensor data. It’s the core of Metrics, and many internal teams from OVH are using Metrics Data Platform to monitor their infrastructure.</description>
    </item>
    
    
    
    <item>
      <title>Event-driven architecture 101</title>
      <link>https://pierrezemb.fr/posts/eventdriven-architecture-101/</link>
      <pubDate>Fri, 13 May 2016 17:19:23 +0000</pubDate>
      
      <guid>https://pierrezemb.fr/posts/eventdriven-architecture-101/</guid>
      <description>update 2019: this is a repost on my own blog. original article can be read on medium.
Do your own cover on http://dev.to/rly
I’m still a student, so my point of view could be far from reality, be gentle ;)
tl;dr: Queue messaging are cool. Use them at the core of your architecture.I’m currently playing a lot around Kafka and Flink at work. I also discovered Vert.x at my local JUG.</description>
    </item>
    
    
    
    <item>
      <title>Let’s talk about containers</title>
      <link>https://pierrezemb.fr/posts/lets-talk-about-containers/</link>
      <pubDate>Mon, 04 Jan 2016 18:52:19 +0000</pubDate>
      
      <guid>https://pierrezemb.fr/posts/lets-talk-about-containers/</guid>
      <description>update 2019: this is a repost on my own blog. original article can be read on medium.
English is not my first language, so the whole story may have some mistakes… corrections and fixes will be greatly appreciated. I’m also still a student, so my point of view could be far from “production ready”, be gentle ;-)
In the last two years, there’s been a technology that became really hype.</description>
    </item>
    
    
  </channel>
</rss>